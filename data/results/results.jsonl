{"question_id": "tqa_rc_validation_0", "question": "Who was the man behind The Chipmunks?", "ground_truth": ["David Seville"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Ross Bagdasarian Sr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:36:40.276915Z"}
{"question_id": "tqa_rc_validation_0", "question": "Who was the man behind The Chipmunks?", "ground_truth": ["David Seville"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Ross Bagdasarian Sr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:37:09.579066Z"}
{"question_id": "tqa_rc_validation_0", "question": "Who was the man behind The Chipmunks?", "ground_truth": ["David Seville"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Ross Bagdasarian Sr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:37:19.953927Z"}
{"question_id": "tqa_rc_validation_0", "question": "Who was the man behind The Chipmunks?", "ground_truth": ["David Seville"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Ross Bagdasarian Sr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:37:43.441442Z"}
{"question_id": "tqa_rc_validation_0", "question": "Who was the man behind The Chipmunks?", "ground_truth": ["David Seville"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Ross Bagdasarian Sr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ross Bagdasarian Jr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Jr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian, also known as David Seville", "Ross Bagdasarian Sr", "Ross Bagdasarian Jr", "Ross Bagdasarian Sr"], "equivalence_results": ["different", "same", "same", "different", "same", "same", "different", "same", "different", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:38:05.193863Z"}
{"question_id": "tqa_rc_validation_1", "question": "Which Lloyd Webber musical premiered in the US on 10th December 1993?", "ground_truth": ["Sunset Boulevard", "Sunset Blvd", "West Sunset Boulevard", "Sunset Bulevard", "Sunset Blvd."], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Sunset Boulevard", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:05.959307Z"}
{"question_id": "tqa_rc_validation_1", "question": "Which Lloyd Webber musical premiered in the US on 10th December 1993?", "ground_truth": ["Sunset Boulevard", "Sunset Blvd", "West Sunset Boulevard", "Sunset Bulevard", "Sunset Blvd."], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Sunset Boulevard", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:07.316436Z"}
{"question_id": "tqa_rc_validation_1", "question": "Which Lloyd Webber musical premiered in the US on 10th December 1993?", "ground_truth": ["Sunset Boulevard", "Sunset Blvd", "West Sunset Boulevard", "Sunset Bulevard", "Sunset Blvd."], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Sunset Boulevard", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:07.744959Z"}
{"question_id": "tqa_rc_validation_1", "question": "Which Lloyd Webber musical premiered in the US on 10th December 1993?", "ground_truth": ["Sunset Boulevard", "Sunset Blvd", "West Sunset Boulevard", "Sunset Bulevard", "Sunset Blvd."], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Sunset Boulevard", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:08.857441Z"}
{"question_id": "tqa_rc_validation_1", "question": "Which Lloyd Webber musical premiered in the US on 10th December 1993?", "ground_truth": ["Sunset Boulevard", "Sunset Blvd", "West Sunset Boulevard", "Sunset Bulevard", "Sunset Blvd."], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Sunset Boulevard", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:09.648350Z"}
{"question_id": "tqa_rc_validation_2", "question": "Who was the next British Prime Minister after Arthur Balfour?", "ground_truth": ["Campbell-Bannerman", "Sir Henry Campbell-Bannerman", "Campbell Bannerman", "Sir Henry Campbell Bannerman", "Henry Campbell Bannerman", "Henry Campbell-Bannerman"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Henry Campbell-Bannerman", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:10.683904Z"}
{"question_id": "tqa_rc_validation_2", "question": "Who was the next British Prime Minister after Arthur Balfour?", "ground_truth": ["Campbell-Bannerman", "Sir Henry Campbell-Bannerman", "Campbell Bannerman", "Sir Henry Campbell Bannerman", "Henry Campbell Bannerman", "Henry Campbell-Bannerman"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Sir Henry Campbell-Bannerman", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:12.250691Z"}
{"question_id": "tqa_rc_validation_2", "question": "Who was the next British Prime Minister after Arthur Balfour?", "ground_truth": ["Campbell-Bannerman", "Sir Henry Campbell-Bannerman", "Campbell Bannerman", "Sir Henry Campbell Bannerman", "Henry Campbell Bannerman", "Henry Campbell-Bannerman"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Sir Henry Campbell-Bannerman", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:12.486354Z"}
{"question_id": "tqa_rc_validation_2", "question": "Who was the next British Prime Minister after Arthur Balfour?", "ground_truth": ["Campbell-Bannerman", "Sir Henry Campbell-Bannerman", "Campbell Bannerman", "Sir Henry Campbell Bannerman", "Henry Campbell Bannerman", "Henry Campbell-Bannerman"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Henry Campbell-Bannerman", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:13.663229Z"}
{"question_id": "tqa_rc_validation_2", "question": "Who was the next British Prime Minister after Arthur Balfour?", "ground_truth": ["Campbell-Bannerman", "Sir Henry Campbell-Bannerman", "Campbell Bannerman", "Sir Henry Campbell Bannerman", "Henry Campbell Bannerman", "Henry Campbell-Bannerman"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Sir Henry Campbell-Bannerman", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:14.461976Z"}
{"question_id": "tqa_rc_validation_3", "question": "Who had a 70s No 1 hit with Kiss You All Over?", "ground_truth": ["Exile", "Internal exile", "Exiles", "Transported for life", "Exile (politics and government)", "Voluntary exile", "Sent into exile", "Exile and Banishment", "Self-exile", "Forced exile", "Exile in Greek tragedy", "Banish", "Banishment", "self exile", "exile politics and government"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Exile", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:15.323607Z"}
{"question_id": "tqa_rc_validation_3", "question": "Who had a 70s No 1 hit with Kiss You All Over?", "ground_truth": ["Exile", "Internal exile", "Exiles", "Transported for life", "Exile (politics and government)", "Voluntary exile", "Sent into exile", "Exile and Banishment", "Self-exile", "Forced exile", "Exile in Greek tragedy", "Banish", "Banishment", "self exile", "exile politics and government"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Exile", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:17.341410Z"}
{"question_id": "tqa_rc_validation_3", "question": "Who had a 70s No 1 hit with Kiss You All Over?", "ground_truth": ["Exile", "Internal exile", "Exiles", "Transported for life", "Exile (politics and government)", "Voluntary exile", "Sent into exile", "Exile and Banishment", "Self-exile", "Forced exile", "Exile in Greek tragedy", "Banish", "Banishment", "self exile", "exile politics and government"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Exile", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:17.722271Z"}
{"question_id": "tqa_rc_validation_3", "question": "Who had a 70s No 1 hit with Kiss You All Over?", "ground_truth": ["Exile", "Internal exile", "Exiles", "Transported for life", "Exile (politics and government)", "Voluntary exile", "Sent into exile", "Exile and Banishment", "Self-exile", "Forced exile", "Exile in Greek tragedy", "Banish", "Banishment", "self exile", "exile politics and government"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Exile", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:18.915361Z"}
{"question_id": "tqa_rc_validation_3", "question": "Who had a 70s No 1 hit with Kiss You All Over?", "ground_truth": ["Exile", "Internal exile", "Exiles", "Transported for life", "Exile (politics and government)", "Voluntary exile", "Sent into exile", "Exile and Banishment", "Self-exile", "Forced exile", "Exile in Greek tragedy", "Banish", "Banishment", "self exile", "exile politics and government"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Exile", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:19.583854Z"}
{"question_id": "tqa_rc_validation_4", "question": "What claimed the life of singer Kathleen Ferrier?", "ground_truth": ["Cancer", "Cancer pathology", "Deaths by cancer", "Anti-cancer", "Cancer (disease)", "Cancerophobia", "Malignant lesion", "Cancer medication", "Malignant tumors", "Cancer signs", "Malignant neoplasm", "Invasive (cancer)", "Malignant Neoplasms", "Malignant growth", "Sporadic cancer", "Malignant cancer", "Tumour virus", "Cancer en cuirasse", "Microtumor", "Malignant tumour", "Carcinophobia", "Malignacy", "Cancer patient", "Epithelial cancers", "Solid cancer", "Cancers", "Tumor medication", "Malignant neoplastic disease", "AIDS-related cancer", "Invasive cancer", "Cancer therapy", "Cancerous tumor", "Financial toxicity", "Cancer diagnosis", "Cancer (medicine)", "Malignant tumor", "Cancerous", "Borderline (cancer)", "Signs of cancer", "Malignancies", "Cancer aromatase", "aids related cancer", "cancer disease", "cancer medicine", "borderline cancer", "anti cancer"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Breast cancer", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:20.403671Z"}
{"question_id": "tqa_rc_validation_4", "question": "What claimed the life of singer Kathleen Ferrier?", "ground_truth": ["Cancer", "Cancer pathology", "Deaths by cancer", "Anti-cancer", "Cancer (disease)", "Cancerophobia", "Malignant lesion", "Cancer medication", "Malignant tumors", "Cancer signs", "Malignant neoplasm", "Invasive (cancer)", "Malignant Neoplasms", "Malignant growth", "Sporadic cancer", "Malignant cancer", "Tumour virus", "Cancer en cuirasse", "Microtumor", "Malignant tumour", "Carcinophobia", "Malignacy", "Cancer patient", "Epithelial cancers", "Solid cancer", "Cancers", "Tumor medication", "Malignant neoplastic disease", "AIDS-related cancer", "Invasive cancer", "Cancer therapy", "Cancerous tumor", "Financial toxicity", "Cancer diagnosis", "Cancer (medicine)", "Malignant tumor", "Cancerous", "Borderline (cancer)", "Signs of cancer", "Malignancies", "Cancer aromatase", "aids related cancer", "cancer disease", "cancer medicine", "borderline cancer", "anti cancer"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Cancer (breast cancer)", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:21.424141Z"}
{"question_id": "tqa_rc_validation_4", "question": "What claimed the life of singer Kathleen Ferrier?", "ground_truth": ["Cancer", "Cancer pathology", "Deaths by cancer", "Anti-cancer", "Cancer (disease)", "Cancerophobia", "Malignant lesion", "Cancer medication", "Malignant tumors", "Cancer signs", "Malignant neoplasm", "Invasive (cancer)", "Malignant Neoplasms", "Malignant growth", "Sporadic cancer", "Malignant cancer", "Tumour virus", "Cancer en cuirasse", "Microtumor", "Malignant tumour", "Carcinophobia", "Malignacy", "Cancer patient", "Epithelial cancers", "Solid cancer", "Cancers", "Tumor medication", "Malignant neoplastic disease", "AIDS-related cancer", "Invasive cancer", "Cancer therapy", "Cancerous tumor", "Financial toxicity", "Cancer diagnosis", "Cancer (medicine)", "Malignant tumor", "Cancerous", "Borderline (cancer)", "Signs of cancer", "Malignancies", "Cancer aromatase", "aids related cancer", "cancer disease", "cancer medicine", "borderline cancer", "anti cancer"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Breast cancer", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:21.803713Z"}
{"question_id": "tqa_rc_validation_4", "question": "What claimed the life of singer Kathleen Ferrier?", "ground_truth": ["Cancer", "Cancer pathology", "Deaths by cancer", "Anti-cancer", "Cancer (disease)", "Cancerophobia", "Malignant lesion", "Cancer medication", "Malignant tumors", "Cancer signs", "Malignant neoplasm", "Invasive (cancer)", "Malignant Neoplasms", "Malignant growth", "Sporadic cancer", "Malignant cancer", "Tumour virus", "Cancer en cuirasse", "Microtumor", "Malignant tumour", "Carcinophobia", "Malignacy", "Cancer patient", "Epithelial cancers", "Solid cancer", "Cancers", "Tumor medication", "Malignant neoplastic disease", "AIDS-related cancer", "Invasive cancer", "Cancer therapy", "Cancerous tumor", "Financial toxicity", "Cancer diagnosis", "Cancer (medicine)", "Malignant tumor", "Cancerous", "Borderline (cancer)", "Signs of cancer", "Malignancies", "Cancer aromatase", "aids related cancer", "cancer disease", "cancer medicine", "borderline cancer", "anti cancer"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Breast cancer", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:23.030460Z"}
{"question_id": "tqa_rc_validation_4", "question": "What claimed the life of singer Kathleen Ferrier?", "ground_truth": ["Cancer", "Cancer pathology", "Deaths by cancer", "Anti-cancer", "Cancer (disease)", "Cancerophobia", "Malignant lesion", "Cancer medication", "Malignant tumors", "Cancer signs", "Malignant neoplasm", "Invasive (cancer)", "Malignant Neoplasms", "Malignant growth", "Sporadic cancer", "Malignant cancer", "Tumour virus", "Cancer en cuirasse", "Microtumor", "Malignant tumour", "Carcinophobia", "Malignacy", "Cancer patient", "Epithelial cancers", "Solid cancer", "Cancers", "Tumor medication", "Malignant neoplastic disease", "AIDS-related cancer", "Invasive cancer", "Cancer therapy", "Cancerous tumor", "Financial toxicity", "Cancer diagnosis", "Cancer (medicine)", "Malignant tumor", "Cancerous", "Borderline (cancer)", "Signs of cancer", "Malignancies", "Cancer aromatase", "aids related cancer", "cancer disease", "cancer medicine", "borderline cancer", "anti cancer"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Breast cancer", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:35.202079Z"}
{"question_id": "tqa_rc_validation_5", "question": "Rita Coolidge sang the title song for which Bond film?", "ground_truth": ["Octopussy", "Kamal kahn", "List of Bond girls in Octopussy", "Magda (James Bond)", "List of James Bond allies in Octopussy", "Vijay (James Bond)", "Bond 13", "Octopussy (character)", "Penelope Smallbone", "General Orlov", "Kamal Khan", "Octopussy (film)", "List of James Bond villains in Octopussy", "Jim Fanning (James Bond)", "magda james bond", "vijay james bond", "jim fanning james bond", "octopussy character", "octopussy film"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Octopussy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:35.992606Z"}
{"question_id": "tqa_rc_validation_5", "question": "Rita Coolidge sang the title song for which Bond film?", "ground_truth": ["Octopussy", "Kamal kahn", "List of Bond girls in Octopussy", "Magda (James Bond)", "List of James Bond allies in Octopussy", "Vijay (James Bond)", "Bond 13", "Octopussy (character)", "Penelope Smallbone", "General Orlov", "Kamal Khan", "Octopussy (film)", "List of James Bond villains in Octopussy", "Jim Fanning (James Bond)", "magda james bond", "vijay james bond", "jim fanning james bond", "octopussy character", "octopussy film"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Octopussy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:37.592607Z"}
{"question_id": "tqa_rc_validation_5", "question": "Rita Coolidge sang the title song for which Bond film?", "ground_truth": ["Octopussy", "Kamal kahn", "List of Bond girls in Octopussy", "Magda (James Bond)", "List of James Bond allies in Octopussy", "Vijay (James Bond)", "Bond 13", "Octopussy (character)", "Penelope Smallbone", "General Orlov", "Kamal Khan", "Octopussy (film)", "List of James Bond villains in Octopussy", "Jim Fanning (James Bond)", "magda james bond", "vijay james bond", "jim fanning james bond", "octopussy character", "octopussy film"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "You Only Live Twice", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["You Only Live Twice", "\"You Only Live Twice\"", "You Only Live Twice", "\"You Only Live Twice\"", "You Only Live Twice", "You Only Live Twice", "\"You Only Live Twice\"", "You Only Live Twice", "\"You Only Live Twice\"", "You Only Live Twice"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:38:47.747868Z"}
{"question_id": "tqa_rc_validation_5", "question": "Rita Coolidge sang the title song for which Bond film?", "ground_truth": ["Octopussy", "Kamal kahn", "List of Bond girls in Octopussy", "Magda (James Bond)", "List of James Bond allies in Octopussy", "Vijay (James Bond)", "Bond 13", "Octopussy (character)", "Penelope Smallbone", "General Orlov", "Kamal Khan", "Octopussy (film)", "List of James Bond villains in Octopussy", "Jim Fanning (James Bond)", "magda james bond", "vijay james bond", "jim fanning james bond", "octopussy character", "octopussy film"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Octopussy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:38:49.021682Z"}
{"question_id": "tqa_rc_validation_5", "question": "Rita Coolidge sang the title song for which Bond film?", "ground_truth": ["Octopussy", "Kamal kahn", "List of Bond girls in Octopussy", "Magda (James Bond)", "List of James Bond allies in Octopussy", "Vijay (James Bond)", "Bond 13", "Octopussy (character)", "Penelope Smallbone", "General Orlov", "Kamal Khan", "Octopussy (film)", "List of James Bond villains in Octopussy", "Jim Fanning (James Bond)", "magda james bond", "vijay james bond", "jim fanning james bond", "octopussy character", "octopussy film"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "All Time High", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["All Time High", "All Time High", "All the Money in the World's predecessor, a song for The World Is Not Enough was performed by, but not Rita, the title song for The World Is Not Enough was performed by Garbage, however Rita did perform a song for an actual Bond", "All Time High", "All Time High", "All Time High was sung by Rita Coolidge for the Bond film Octopussy", "Octopussy", "All Time High", "All Time High (not the title song specifically in the film)", "All Time High"], "equivalence_results": ["same", "same", "different", "same", "same", "different", "different", "same", "different", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:39:24.230851Z"}
{"question_id": "tqa_rc_validation_6", "question": "What was the last US state to reintroduce alcohol after prohibition?", "ground_truth": ["Utah", "Utah (State)", "Forty-Fifth State", "Sports in Utah", "Climate of Utah", "Education in Utah", "UT (state)", "Utahn", "Yutas", "Geography of Utah", "Utah, United States", "Utah state nickname", "History of mining in Utah", "State of Utah", "Religion in Utah", "Utah (U.S. state)", "Transportation in Utah", "Beehive State", "US-UT", "Utahan", "Politics of Utah", "Salt Lake Seagulls", "45th State", "History of Utah (to 1847)", "The Beehive State", "Youtah", "Transport in Utah", "utah united states", "us ut", "utah state", "forty fifth state", "ut state", "history of utah to 1847", "utah u s state"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Mississippi", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:39:42.293768Z"}
{"question_id": "tqa_rc_validation_6", "question": "What was the last US state to reintroduce alcohol after prohibition?", "ground_truth": ["Utah", "Utah (State)", "Forty-Fifth State", "Sports in Utah", "Climate of Utah", "Education in Utah", "UT (state)", "Utahn", "Yutas", "Geography of Utah", "Utah, United States", "Utah state nickname", "History of mining in Utah", "State of Utah", "Religion in Utah", "Utah (U.S. state)", "Transportation in Utah", "Beehive State", "US-UT", "Utahan", "Politics of Utah", "Salt Lake Seagulls", "45th State", "History of Utah (to 1847)", "The Beehive State", "Youtah", "Transport in Utah", "utah united states", "us ut", "utah state", "forty fifth state", "ut state", "history of utah to 1847", "utah u s state"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Mississippi (in 1966)", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:40:11.147200Z"}
{"question_id": "tqa_rc_validation_6", "question": "What was the last US state to reintroduce alcohol after prohibition?", "ground_truth": ["Utah", "Utah (State)", "Forty-Fifth State", "Sports in Utah", "Climate of Utah", "Education in Utah", "UT (state)", "Utahn", "Yutas", "Geography of Utah", "Utah, United States", "Utah state nickname", "History of mining in Utah", "State of Utah", "Religion in Utah", "Utah (U.S. state)", "Transportation in Utah", "Beehive State", "US-UT", "Utahan", "Politics of Utah", "Salt Lake Seagulls", "45th State", "History of Utah (to 1847)", "The Beehive State", "Youtah", "Transport in Utah", "utah united states", "us ut", "utah state", "forty fifth state", "ut state", "history of utah to 1847", "utah u s state"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Kansas", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Kansas", "Mississippi", "Mississippi", "Mississippi", "Kansas"], "equivalence_results": ["different", "different", "different", "different", "different", "same", "different", "different", "different", "same"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:40:21.980780Z"}
{"question_id": "tqa_rc_validation_6", "question": "What was the last US state to reintroduce alcohol after prohibition?", "ground_truth": ["Utah", "Utah (State)", "Forty-Fifth State", "Sports in Utah", "Climate of Utah", "Education in Utah", "UT (state)", "Utahn", "Yutas", "Geography of Utah", "Utah, United States", "Utah state nickname", "History of mining in Utah", "State of Utah", "Religion in Utah", "Utah (U.S. state)", "Transportation in Utah", "Beehive State", "US-UT", "Utahan", "Politics of Utah", "Salt Lake Seagulls", "45th State", "History of Utah (to 1847)", "The Beehive State", "Youtah", "Transport in Utah", "utah united states", "us ut", "utah state", "forty fifth state", "ut state", "history of utah to 1847", "utah u s state"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Mississippi", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:40:42.962346Z"}
{"question_id": "tqa_rc_validation_6", "question": "What was the last US state to reintroduce alcohol after prohibition?", "ground_truth": ["Utah", "Utah (State)", "Forty-Fifth State", "Sports in Utah", "Climate of Utah", "Education in Utah", "UT (state)", "Utahn", "Yutas", "Geography of Utah", "Utah, United States", "Utah state nickname", "History of mining in Utah", "State of Utah", "Religion in Utah", "Utah (U.S. state)", "Transportation in Utah", "Beehive State", "US-UT", "Utahan", "Politics of Utah", "Salt Lake Seagulls", "45th State", "History of Utah (to 1847)", "The Beehive State", "Youtah", "Transport in Utah", "utah united states", "us ut", "utah state", "forty fifth state", "ut state", "history of utah to 1847", "utah u s state"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Mississippi", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Massachusetts", "Massachusetts", "Massachusetts", "Mississippi", "Mississippi", "Connecticut", "Connecticut, on October 19, 1963", "Mississippi", "Massachusetts", "Massachusetts"], "equivalence_results": ["different", "different", "different", "same", "same", "different", "different", "same", "different", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:41:01.658608Z"}
{"question_id": "tqa_rc_validation_7", "question": "Which actress was voted Miss Greenwich Village in 1942?", "ground_truth": ["Lauren Bacall", "Bacall", "Lauren Becal", "Lauren Becall", "Betty J. Perske", "Loren Bacall", "Betty Joan Perske", "Betty Perske", "Betty Joan Perski", "betty j perske"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Lauren Bacall", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:41:02.592296Z"}
{"question_id": "tqa_rc_validation_7", "question": "Which actress was voted Miss Greenwich Village in 1942?", "ground_truth": ["Lauren Bacall", "Bacall", "Lauren Becal", "Lauren Becall", "Betty J. Perske", "Loren Bacall", "Betty Joan Perske", "Betty Perske", "Betty Joan Perski", "betty j perske"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Lauren Bacall", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:41:04.320344Z"}
{"question_id": "tqa_rc_validation_7", "question": "Which actress was voted Miss Greenwich Village in 1942?", "ground_truth": ["Lauren Bacall", "Bacall", "Lauren Becal", "Lauren Becall", "Betty J. Perske", "Loren Bacall", "Betty Joan Perske", "Betty Perske", "Betty Joan Perski", "betty j perske"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Shelley Winters", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Shelley Winters", "Shelley Winters", "Barbara Stanwyck", "Kim Novak", "Marilyn Monroe", "Shelley Winters", "Shelley Winters", "Shelley Winters", "Marilyn Monroe", "Tippi Hedren"], "equivalence_results": ["same", "same", "different", "different", "different", "same", "same", "same", "different", "different"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:41:15.007013Z"}
{"question_id": "tqa_rc_validation_7", "question": "Which actress was voted Miss Greenwich Village in 1942?", "ground_truth": ["Lauren Bacall", "Bacall", "Lauren Becal", "Lauren Becall", "Betty J. Perske", "Loren Bacall", "Betty Joan Perske", "Betty Perske", "Betty Joan Perski", "betty j perske"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Mona Freeman", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Mona Freeman", "Mona Freeman", "Marilyn Monroe", "Mona Freeman", "Mona Freeman", "Mona Freeman", "Marilyn Monroe", "Mona Freeman", "Mona Freeman", "Mona Freeman"], "equivalence_results": ["same", "same", "different", "same", "same", "same", "different", "same", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:41:37.371246Z"}
{"question_id": "tqa_rc_validation_7", "question": "Which actress was voted Miss Greenwich Village in 1942?", "ground_truth": ["Lauren Bacall", "Bacall", "Lauren Becal", "Lauren Becall", "Betty J. Perske", "Loren Bacall", "Betty Joan Perske", "Betty Perske", "Betty Joan Perski", "betty j perske"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Cloris Leachman", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Lauren Bacall", "Marlene Dietrich", "Cloris Leachman", "Betty Grable", "Joan Crawford", "Cloris Leachman", "Claire Bloom", "Claudia Barrett", "Betty Grable", "Lauren Bacall"], "equivalence_results": ["different", "different", "same", "different", "different", "same", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:41:54.448562Z"}
{"question_id": "tqa_rc_validation_8", "question": "What is the Japanese share index called?", "ground_truth": ["Nikkei", "Nikkei (disambiguation)", "nikkei disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Nikkei 225", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:41:55.236734Z"}
{"question_id": "tqa_rc_validation_8", "question": "What is the Japanese share index called?", "ground_truth": ["Nikkei", "Nikkei (disambiguation)", "nikkei disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Nikkei 225", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:41:57.032918Z"}
{"question_id": "tqa_rc_validation_8", "question": "What is the Japanese share index called?", "ground_truth": ["Nikkei", "Nikkei (disambiguation)", "nikkei disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Nikkei 225", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:41:57.276540Z"}
{"question_id": "tqa_rc_validation_8", "question": "What is the Japanese share index called?", "ground_truth": ["Nikkei", "Nikkei (disambiguation)", "nikkei disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Nikkei 225", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:41:58.647236Z"}
{"question_id": "tqa_rc_validation_8", "question": "What is the Japanese share index called?", "ground_truth": ["Nikkei", "Nikkei (disambiguation)", "nikkei disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Nikkei 225", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:41:59.370277Z"}
{"question_id": "tqa_rc_validation_9", "question": "What was the name of Michael Jackson's autobiography written in 1988?", "ground_truth": ["Moonwalk", "Walk on the Moon", "Moonwalk (disambiguation)", "Lunar walks", "Moon Walk", "Moonwalking", "Lunar walk", "Moonwalks", "Moon walks", "Lunar walking", "Moon walking", "moonwalk disambiguation", "walk on moon"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Moonwalk", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:42:00.237423Z"}
{"question_id": "tqa_rc_validation_9", "question": "What was the name of Michael Jackson's autobiography written in 1988?", "ground_truth": ["Moonwalk", "Walk on the Moon", "Moonwalk (disambiguation)", "Lunar walks", "Moon Walk", "Moonwalking", "Lunar walk", "Moonwalks", "Moon walks", "Lunar walking", "Moon walking", "moonwalk disambiguation", "walk on moon"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Moonwalk", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:42:01.201544Z"}
{"question_id": "tqa_rc_validation_9", "question": "What was the name of Michael Jackson's autobiography written in 1988?", "ground_truth": ["Moonwalk", "Walk on the Moon", "Moonwalk (disambiguation)", "Lunar walks", "Moon Walk", "Moonwalking", "Lunar walk", "Moonwalks", "Moon walks", "Lunar walking", "Moon walking", "moonwalk disambiguation", "walk on moon"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "\"Moonwalk\"", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:42:01.350265Z"}
{"question_id": "tqa_rc_validation_9", "question": "What was the name of Michael Jackson's autobiography written in 1988?", "ground_truth": ["Moonwalk", "Walk on the Moon", "Moonwalk (disambiguation)", "Lunar walks", "Moon Walk", "Moonwalking", "Lunar walk", "Moonwalks", "Moon walks", "Lunar walking", "Moon walking", "moonwalk disambiguation", "walk on moon"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Moon Walk", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:42:02.761309Z"}
{"question_id": "tqa_rc_validation_9", "question": "What was the name of Michael Jackson's autobiography written in 1988?", "ground_truth": ["Moonwalk", "Walk on the Moon", "Moonwalk (disambiguation)", "Lunar walks", "Moon Walk", "Moonwalking", "Lunar walk", "Moonwalks", "Moon walks", "Lunar walking", "Moon walking", "moonwalk disambiguation", "walk on moon"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Moonwalk", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:42:03.481287Z"}
{"question_id": "tqa_rc_validation_10", "question": "In which decade did stereo records first go on sale?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "1950s", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1950s", "The 1950s", "1950s", "1950s", "The 1950s", "1950s", "1950s", "The 1950s", "1950s", "1950s"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:42:21.479801Z"}
{"question_id": "tqa_rc_validation_10", "question": "In which decade did stereo records first go on sale?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "1950s", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:42:47.621856Z"}
{"question_id": "tqa_rc_validation_10", "question": "In which decade did stereo records first go on sale?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "1950s", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:42:58.103058Z"}
{"question_id": "tqa_rc_validation_10", "question": "In which decade did stereo records first go on sale?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "1950s", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s", "1950s"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:43:19.040885Z"}
{"question_id": "tqa_rc_validation_10", "question": "In which decade did stereo records first go on sale?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "1958", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The 1940s", "The 1940s", "1958", "The 1950s", "1948", "The 1950s", "The 1940s", "1958", "The 1940s", "1950s"], "equivalence_results": ["different", "different", "same", "same", "different", "same", "different", "same", "different", "same"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:43:36.620938Z"}
{"question_id": "tqa_rc_validation_11", "question": "In what year's Olympics were electric timing devices and a public-address system used for the first time?", "ground_truth": ["In 1912, in Stockholm", "in 1912 in stockholm"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "1912", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1912", "1912", "1912", "1912", "1912", "1912", "1912", "1912", "1912", "1912"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:43:54.354962Z"}
{"question_id": "tqa_rc_validation_11", "question": "In what year's Olympics were electric timing devices and a public-address system used for the first time?", "ground_truth": ["In 1912, in Stockholm", "in 1912 in stockholm"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "1912", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1912", "1912", "1912", "1912", "1912", "1912", "1912", "1912", "1912", "1912"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:44:21.401605Z"}
{"question_id": "tqa_rc_validation_11", "question": "In what year's Olympics were electric timing devices and a public-address system used for the first time?", "ground_truth": ["In 1912, in Stockholm", "in 1912 in stockholm"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "1932", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1932", "1932", "1932", "1932", "1932", "1932", "1932", "1932", "1932", "1932"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:44:31.902798Z"}
{"question_id": "tqa_rc_validation_11", "question": "In what year's Olympics were electric timing devices and a public-address system used for the first time?", "ground_truth": ["In 1912, in Stockholm", "in 1912 in stockholm"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "1912", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1912", "1912", "1912", "1912", "1912", "1912", "1912", "1912", "1912", "1912"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:44:53.190891Z"}
{"question_id": "tqa_rc_validation_11", "question": "In what year's Olympics were electric timing devices and a public-address system used for the first time?", "ground_truth": ["In 1912, in Stockholm", "in 1912 in stockholm"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "1912", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1912", "1912", "1908", "1912", "1936", "1908", "1908", "1912", "1908", "1928"], "equivalence_results": ["same", "same", "different", "same", "different", "different", "different", "same", "different", "different"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:45:08.804380Z"}
{"question_id": "tqa_rc_validation_12", "question": "Which volcano in Tanzania is the highest mountain in Africa?", "ground_truth": ["Kilimanjaro", "Mawensi", "Mt. Kilimanjaro", "Kibo (volcano)", "Mount killimanjaro", "Highest mountain in Africa", "Kilimanjaro Massif", "Stella Point", "Kilimandjaro", "Kilimonjaro", "Gilman's Point", "Killimanjaro", "Kilima-Njaro", "Kiliminjaro", "Mt Kilimanjaro", "Kilimanjaro Mountain", "Mount Kilimanjaro", "Mawenzi", "Uhuru Peak", "Kilimanjiro", "Kaiser-Wilhelm-Spitze", "Mt Kilamanjaro", "Mount Kiliminjaro", "Mount Kilimandjaro", "Mount Kilamanjaro", "Tussock Grassland (Tanzania)", "Kilamanjaro", "tussock grassland tanzania", "kibo volcano", "kaiser wilhelm spitze", "gilman s point", "kilima njaro"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Mount Kilimanjaro", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:09.715811Z"}
{"question_id": "tqa_rc_validation_12", "question": "Which volcano in Tanzania is the highest mountain in Africa?", "ground_truth": ["Kilimanjaro", "Mawensi", "Mt. Kilimanjaro", "Kibo (volcano)", "Mount killimanjaro", "Highest mountain in Africa", "Kilimanjaro Massif", "Stella Point", "Kilimandjaro", "Kilimonjaro", "Gilman's Point", "Killimanjaro", "Kilima-Njaro", "Kiliminjaro", "Mt Kilimanjaro", "Kilimanjaro Mountain", "Mount Kilimanjaro", "Mawenzi", "Uhuru Peak", "Kilimanjiro", "Kaiser-Wilhelm-Spitze", "Mt Kilamanjaro", "Mount Kiliminjaro", "Mount Kilimandjaro", "Mount Kilamanjaro", "Tussock Grassland (Tanzania)", "Kilamanjaro", "tussock grassland tanzania", "kibo volcano", "kaiser wilhelm spitze", "gilman s point", "kilima njaro"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Mount Kilimanjaro", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:11.352484Z"}
{"question_id": "tqa_rc_validation_12", "question": "Which volcano in Tanzania is the highest mountain in Africa?", "ground_truth": ["Kilimanjaro", "Mawensi", "Mt. Kilimanjaro", "Kibo (volcano)", "Mount killimanjaro", "Highest mountain in Africa", "Kilimanjaro Massif", "Stella Point", "Kilimandjaro", "Kilimonjaro", "Gilman's Point", "Killimanjaro", "Kilima-Njaro", "Kiliminjaro", "Mt Kilimanjaro", "Kilimanjaro Mountain", "Mount Kilimanjaro", "Mawenzi", "Uhuru Peak", "Kilimanjiro", "Kaiser-Wilhelm-Spitze", "Mt Kilamanjaro", "Mount Kiliminjaro", "Mount Kilimandjaro", "Mount Kilamanjaro", "Tussock Grassland (Tanzania)", "Kilamanjaro", "tussock grassland tanzania", "kibo volcano", "kaiser wilhelm spitze", "gilman s point", "kilima njaro"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Mount Kilimanjaro", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:11.555660Z"}
{"question_id": "tqa_rc_validation_12", "question": "Which volcano in Tanzania is the highest mountain in Africa?", "ground_truth": ["Kilimanjaro", "Mawensi", "Mt. Kilimanjaro", "Kibo (volcano)", "Mount killimanjaro", "Highest mountain in Africa", "Kilimanjaro Massif", "Stella Point", "Kilimandjaro", "Kilimonjaro", "Gilman's Point", "Killimanjaro", "Kilima-Njaro", "Kiliminjaro", "Mt Kilimanjaro", "Kilimanjaro Mountain", "Mount Kilimanjaro", "Mawenzi", "Uhuru Peak", "Kilimanjiro", "Kaiser-Wilhelm-Spitze", "Mt Kilamanjaro", "Mount Kiliminjaro", "Mount Kilimandjaro", "Mount Kilamanjaro", "Tussock Grassland (Tanzania)", "Kilamanjaro", "tussock grassland tanzania", "kibo volcano", "kaiser wilhelm spitze", "gilman s point", "kilima njaro"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Mount Kilimanjaro", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:12.734931Z"}
{"question_id": "tqa_rc_validation_12", "question": "Which volcano in Tanzania is the highest mountain in Africa?", "ground_truth": ["Kilimanjaro", "Mawensi", "Mt. Kilimanjaro", "Kibo (volcano)", "Mount killimanjaro", "Highest mountain in Africa", "Kilimanjaro Massif", "Stella Point", "Kilimandjaro", "Kilimonjaro", "Gilman's Point", "Killimanjaro", "Kilima-Njaro", "Kiliminjaro", "Mt Kilimanjaro", "Kilimanjaro Mountain", "Mount Kilimanjaro", "Mawenzi", "Uhuru Peak", "Kilimanjiro", "Kaiser-Wilhelm-Spitze", "Mt Kilamanjaro", "Mount Kiliminjaro", "Mount Kilimandjaro", "Mount Kilamanjaro", "Tussock Grassland (Tanzania)", "Kilamanjaro", "tussock grassland tanzania", "kibo volcano", "kaiser wilhelm spitze", "gilman s point", "kilima njaro"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Mount Kilimanjaro", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:13.523054Z"}
{"question_id": "tqa_rc_validation_13", "question": "The flag of Libya is a plain rectangle of which color?", "ground_truth": ["Green", "Greenishly", "Avacado (color)", "Green (color)", "Rgb(0, 255, 0)", "Greenishness", "The colour green", "Greenest", "List of terms associated with the color green", "The color green", "Pastel green", "(0, 255, 0)", "Green (colour)", "Greenness", "color green", "0 255 0", "green color", "rgb 0 255 0", "avacado color", "list of terms associated with color green", "colour green", "green colour"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Green", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:14.419299Z"}
{"question_id": "tqa_rc_validation_13", "question": "The flag of Libya is a plain rectangle of which color?", "ground_truth": ["Green", "Greenishly", "Avacado (color)", "Green (color)", "Rgb(0, 255, 0)", "Greenishness", "The colour green", "Greenest", "List of terms associated with the color green", "The color green", "Pastel green", "(0, 255, 0)", "Green (colour)", "Greenness", "color green", "0 255 0", "green color", "rgb 0 255 0", "avacado color", "list of terms associated with color green", "colour green", "green colour"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Green", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:15.862891Z"}
{"question_id": "tqa_rc_validation_13", "question": "The flag of Libya is a plain rectangle of which color?", "ground_truth": ["Green", "Greenishly", "Avacado (color)", "Green (color)", "Rgb(0, 255, 0)", "Greenishness", "The colour green", "Greenest", "List of terms associated with the color green", "The color green", "Pastel green", "(0, 255, 0)", "Green (colour)", "Greenness", "color green", "0 255 0", "green color", "rgb 0 255 0", "avacado color", "list of terms associated with color green", "colour green", "green colour"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Green", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:16.128904Z"}
{"question_id": "tqa_rc_validation_13", "question": "The flag of Libya is a plain rectangle of which color?", "ground_truth": ["Green", "Greenishly", "Avacado (color)", "Green (color)", "Rgb(0, 255, 0)", "Greenishness", "The colour green", "Greenest", "List of terms associated with the color green", "The color green", "Pastel green", "(0, 255, 0)", "Green (colour)", "Greenness", "color green", "0 255 0", "green color", "rgb 0 255 0", "avacado color", "list of terms associated with color green", "colour green", "green colour"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Green", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:17.217244Z"}
{"question_id": "tqa_rc_validation_13", "question": "The flag of Libya is a plain rectangle of which color?", "ground_truth": ["Green", "Greenishly", "Avacado (color)", "Green (color)", "Rgb(0, 255, 0)", "Greenishness", "The colour green", "Greenest", "List of terms associated with the color green", "The color green", "Pastel green", "(0, 255, 0)", "Green (colour)", "Greenness", "color green", "0 255 0", "green color", "rgb 0 255 0", "avacado color", "list of terms associated with color green", "colour green", "green colour"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Green", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:17.876224Z"}
{"question_id": "tqa_rc_validation_14", "question": "Of which African country is Niamey the capital?", "ground_truth": ["Niger", "Niger Republic", "Nigerois", "Republic Of Niger", "The Republic of Niger", "Nigerien", "Niger (country)", "République du Niger", "Republique du Niger", "ISO 3166-1:NE", "NG-NI", "iso 3166 1 ne", "niger country", "ng ni"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Niger", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:18.673991Z"}
{"question_id": "tqa_rc_validation_14", "question": "Of which African country is Niamey the capital?", "ground_truth": ["Niger", "Niger Republic", "Nigerois", "Republic Of Niger", "The Republic of Niger", "Nigerien", "Niger (country)", "République du Niger", "Republique du Niger", "ISO 3166-1:NE", "NG-NI", "iso 3166 1 ne", "niger country", "ng ni"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Niger", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:20.420595Z"}
{"question_id": "tqa_rc_validation_14", "question": "Of which African country is Niamey the capital?", "ground_truth": ["Niger", "Niger Republic", "Nigerois", "Republic Of Niger", "The Republic of Niger", "Nigerien", "Niger (country)", "République du Niger", "Republique du Niger", "ISO 3166-1:NE", "NG-NI", "iso 3166 1 ne", "niger country", "ng ni"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Niger", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:20.563439Z"}
{"question_id": "tqa_rc_validation_14", "question": "Of which African country is Niamey the capital?", "ground_truth": ["Niger", "Niger Republic", "Nigerois", "Republic Of Niger", "The Republic of Niger", "Nigerien", "Niger (country)", "République du Niger", "Republique du Niger", "ISO 3166-1:NE", "NG-NI", "iso 3166 1 ne", "niger country", "ng ni"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Niger", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:21.727239Z"}
{"question_id": "tqa_rc_validation_14", "question": "Of which African country is Niamey the capital?", "ground_truth": ["Niger", "Niger Republic", "Nigerois", "Republic Of Niger", "The Republic of Niger", "Nigerien", "Niger (country)", "République du Niger", "Republique du Niger", "ISO 3166-1:NE", "NG-NI", "iso 3166 1 ne", "niger country", "ng ni"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Niger", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:45:22.560926Z"}
{"question_id": "tqa_rc_validation_15", "question": "Who was the director of the CIA from 1976-81?", "ground_truth": ["George Bush", "Goerge Bush", "George W. Bush (disambiguation)", "GeorgeBush", "George Bushe", "Georg bush", "G Bush", "George Bush, President", "George Bush (disambiguation)", "Bush, George", "Geroge Bush", "bush george", "george w bush disambiguation", "george bush president", "george bush disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Stansfield Turner", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:45:40.498210Z"}
{"question_id": "tqa_rc_validation_15", "question": "Who was the director of the CIA from 1976-81?", "ground_truth": ["George Bush", "Goerge Bush", "George W. Bush (disambiguation)", "GeorgeBush", "George Bushe", "Georg bush", "G Bush", "George Bush, President", "George Bush (disambiguation)", "Bush, George", "Geroge Bush", "bush george", "george w bush disambiguation", "george bush president", "george bush disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "George H", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["George H", "George H", "George H", "George H", "George H", "George H", "George H", "George H", "George H", "George H"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:46:13.342978Z"}
{"question_id": "tqa_rc_validation_15", "question": "Who was the director of the CIA from 1976-81?", "ground_truth": ["George Bush", "Goerge Bush", "George W. Bush (disambiguation)", "GeorgeBush", "George Bushe", "Georg bush", "G Bush", "George Bush, President", "George Bush (disambiguation)", "Bush, George", "Geroge Bush", "bush george", "george w bush disambiguation", "george bush president", "george bush disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Stansfield Turner", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Admiral Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:46:26.333453Z"}
{"question_id": "tqa_rc_validation_15", "question": "Who was the director of the CIA from 1976-81?", "ground_truth": ["George Bush", "Goerge Bush", "George W. Bush (disambiguation)", "GeorgeBush", "George Bushe", "Georg bush", "G Bush", "George Bush, President", "George Bush (disambiguation)", "Bush, George", "Geroge Bush", "bush george", "george w bush disambiguation", "george bush president", "george bush disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "George H", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["George H", "George H", "George H", "George H", "George H", "Stansfield Turner", "George H", "Stansfield Turner", "George H", "George H"], "equivalence_results": ["same", "same", "same", "same", "same", "different", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:46:52.349246Z"}
{"question_id": "tqa_rc_validation_15", "question": "Who was the director of the CIA from 1976-81?", "ground_truth": ["George Bush", "Goerge Bush", "George W. Bush (disambiguation)", "GeorgeBush", "George Bushe", "Georg bush", "G Bush", "George Bush, President", "George Bush (disambiguation)", "Bush, George", "Geroge Bush", "bush george", "george w bush disambiguation", "george bush president", "george bush disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Stansfield Turner", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner", "Stansfield Turner"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:47:08.261707Z"}
{"question_id": "tqa_rc_validation_16", "question": "Which musical featured the song The Street Where You Live?", "ground_truth": ["My Fair Lady", "My Fair Lady (2010 film)", "Enry Iggins", "Why Can't the English%3F", "My Fair Lady (upcoming film)", "My Fair Lady (musical)", "I'm an Ordinary Man", "My Fair Lady (2014 film)", "My Fair Lady (2012 film)", "My Fair Lady (2015 film)", "my fair lady musical", "my fair lady 2010 film", "why can t english 3f", "my fair lady upcoming film", "my fair lady 2012 film", "my fair lady 2014 film", "my fair lady 2015 film", "i m ordinary man"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "My Fair Lady", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:09.067128Z"}
{"question_id": "tqa_rc_validation_16", "question": "Which musical featured the song The Street Where You Live?", "ground_truth": ["My Fair Lady", "My Fair Lady (2010 film)", "Enry Iggins", "Why Can't the English%3F", "My Fair Lady (upcoming film)", "My Fair Lady (musical)", "I'm an Ordinary Man", "My Fair Lady (2014 film)", "My Fair Lady (2012 film)", "My Fair Lady (2015 film)", "my fair lady musical", "my fair lady 2010 film", "why can t english 3f", "my fair lady upcoming film", "my fair lady 2012 film", "my fair lady 2014 film", "my fair lady 2015 film", "i m ordinary man"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "My Fair Lady", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:10.787199Z"}
{"question_id": "tqa_rc_validation_16", "question": "Which musical featured the song The Street Where You Live?", "ground_truth": ["My Fair Lady", "My Fair Lady (2010 film)", "Enry Iggins", "Why Can't the English%3F", "My Fair Lady (upcoming film)", "My Fair Lady (musical)", "I'm an Ordinary Man", "My Fair Lady (2014 film)", "My Fair Lady (2012 film)", "My Fair Lady (2015 film)", "my fair lady musical", "my fair lady 2010 film", "why can t english 3f", "my fair lady upcoming film", "my fair lady 2012 film", "my fair lady 2014 film", "my fair lady 2015 film", "i m ordinary man"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "My Fair Lady", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:11.001773Z"}
{"question_id": "tqa_rc_validation_16", "question": "Which musical featured the song The Street Where You Live?", "ground_truth": ["My Fair Lady", "My Fair Lady (2010 film)", "Enry Iggins", "Why Can't the English%3F", "My Fair Lady (upcoming film)", "My Fair Lady (musical)", "I'm an Ordinary Man", "My Fair Lady (2014 film)", "My Fair Lady (2012 film)", "My Fair Lady (2015 film)", "my fair lady musical", "my fair lady 2010 film", "why can t english 3f", "my fair lady upcoming film", "my fair lady 2012 film", "my fair lady 2014 film", "my fair lady 2015 film", "i m ordinary man"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "My Fair Lady", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:12.109282Z"}
{"question_id": "tqa_rc_validation_16", "question": "Which musical featured the song The Street Where You Live?", "ground_truth": ["My Fair Lady", "My Fair Lady (2010 film)", "Enry Iggins", "Why Can't the English%3F", "My Fair Lady (upcoming film)", "My Fair Lady (musical)", "I'm an Ordinary Man", "My Fair Lady (2014 film)", "My Fair Lady (2012 film)", "My Fair Lady (2015 film)", "my fair lady musical", "my fair lady 2010 film", "why can t english 3f", "my fair lady upcoming film", "my fair lady 2012 film", "my fair lady 2014 film", "my fair lady 2015 film", "i m ordinary man"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "My Fair Lady", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:12.811718Z"}
{"question_id": "tqa_rc_validation_17", "question": "\"Who was the target of the failed \"\"Bomb Plot\"\" of 1944?\"", "ground_truth": ["Hitler", "Hitlerian", "Adolph Schicklgruber", "HitlerAdolf", "Hitler's medical health", "Adolf Hitle", "Hitlar", "Adolph Hiedler", "Adolf Hiedler", "Adolph Hittler", "Day of Potsdam", "Adolpf Hitler", "Adolf Hister", "Adolf Hitlier", "Adolph Hitler's health", "Hitler's health", "Hitlers", "Aldof Hilter", "Hitler, Adolph", "History of Adolf Hitler", "Hitler,Adolph", "Adolph Hiter", "Adolf Hittler", "Herr Hitler", "Hitler,Adolf", "Adolf Schicklegruber", "Adolf hitler", "Adlof hitler", "Adolph Schickelgruber", "Hitler Adolf", "Hitlers medical health", "HitlerAdolph", "Adolph Schicklegruber", "Adolf Hiler", "Adolf Hitler's medical condition", "Hittler", "Adolf Schickelgruber", "Hitler's", "Hitler, adolf", "Nazi leader", "Herr Wolf", "Adolph Hitler's medical health", "Adolph Hitler", "Adolf Hitler's health", "Adolf Schicklgruber", "AdolphHitler", "Adolf Hilter", "Health of Adolf Hitler", "Adolf Hitler's medical health", "Hitler Adolph", "AdolfHitler", "Hitlet", "Adoff Hitler", "Adolfus Hitler", "hitler s medical health", "adolf hitler s health", "hitler s", "adolf hitler s medical health", "hitler s health", "adolf hitler s medical condition", "adolph hitler s medical health", "adolph hitler s health"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Adolf Hitler", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:13.707158Z"}
{"question_id": "tqa_rc_validation_17", "question": "\"Who was the target of the failed \"\"Bomb Plot\"\" of 1944?\"", "ground_truth": ["Hitler", "Hitlerian", "Adolph Schicklgruber", "HitlerAdolf", "Hitler's medical health", "Adolf Hitle", "Hitlar", "Adolph Hiedler", "Adolf Hiedler", "Adolph Hittler", "Day of Potsdam", "Adolpf Hitler", "Adolf Hister", "Adolf Hitlier", "Adolph Hitler's health", "Hitler's health", "Hitlers", "Aldof Hilter", "Hitler, Adolph", "History of Adolf Hitler", "Hitler,Adolph", "Adolph Hiter", "Adolf Hittler", "Herr Hitler", "Hitler,Adolf", "Adolf Schicklegruber", "Adolf hitler", "Adlof hitler", "Adolph Schickelgruber", "Hitler Adolf", "Hitlers medical health", "HitlerAdolph", "Adolph Schicklegruber", "Adolf Hiler", "Adolf Hitler's medical condition", "Hittler", "Adolf Schickelgruber", "Hitler's", "Hitler, adolf", "Nazi leader", "Herr Wolf", "Adolph Hitler's medical health", "Adolph Hitler", "Adolf Hitler's health", "Adolf Schicklgruber", "AdolphHitler", "Adolf Hilter", "Health of Adolf Hitler", "Adolf Hitler's medical health", "Hitler Adolph", "AdolfHitler", "Hitlet", "Adoff Hitler", "Adolfus Hitler", "hitler s medical health", "adolf hitler s health", "hitler s", "adolf hitler s medical health", "hitler s health", "adolf hitler s medical condition", "adolph hitler s medical health", "adolph hitler s health"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Adolf Hitler", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:15.443523Z"}
{"question_id": "tqa_rc_validation_17", "question": "\"Who was the target of the failed \"\"Bomb Plot\"\" of 1944?\"", "ground_truth": ["Hitler", "Hitlerian", "Adolph Schicklgruber", "HitlerAdolf", "Hitler's medical health", "Adolf Hitle", "Hitlar", "Adolph Hiedler", "Adolf Hiedler", "Adolph Hittler", "Day of Potsdam", "Adolpf Hitler", "Adolf Hister", "Adolf Hitlier", "Adolph Hitler's health", "Hitler's health", "Hitlers", "Aldof Hilter", "Hitler, Adolph", "History of Adolf Hitler", "Hitler,Adolph", "Adolph Hiter", "Adolf Hittler", "Herr Hitler", "Hitler,Adolf", "Adolf Schicklegruber", "Adolf hitler", "Adlof hitler", "Adolph Schickelgruber", "Hitler Adolf", "Hitlers medical health", "HitlerAdolph", "Adolph Schicklegruber", "Adolf Hiler", "Adolf Hitler's medical condition", "Hittler", "Adolf Schickelgruber", "Hitler's", "Hitler, adolf", "Nazi leader", "Herr Wolf", "Adolph Hitler's medical health", "Adolph Hitler", "Adolf Hitler's health", "Adolf Schicklgruber", "AdolphHitler", "Adolf Hilter", "Health of Adolf Hitler", "Adolf Hitler's medical health", "Hitler Adolph", "AdolfHitler", "Hitlet", "Adoff Hitler", "Adolfus Hitler", "hitler s medical health", "adolf hitler s health", "hitler s", "adolf hitler s medical health", "hitler s health", "adolf hitler s medical condition", "adolph hitler s medical health", "adolph hitler s health"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Winston Churchill", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Winston Churchill", "Winston Churchill", "Winston Churchill", "Adolf Hitler", "Winston Churchill", "Hitler", "Winston Churchill", "Winston Churchill", "Winston Churchill", "Winston Churchill"], "equivalence_results": ["same", "same", "same", "different", "same", "different", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:47:25.694984Z"}
{"question_id": "tqa_rc_validation_0", "question": "Who was the man behind The Chipmunks?", "ground_truth": ["David Seville"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Ross Bagdasarian Sr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:47:26.472102Z"}
{"question_id": "tqa_rc_validation_17", "question": "\"Who was the target of the failed \"\"Bomb Plot\"\" of 1944?\"", "ground_truth": ["Hitler", "Hitlerian", "Adolph Schicklgruber", "HitlerAdolf", "Hitler's medical health", "Adolf Hitle", "Hitlar", "Adolph Hiedler", "Adolf Hiedler", "Adolph Hittler", "Day of Potsdam", "Adolpf Hitler", "Adolf Hister", "Adolf Hitlier", "Adolph Hitler's health", "Hitler's health", "Hitlers", "Aldof Hilter", "Hitler, Adolph", "History of Adolf Hitler", "Hitler,Adolph", "Adolph Hiter", "Adolf Hittler", "Herr Hitler", "Hitler,Adolf", "Adolf Schicklegruber", "Adolf hitler", "Adlof hitler", "Adolph Schickelgruber", "Hitler Adolf", "Hitlers medical health", "HitlerAdolph", "Adolph Schicklegruber", "Adolf Hiler", "Adolf Hitler's medical condition", "Hittler", "Adolf Schickelgruber", "Hitler's", "Hitler, adolf", "Nazi leader", "Herr Wolf", "Adolph Hitler's medical health", "Adolph Hitler", "Adolf Hitler's health", "Adolf Schicklgruber", "AdolphHitler", "Adolf Hilter", "Health of Adolf Hitler", "Adolf Hitler's medical health", "Hitler Adolph", "AdolfHitler", "Hitlet", "Adoff Hitler", "Adolfus Hitler", "hitler s medical health", "adolf hitler s health", "hitler s", "adolf hitler s medical health", "hitler s health", "adolf hitler s medical condition", "adolph hitler s medical health", "adolph hitler s health"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Adolf Hitler", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:26.945468Z"}
{"question_id": "tqa_rc_validation_17", "question": "\"Who was the target of the failed \"\"Bomb Plot\"\" of 1944?\"", "ground_truth": ["Hitler", "Hitlerian", "Adolph Schicklgruber", "HitlerAdolf", "Hitler's medical health", "Adolf Hitle", "Hitlar", "Adolph Hiedler", "Adolf Hiedler", "Adolph Hittler", "Day of Potsdam", "Adolpf Hitler", "Adolf Hister", "Adolf Hitlier", "Adolph Hitler's health", "Hitler's health", "Hitlers", "Aldof Hilter", "Hitler, Adolph", "History of Adolf Hitler", "Hitler,Adolph", "Adolph Hiter", "Adolf Hittler", "Herr Hitler", "Hitler,Adolf", "Adolf Schicklegruber", "Adolf hitler", "Adlof hitler", "Adolph Schickelgruber", "Hitler Adolf", "Hitlers medical health", "HitlerAdolph", "Adolph Schicklegruber", "Adolf Hiler", "Adolf Hitler's medical condition", "Hittler", "Adolf Schickelgruber", "Hitler's", "Hitler, adolf", "Nazi leader", "Herr Wolf", "Adolph Hitler's medical health", "Adolph Hitler", "Adolf Hitler's health", "Adolf Schicklgruber", "AdolphHitler", "Adolf Hilter", "Health of Adolf Hitler", "Adolf Hitler's medical health", "Hitler Adolph", "AdolfHitler", "Hitlet", "Adoff Hitler", "Adolfus Hitler", "hitler s medical health", "adolf hitler s health", "hitler s", "adolf hitler s medical health", "hitler s health", "adolf hitler s medical condition", "adolph hitler s medical health", "adolph hitler s health"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Adolf Hitler", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:27.768561Z"}
{"question_id": "tqa_rc_validation_18", "question": "Who had an 80s No 1 hit with Hold On To The Nights?", "ground_truth": ["Richard Marx", "Richard Noel Marx"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Richard Marx", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:28.644773Z"}
{"question_id": "tqa_rc_validation_18", "question": "Who had an 80s No 1 hit with Hold On To The Nights?", "ground_truth": ["Richard Marx", "Richard Noel Marx"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Richard Marx", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:30.352488Z"}
{"question_id": "tqa_rc_validation_18", "question": "Who had an 80s No 1 hit with Hold On To The Nights?", "ground_truth": ["Richard Marx", "Richard Noel Marx"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Richard Marx", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:30.599479Z"}
{"question_id": "tqa_rc_validation_18", "question": "Who had an 80s No 1 hit with Hold On To The Nights?", "ground_truth": ["Richard Marx", "Richard Noel Marx"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Richard Marx", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:31.688341Z"}
{"question_id": "tqa_rc_validation_18", "question": "Who had an 80s No 1 hit with Hold On To The Nights?", "ground_truth": ["Richard Marx", "Richard Noel Marx"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Dennis DeYoung", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Reid Kennedy", "Richard Marx", "Richard Marx", "Diana Ross did have a number one hit in the 80s with the song \"Hold Me,\" but the song \"Hold On To The Nights\" is actually a hit by 80s band  Reckless", "Dennis DeYoung", "Dennis DeYoung", "Dennis DeYoung did not have a No 1 hit with that title, but,  in 1984,  a No 1 hit single \"Hold On to the Nights\" was by Richard Marx", "Richard Marx", "Richard Marx", "Diana Ross is not correct this one is actually Richard Marx"], "equivalence_results": ["different", "different", "different", "different", "same", "same", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:47:49.356744Z"}
{"question_id": "tqa_rc_validation_19", "question": "Who directed the classic 30s western Stagecoach?", "ground_truth": ["John Ford", "John Ford (1895-1973)", "Sean O'Feeney", "John Ford (film director)", "Ford, John (1895-1973)", "Argosy Pictures", "John Ford statue", "John Martin O'Feeney", "John Ford (director)", "Cavalry trilogy", "John O'Feeney", "Sean Aloysius O'Feeney", "Ford, John", "john ford 1895 1973", "sean o feeney", "ford john 1895 1973", "ford john", "john o feeney", "sean aloysius o feeney", "john ford film director", "john ford director", "john martin o feeney"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "John Ford", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:50.297077Z"}
{"question_id": "tqa_rc_validation_19", "question": "Who directed the classic 30s western Stagecoach?", "ground_truth": ["John Ford", "John Ford (1895-1973)", "Sean O'Feeney", "John Ford (film director)", "Ford, John (1895-1973)", "Argosy Pictures", "John Ford statue", "John Martin O'Feeney", "John Ford (director)", "Cavalry trilogy", "John O'Feeney", "Sean Aloysius O'Feeney", "Ford, John", "john ford 1895 1973", "sean o feeney", "ford john 1895 1973", "ford john", "john o feeney", "sean aloysius o feeney", "john ford film director", "john ford director", "john martin o feeney"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "John Ford", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:52.012922Z"}
{"question_id": "tqa_rc_validation_19", "question": "Who directed the classic 30s western Stagecoach?", "ground_truth": ["John Ford", "John Ford (1895-1973)", "Sean O'Feeney", "John Ford (film director)", "Ford, John (1895-1973)", "Argosy Pictures", "John Ford statue", "John Martin O'Feeney", "John Ford (director)", "Cavalry trilogy", "John O'Feeney", "Sean Aloysius O'Feeney", "Ford, John", "john ford 1895 1973", "sean o feeney", "ford john 1895 1973", "ford john", "john o feeney", "sean aloysius o feeney", "john ford film director", "john ford director", "john martin o feeney"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "John Ford", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:52.213591Z"}
{"question_id": "tqa_rc_validation_19", "question": "Who directed the classic 30s western Stagecoach?", "ground_truth": ["John Ford", "John Ford (1895-1973)", "Sean O'Feeney", "John Ford (film director)", "Ford, John (1895-1973)", "Argosy Pictures", "John Ford statue", "John Martin O'Feeney", "John Ford (director)", "Cavalry trilogy", "John O'Feeney", "Sean Aloysius O'Feeney", "Ford, John", "john ford 1895 1973", "sean o feeney", "ford john 1895 1973", "ford john", "john o feeney", "sean aloysius o feeney", "john ford film director", "john ford director", "john martin o feeney"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "John Ford", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:53.409710Z"}
{"question_id": "tqa_rc_validation_19", "question": "Who directed the classic 30s western Stagecoach?", "ground_truth": ["John Ford", "John Ford (1895-1973)", "Sean O'Feeney", "John Ford (film director)", "Ford, John (1895-1973)", "Argosy Pictures", "John Ford statue", "John Martin O'Feeney", "John Ford (director)", "Cavalry trilogy", "John O'Feeney", "Sean Aloysius O'Feeney", "Ford, John", "john ford 1895 1973", "sean o feeney", "ford john 1895 1973", "ford john", "john o feeney", "sean aloysius o feeney", "john ford film director", "john ford director", "john martin o feeney"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "John Ford", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:54.139129Z"}
{"question_id": "tqa_rc_validation_20", "question": "Dave Gilmore and Roger Waters were in which rock group?", "ground_truth": ["Pink Floyd", "Grey Floyd", "Pink Floyd trivia", "The Screaming Ab Dabs", "Pink flowd", "The Meggadeaths", "The Architectural Abdabs", "Pink Flod", "The Pink Floyd", "Notable or frequent contributors to pink floyd", "The Tea Set", "Pinkfloyd", "Pi5", "Pink floid", "Pink Floyd (band)", "The T Set", "Screaming abdabs", "The Megadeaths", "Pik floyd", "The Pink Floyd Sound", "The T-Set", "The Screaming Abdabs", "Clive Metcalfe", "Meggadeaths", "megadeaths", "pink floyd band", "screaming ab dabs", "architectural abdabs", "pink floyd sound", "tea set", "t set"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Pink Floyd", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:54.902022Z"}
{"question_id": "tqa_rc_validation_20", "question": "Dave Gilmore and Roger Waters were in which rock group?", "ground_truth": ["Pink Floyd", "Grey Floyd", "Pink Floyd trivia", "The Screaming Ab Dabs", "Pink flowd", "The Meggadeaths", "The Architectural Abdabs", "Pink Flod", "The Pink Floyd", "Notable or frequent contributors to pink floyd", "The Tea Set", "Pinkfloyd", "Pi5", "Pink floid", "Pink Floyd (band)", "The T Set", "Screaming abdabs", "The Megadeaths", "Pik floyd", "The Pink Floyd Sound", "The T-Set", "The Screaming Abdabs", "Clive Metcalfe", "Meggadeaths", "megadeaths", "pink floyd band", "screaming ab dabs", "architectural abdabs", "pink floyd sound", "tea set", "t set"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Pink Floyd", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:56.865693Z"}
{"question_id": "tqa_rc_validation_20", "question": "Dave Gilmore and Roger Waters were in which rock group?", "ground_truth": ["Pink Floyd", "Grey Floyd", "Pink Floyd trivia", "The Screaming Ab Dabs", "Pink flowd", "The Meggadeaths", "The Architectural Abdabs", "Pink Flod", "The Pink Floyd", "Notable or frequent contributors to pink floyd", "The Tea Set", "Pinkfloyd", "Pi5", "Pink floid", "Pink Floyd (band)", "The T Set", "Screaming abdabs", "The Megadeaths", "Pik floyd", "The Pink Floyd Sound", "The T-Set", "The Screaming Abdabs", "Clive Metcalfe", "Meggadeaths", "megadeaths", "pink floyd band", "screaming ab dabs", "architectural abdabs", "pink floyd sound", "tea set", "t set"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Pink Floyd", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:57.015954Z"}
{"question_id": "tqa_rc_validation_20", "question": "Dave Gilmore and Roger Waters were in which rock group?", "ground_truth": ["Pink Floyd", "Grey Floyd", "Pink Floyd trivia", "The Screaming Ab Dabs", "Pink flowd", "The Meggadeaths", "The Architectural Abdabs", "Pink Flod", "The Pink Floyd", "Notable or frequent contributors to pink floyd", "The Tea Set", "Pinkfloyd", "Pi5", "Pink floid", "Pink Floyd (band)", "The T Set", "Screaming abdabs", "The Megadeaths", "Pik floyd", "The Pink Floyd Sound", "The T-Set", "The Screaming Abdabs", "Clive Metcalfe", "Meggadeaths", "megadeaths", "pink floyd band", "screaming ab dabs", "architectural abdabs", "pink floyd sound", "tea set", "t set"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Pink Floyd", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:58.136689Z"}
{"question_id": "tqa_rc_validation_20", "question": "Dave Gilmore and Roger Waters were in which rock group?", "ground_truth": ["Pink Floyd", "Grey Floyd", "Pink Floyd trivia", "The Screaming Ab Dabs", "Pink flowd", "The Meggadeaths", "The Architectural Abdabs", "Pink Flod", "The Pink Floyd", "Notable or frequent contributors to pink floyd", "The Tea Set", "Pinkfloyd", "Pi5", "Pink floid", "Pink Floyd (band)", "The T Set", "Screaming abdabs", "The Megadeaths", "Pik floyd", "The Pink Floyd Sound", "The T-Set", "The Screaming Abdabs", "Clive Metcalfe", "Meggadeaths", "megadeaths", "pink floyd band", "screaming ab dabs", "architectural abdabs", "pink floyd sound", "tea set", "t set"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Pink Floyd", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:47:58.950876Z"}
{"question_id": "tqa_rc_validation_21", "question": "Which highway was Revisited in a classic 60s album by Bob Dylan?", "ground_truth": ["61", "sixty-one", "sixty one"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Highway 61", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:48:15.754898Z"}
{"question_id": "tqa_rc_validation_21", "question": "Which highway was Revisited in a classic 60s album by Bob Dylan?", "ground_truth": ["61", "sixty-one", "sixty one"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Highway 61", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:48:42.145468Z"}
{"question_id": "tqa_rc_validation_21", "question": "Which highway was Revisited in a classic 60s album by Bob Dylan?", "ground_truth": ["61", "sixty-one", "sixty one"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Highway 61", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:48:51.945411Z"}
{"question_id": "tqa_rc_validation_21", "question": "Which highway was Revisited in a classic 60s album by Bob Dylan?", "ground_truth": ["61", "sixty-one", "sixty one"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Highway 61", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:49:13.619432Z"}
{"question_id": "tqa_rc_validation_21", "question": "Which highway was Revisited in a classic 60s album by Bob Dylan?", "ground_truth": ["61", "sixty-one", "sixty one"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Highway 61", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Highway 61", "Highway 61", "Highway 61", "U", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61", "Highway 61"], "equivalence_results": ["same", "same", "same", "different", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:49:30.062454Z"}
{"question_id": "tqa_rc_validation_22", "question": "Which was the only eastern bloc country to participate in the 1984 LA Olympics?", "ground_truth": ["Rumania", "ISO 3166-1:RO", "Romanian state", "ROMANIA", "Roumania", "Etymology of Romania", "Romainia", "Romînia", "North Danubian region", "Carpathian Danubian space", "ROU", "România", "Roumanie", "Country ROM", "Rromania", "Republic of Romania", "RO (country)", "Rumänien", "Danubian-Carpathian Area", "Austro-Hungarian Empire (Romania)", "Rumunia", "danubian carpathian area", "austro hungarian empire romania", "iso 3166 1 ro", "ro country"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Romania", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:49:31.199270Z"}
{"question_id": "tqa_rc_validation_22", "question": "Which was the only eastern bloc country to participate in the 1984 LA Olympics?", "ground_truth": ["Rumania", "ISO 3166-1:RO", "Romanian state", "ROMANIA", "Roumania", "Etymology of Romania", "Romainia", "Romînia", "North Danubian region", "Carpathian Danubian space", "ROU", "România", "Roumanie", "Country ROM", "Rromania", "Republic of Romania", "RO (country)", "Rumänien", "Danubian-Carpathian Area", "Austro-Hungarian Empire (Romania)", "Rumunia", "danubian carpathian area", "austro hungarian empire romania", "iso 3166 1 ro", "ro country"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Romania", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:49:32.746941Z"}
{"question_id": "tqa_rc_validation_22", "question": "Which was the only eastern bloc country to participate in the 1984 LA Olympics?", "ground_truth": ["Rumania", "ISO 3166-1:RO", "Romanian state", "ROMANIA", "Roumania", "Etymology of Romania", "Romainia", "Romînia", "North Danubian region", "Carpathian Danubian space", "ROU", "România", "Roumanie", "Country ROM", "Rromania", "Republic of Romania", "RO (country)", "Rumänien", "Danubian-Carpathian Area", "Austro-Hungarian Empire (Romania)", "Rumunia", "danubian carpathian area", "austro hungarian empire romania", "iso 3166 1 ro", "ro country"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Romania", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:49:33.032302Z"}
{"question_id": "tqa_rc_validation_22", "question": "Which was the only eastern bloc country to participate in the 1984 LA Olympics?", "ground_truth": ["Rumania", "ISO 3166-1:RO", "Romanian state", "ROMANIA", "Roumania", "Etymology of Romania", "Romainia", "Romînia", "North Danubian region", "Carpathian Danubian space", "ROU", "România", "Roumanie", "Country ROM", "Rromania", "Republic of Romania", "RO (country)", "Rumänien", "Danubian-Carpathian Area", "Austro-Hungarian Empire (Romania)", "Rumunia", "danubian carpathian area", "austro hungarian empire romania", "iso 3166 1 ro", "ro country"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Romania", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:49:35.104145Z"}
{"question_id": "tqa_rc_validation_22", "question": "Which was the only eastern bloc country to participate in the 1984 LA Olympics?", "ground_truth": ["Rumania", "ISO 3166-1:RO", "Romanian state", "ROMANIA", "Roumania", "Etymology of Romania", "Romainia", "Romînia", "North Danubian region", "Carpathian Danubian space", "ROU", "România", "Roumanie", "Country ROM", "Rromania", "Republic of Romania", "RO (country)", "Rumänien", "Danubian-Carpathian Area", "Austro-Hungarian Empire (Romania)", "Rumunia", "danubian carpathian area", "austro hungarian empire romania", "iso 3166 1 ro", "ro country"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Romania", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:49:35.956174Z"}
{"question_id": "tqa_rc_validation_23", "question": "Which 90s sci fi series with James Belushi was based on Bruce Wagner's comic strip of the same name?", "ground_truth": ["Wild Palms"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Flash", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Last Precinct", "The Wild West", "The Flash", "The Last Precinct", "The Flash", "The Flash", "The Wild West", "The Last Resort", "The Last Resort", "The Flash"], "equivalence_results": ["different", "different", "same", "different", "same", "same", "different", "different", "different", "same"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:49:53.360539Z"}
{"question_id": "tqa_rc_validation_23", "question": "Which 90s sci fi series with James Belushi was based on Bruce Wagner's comic strip of the same name?", "ground_truth": ["Wild Palms"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Wild Palms", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:49:54.351866Z"}
{"question_id": "tqa_rc_validation_23", "question": "Which 90s sci fi series with James Belushi was based on Bruce Wagner's comic strip of the same name?", "ground_truth": ["Wild Palms"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Wild Palms", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:49:54.823880Z"}
{"question_id": "tqa_rc_validation_23", "question": "Which 90s sci fi series with James Belushi was based on Bruce Wagner's comic strip of the same name?", "ground_truth": ["Wild Palms"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The Adventures of Brisco County, Jr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Adventures of Brisco County, Jr", "The Adventures of Brisco County, Jr", "The Adventures of Brisco County, Jr", "The Adventures of Brisco County, Jr", "Life with Louie", "Life with Louie", "Life with Louie", "The Adventures of Brisco County, Jr", "The Adventures of Brisco County, Jr", "The Adventures of Brisco County, Jr"], "equivalence_results": ["same", "same", "same", "same", "different", "different", "different", "same", "same", "same"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:50:18.272257Z"}
{"question_id": "tqa_rc_validation_23", "question": "Which 90s sci fi series with James Belushi was based on Bruce Wagner's comic strip of the same name?", "ground_truth": ["Wild Palms"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Wild Palms", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:19.232602Z"}
{"question_id": "tqa_rc_validation_24", "question": "If I Were A Rich Man Was a big hit from which stage show?", "ground_truth": ["Fiddler on the Roof", "Fiddler on a Roof", "Sprintze", "2 life", "The Fiddler on the Roof", "Fiddler on the reoof", "Anatevka", "fiddler on roof", "fiddler on reoof"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Fiddler on the Roof", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:20.093364Z"}
{"question_id": "tqa_rc_validation_24", "question": "If I Were A Rich Man Was a big hit from which stage show?", "ground_truth": ["Fiddler on the Roof", "Fiddler on a Roof", "Sprintze", "2 life", "The Fiddler on the Roof", "Fiddler on the reoof", "Anatevka", "fiddler on roof", "fiddler on reoof"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Fiddler on the Roof", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:21.799640Z"}
{"question_id": "tqa_rc_validation_24", "question": "If I Were A Rich Man Was a big hit from which stage show?", "ground_truth": ["Fiddler on the Roof", "Fiddler on a Roof", "Sprintze", "2 life", "The Fiddler on the Roof", "Fiddler on the reoof", "Anatevka", "fiddler on roof", "fiddler on reoof"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Fiddler on the Roof", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:22.020417Z"}
{"question_id": "tqa_rc_validation_24", "question": "If I Were A Rich Man Was a big hit from which stage show?", "ground_truth": ["Fiddler on the Roof", "Fiddler on a Roof", "Sprintze", "2 life", "The Fiddler on the Roof", "Fiddler on the reoof", "Anatevka", "fiddler on roof", "fiddler on reoof"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Fiddler on the Roof", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:23.447931Z"}
{"question_id": "tqa_rc_validation_24", "question": "If I Were A Rich Man Was a big hit from which stage show?", "ground_truth": ["Fiddler on the Roof", "Fiddler on a Roof", "Sprintze", "2 life", "The Fiddler on the Roof", "Fiddler on the reoof", "Anatevka", "fiddler on roof", "fiddler on reoof"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Fiddler on the Roof", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:24.366261Z"}
{"question_id": "tqa_rc_validation_25", "question": "Men Against the Sea and Pitcairn's Island were two sequels to what famous novel?", "ground_truth": ["Mutiny On The Bounty", "HMS Bounty mutineers", "Mutiny on Bounty", "Mutiny on the Bounty (history)", "Bounty (vessel)", "Thomas Ledward", "mutiny on bounty history", "bounty vessel"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Mutiny on the Bounty", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:25.321775Z"}
{"question_id": "tqa_rc_validation_25", "question": "Men Against the Sea and Pitcairn's Island were two sequels to what famous novel?", "ground_truth": ["Mutiny On The Bounty", "HMS Bounty mutineers", "Mutiny on Bounty", "Mutiny on the Bounty (history)", "Bounty (vessel)", "Thomas Ledward", "mutiny on bounty history", "bounty vessel"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Mutiny on the Bounty", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:26.833239Z"}
{"question_id": "tqa_rc_validation_25", "question": "Men Against the Sea and Pitcairn's Island were two sequels to what famous novel?", "ground_truth": ["Mutiny On The Bounty", "HMS Bounty mutineers", "Mutiny on Bounty", "Mutiny on the Bounty (history)", "Bounty (vessel)", "Thomas Ledward", "mutiny on bounty history", "bounty vessel"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Mutiny on the Bounty", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:27.079554Z"}
{"question_id": "tqa_rc_validation_25", "question": "Men Against the Sea and Pitcairn's Island were two sequels to what famous novel?", "ground_truth": ["Mutiny On The Bounty", "HMS Bounty mutineers", "Mutiny on Bounty", "Mutiny on the Bounty (history)", "Bounty (vessel)", "Thomas Ledward", "mutiny on bounty history", "bounty vessel"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Mutiny on the Bounty", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:28.811304Z"}
{"question_id": "tqa_rc_validation_25", "question": "Men Against the Sea and Pitcairn's Island were two sequels to what famous novel?", "ground_truth": ["Mutiny On The Bounty", "HMS Bounty mutineers", "Mutiny on Bounty", "Mutiny on the Bounty (history)", "Bounty (vessel)", "Thomas Ledward", "mutiny on bounty history", "bounty vessel"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Typee: A Peep at Polynesian Life", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Typee: A Peep at Polynesian Life", "Mutiny on the Bounty", "Typee", "Treasure Island", "Masters of Ballantrae", "Moby-Dick", "Mutiny on the Bounty", "Typee: A Peep at Polynesian Life", "Mutiny on the Bounty", "Mutiny on the Bounty"], "equivalence_results": ["same", "different", "same", "different", "different", "different", "different", "same", "different", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:50:45.504223Z"}
{"question_id": "tqa_rc_validation_26", "question": "What was Truman Capote's last name before he was adopted by his stepfather?", "ground_truth": ["Persons", "Perſons", "Person", "Person (philosophical)", "Personhood Theory", "Perſon", "A person", "person philosophical"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Persons", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:46.190634Z"}
{"question_id": "tqa_rc_validation_26", "question": "What was Truman Capote's last name before he was adopted by his stepfather?", "ground_truth": ["Persons", "Perſons", "Person", "Person (philosophical)", "Personhood Theory", "Perſon", "A person", "person philosophical"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Persons", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:47.965453Z"}
{"question_id": "tqa_rc_validation_26", "question": "What was Truman Capote's last name before he was adopted by his stepfather?", "ground_truth": ["Persons", "Perſons", "Person", "Person (philosophical)", "Personhood Theory", "Perſon", "A person", "person philosophical"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Persons", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:48.405660Z"}
{"question_id": "tqa_rc_validation_26", "question": "What was Truman Capote's last name before he was adopted by his stepfather?", "ground_truth": ["Persons", "Perſons", "Person", "Person (philosophical)", "Personhood Theory", "Perſon", "A person", "person philosophical"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Persons", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:50:49.611619Z"}
{"question_id": "tqa_rc_validation_26", "question": "What was Truman Capote's last name before he was adopted by his stepfather?", "ground_truth": ["Persons", "Perſons", "Person", "Person (philosophical)", "Personhood Theory", "Perſon", "A person", "person philosophical"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Monroe", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Monroe", "Monroe", "Monroe", "Persons", "Monroe", "Monroe", "Monroe", "Monroe", "Monroe", "Monroe"], "equivalence_results": ["same", "same", "same", "different", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:51:07.505583Z"}
{"question_id": "tqa_rc_validation_27", "question": "In Lewis Carroll's poem The Hunting of the Snark, what did the elusive, troublesome snark turn into to fool hunters?", "ground_truth": ["A boojum", "Boojum (disambiguation)", "Boojum", "boojum disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "A Boojum", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:08.425790Z"}
{"question_id": "tqa_rc_validation_27", "question": "In Lewis Carroll's poem The Hunting of the Snark, what did the elusive, troublesome snark turn into to fool hunters?", "ground_truth": ["A boojum", "Boojum (disambiguation)", "Boojum", "boojum disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "A Boojum", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:09.506253Z"}
{"question_id": "tqa_rc_validation_27", "question": "In Lewis Carroll's poem The Hunting of the Snark, what did the elusive, troublesome snark turn into to fool hunters?", "ground_truth": ["A boojum", "Boojum (disambiguation)", "Boojum", "boojum disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "A Boojum", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:09.718473Z"}
{"question_id": "tqa_rc_validation_27", "question": "In Lewis Carroll's poem The Hunting of the Snark, what did the elusive, troublesome snark turn into to fool hunters?", "ground_truth": ["A boojum", "Boojum (disambiguation)", "Boojum", "boojum disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "A boojum", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:11.066457Z"}
{"question_id": "tqa_rc_validation_27", "question": "In Lewis Carroll's poem The Hunting of the Snark, what did the elusive, troublesome snark turn into to fool hunters?", "ground_truth": ["A boojum", "Boojum (disambiguation)", "Boojum", "boojum disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "A Boojum", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:11.940595Z"}
{"question_id": "tqa_rc_validation_28", "question": "In the Bible, who did the sun and moon stand still before?", "ground_truth": ["Joshua", "Joshua of ephraim", "Y'hosheya", "Yehoshea", "Yahushua", "Yoshea", "Yehoshua%60", "Yūsha", "Yhoshoa", "Joshua bin Nun", "Joshua Ben Nun", "Yehosha", "Jehoshua", "Yahusha", "Yhoshua", "Joshua Bin-Nun", "Yhoshua Ben Nun", "Yoshia", "Yehoshua Ben Nun", "Y'hoshiya", "Yhoshea", "Y'hoshea", "Yhosheya", "Yoshoa", "Josue", "Yhoshia", "Y'hoshua", "Yhosha", "Yusha'", "Yhoshiya", "Y'hoshia", "Joshua's Prayer", "Ieshua", "Y'hoshoa", "Yoshua", "Y'hosha", "Joshuah", "يوشع", "Yehoshia", "Jesus Navin", "Joshua in Islam", "Joshua's conquests", "Yosheya", "Joshua son of Nun", "Yehoshoa", "Yehoshiya", "Yĕhōshūa‘", "Yehosheya", "Yosha", "Jehoshuah", "יְהוֹשֻׁעַ", "yehoshua 60", "yusha", "y hoshea", "joshua s prayer", "y hoshua", "y hoshoa", "yĕhōshūa", "y hosheya", "joshua s conquests", "y hoshiya", "y hoshia", "y hosha"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Joshua", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:12.662882Z"}
{"question_id": "tqa_rc_validation_28", "question": "In the Bible, who did the sun and moon stand still before?", "ground_truth": ["Joshua", "Joshua of ephraim", "Y'hosheya", "Yehoshea", "Yahushua", "Yoshea", "Yehoshua%60", "Yūsha", "Yhoshoa", "Joshua bin Nun", "Joshua Ben Nun", "Yehosha", "Jehoshua", "Yahusha", "Yhoshua", "Joshua Bin-Nun", "Yhoshua Ben Nun", "Yoshia", "Yehoshua Ben Nun", "Y'hoshiya", "Yhoshea", "Y'hoshea", "Yhosheya", "Yoshoa", "Josue", "Yhoshia", "Y'hoshua", "Yhosha", "Yusha'", "Yhoshiya", "Y'hoshia", "Joshua's Prayer", "Ieshua", "Y'hoshoa", "Yoshua", "Y'hosha", "Joshuah", "يوشع", "Yehoshia", "Jesus Navin", "Joshua in Islam", "Joshua's conquests", "Yosheya", "Joshua son of Nun", "Yehoshoa", "Yehoshiya", "Yĕhōshūa‘", "Yehosheya", "Yosha", "Jehoshuah", "יְהוֹשֻׁעַ", "yehoshua 60", "yusha", "y hoshea", "joshua s prayer", "y hoshua", "y hoshoa", "yĕhōshūa", "y hosheya", "joshua s conquests", "y hoshiya", "y hoshia", "y hosha"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Joshua", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:14.298096Z"}
{"question_id": "tqa_rc_validation_28", "question": "In the Bible, who did the sun and moon stand still before?", "ground_truth": ["Joshua", "Joshua of ephraim", "Y'hosheya", "Yehoshea", "Yahushua", "Yoshea", "Yehoshua%60", "Yūsha", "Yhoshoa", "Joshua bin Nun", "Joshua Ben Nun", "Yehosha", "Jehoshua", "Yahusha", "Yhoshua", "Joshua Bin-Nun", "Yhoshua Ben Nun", "Yoshia", "Yehoshua Ben Nun", "Y'hoshiya", "Yhoshea", "Y'hoshea", "Yhosheya", "Yoshoa", "Josue", "Yhoshia", "Y'hoshua", "Yhosha", "Yusha'", "Yhoshiya", "Y'hoshia", "Joshua's Prayer", "Ieshua", "Y'hoshoa", "Yoshua", "Y'hosha", "Joshuah", "يوشع", "Yehoshia", "Jesus Navin", "Joshua in Islam", "Joshua's conquests", "Yosheya", "Joshua son of Nun", "Yehoshoa", "Yehoshiya", "Yĕhōshūa‘", "Yehosheya", "Yosha", "Jehoshuah", "יְהוֹשֻׁעַ", "yehoshua 60", "yusha", "y hoshea", "joshua s prayer", "y hoshua", "y hoshoa", "yĕhōshūa", "y hosheya", "joshua s conquests", "y hoshiya", "y hoshia", "y hosha"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Joshua", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:14.442647Z"}
{"question_id": "tqa_rc_validation_28", "question": "In the Bible, who did the sun and moon stand still before?", "ground_truth": ["Joshua", "Joshua of ephraim", "Y'hosheya", "Yehoshea", "Yahushua", "Yoshea", "Yehoshua%60", "Yūsha", "Yhoshoa", "Joshua bin Nun", "Joshua Ben Nun", "Yehosha", "Jehoshua", "Yahusha", "Yhoshua", "Joshua Bin-Nun", "Yhoshua Ben Nun", "Yoshia", "Yehoshua Ben Nun", "Y'hoshiya", "Yhoshea", "Y'hoshea", "Yhosheya", "Yoshoa", "Josue", "Yhoshia", "Y'hoshua", "Yhosha", "Yusha'", "Yhoshiya", "Y'hoshia", "Joshua's Prayer", "Ieshua", "Y'hoshoa", "Yoshua", "Y'hosha", "Joshuah", "يوشع", "Yehoshia", "Jesus Navin", "Joshua in Islam", "Joshua's conquests", "Yosheya", "Joshua son of Nun", "Yehoshoa", "Yehoshiya", "Yĕhōshūa‘", "Yehosheya", "Yosha", "Jehoshuah", "יְהוֹשֻׁעַ", "yehoshua 60", "yusha", "y hoshea", "joshua s prayer", "y hoshua", "y hoshoa", "yĕhōshūa", "y hosheya", "joshua s conquests", "y hoshiya", "y hoshia", "y hosha"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Joshua", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:15.573093Z"}
{"question_id": "tqa_rc_validation_28", "question": "In the Bible, who did the sun and moon stand still before?", "ground_truth": ["Joshua", "Joshua of ephraim", "Y'hosheya", "Yehoshea", "Yahushua", "Yoshea", "Yehoshua%60", "Yūsha", "Yhoshoa", "Joshua bin Nun", "Joshua Ben Nun", "Yehosha", "Jehoshua", "Yahusha", "Yhoshua", "Joshua Bin-Nun", "Yhoshua Ben Nun", "Yoshia", "Yehoshua Ben Nun", "Y'hoshiya", "Yhoshea", "Y'hoshea", "Yhosheya", "Yoshoa", "Josue", "Yhoshia", "Y'hoshua", "Yhosha", "Yusha'", "Yhoshiya", "Y'hoshia", "Joshua's Prayer", "Ieshua", "Y'hoshoa", "Yoshua", "Y'hosha", "Joshuah", "يوشع", "Yehoshia", "Jesus Navin", "Joshua in Islam", "Joshua's conquests", "Yosheya", "Joshua son of Nun", "Yehoshoa", "Yehoshiya", "Yĕhōshūa‘", "Yehosheya", "Yosha", "Jehoshuah", "יְהוֹשֻׁעַ", "yehoshua 60", "yusha", "y hoshea", "joshua s prayer", "y hoshua", "y hoshoa", "yĕhōshūa", "y hosheya", "joshua s conquests", "y hoshiya", "y hoshia", "y hosha"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Joshua", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:16.245956Z"}
{"question_id": "tqa_rc_validation_29", "question": "What Michelle Pfeiffer movie got a boost from the Coolio song Gangsta's Paradise?", "ground_truth": ["Dangerous Minds", "Dangerous Minds (film)", "My Posse Don't Do Homework", "my posse don t do homework", "dangerous minds film"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Dangerous Minds", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:17.422220Z"}
{"question_id": "tqa_rc_validation_29", "question": "What Michelle Pfeiffer movie got a boost from the Coolio song Gangsta's Paradise?", "ground_truth": ["Dangerous Minds", "Dangerous Minds (film)", "My Posse Don't Do Homework", "my posse don t do homework", "dangerous minds film"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Dangerous Minds", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:19.182330Z"}
{"question_id": "tqa_rc_validation_29", "question": "What Michelle Pfeiffer movie got a boost from the Coolio song Gangsta's Paradise?", "ground_truth": ["Dangerous Minds", "Dangerous Minds (film)", "My Posse Don't Do Homework", "my posse don t do homework", "dangerous minds film"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Dangerous Minds", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:19.427313Z"}
{"question_id": "tqa_rc_validation_29", "question": "What Michelle Pfeiffer movie got a boost from the Coolio song Gangsta's Paradise?", "ground_truth": ["Dangerous Minds", "Dangerous Minds (film)", "My Posse Don't Do Homework", "my posse don t do homework", "dangerous minds film"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Dangerous Minds", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:20.672958Z"}
{"question_id": "tqa_rc_validation_29", "question": "What Michelle Pfeiffer movie got a boost from the Coolio song Gangsta's Paradise?", "ground_truth": ["Dangerous Minds", "Dangerous Minds (film)", "My Posse Don't Do Homework", "my posse don t do homework", "dangerous minds film"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Dangerous Minds", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:21.574494Z"}
{"question_id": "tqa_rc_validation_30", "question": "What was President Gerald Ford's middle name?", "ground_truth": ["Rudolph", "Rudolph (disambiguation)", "Rudolf", "Rodolph", "Rodolphe", "rudolph disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Rudolph", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:22.467880Z"}
{"question_id": "tqa_rc_validation_30", "question": "What was President Gerald Ford's middle name?", "ground_truth": ["Rudolph", "Rudolph (disambiguation)", "Rudolf", "Rodolph", "Rodolphe", "rudolph disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Rudolph", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:24.211391Z"}
{"question_id": "tqa_rc_validation_30", "question": "What was President Gerald Ford's middle name?", "ground_truth": ["Rudolph", "Rudolph (disambiguation)", "Rudolf", "Rodolph", "Rodolphe", "rudolph disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Rudolph", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:24.360455Z"}
{"question_id": "tqa_rc_validation_30", "question": "What was President Gerald Ford's middle name?", "ground_truth": ["Rudolph", "Rudolph (disambiguation)", "Rudolf", "Rodolph", "Rodolphe", "rudolph disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Rudolph", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:25.545931Z"}
{"question_id": "tqa_rc_validation_30", "question": "What was President Gerald Ford's middle name?", "ground_truth": ["Rudolph", "Rudolph (disambiguation)", "Rudolf", "Rodolph", "Rodolphe", "rudolph disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Elliot", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ellis", "Ellison", "Elliot", "Rudolph", "Elliot", "Ellison", "Ellison", "Rudolph", "Ellison", "Elliot"], "equivalence_results": ["different", "different", "same", "different", "same", "different", "different", "different", "different", "same"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:51:41.349176Z"}
{"question_id": "tqa_rc_validation_31", "question": "Art Garfunkel trained for which profession although he didn't qualify?", "ground_truth": ["Architect", "Master Builder (occupation)", "Registered Architect", "Architects", "Architecht", "HOK Canada, Inc.", "Stanford Downey Architects Inc.", "Graziani + Corazza", "Architechts", "Clifford & Lawrie", "master builder occupation", "graziani corazza", "clifford lawrie", "hok canada inc", "stanford downey architects inc"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Architecture", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:42.115693Z"}
{"question_id": "tqa_rc_validation_31", "question": "Art Garfunkel trained for which profession although he didn't qualify?", "ground_truth": ["Architect", "Master Builder (occupation)", "Registered Architect", "Architects", "Architecht", "HOK Canada, Inc.", "Stanford Downey Architects Inc.", "Graziani + Corazza", "Architechts", "Clifford & Lawrie", "master builder occupation", "graziani corazza", "clifford lawrie", "hok canada inc", "stanford downey architects inc"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Architecture", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:43.668143Z"}
{"question_id": "tqa_rc_validation_31", "question": "Art Garfunkel trained for which profession although he didn't qualify?", "ground_truth": ["Architect", "Master Builder (occupation)", "Registered Architect", "Architects", "Architecht", "HOK Canada, Inc.", "Stanford Downey Architects Inc.", "Graziani + Corazza", "Architechts", "Clifford & Lawrie", "master builder occupation", "graziani corazza", "clifford lawrie", "hok canada inc", "stanford downey architects inc"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Architecture", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:44.090384Z"}
{"question_id": "tqa_rc_validation_31", "question": "Art Garfunkel trained for which profession although he didn't qualify?", "ground_truth": ["Architect", "Master Builder (occupation)", "Registered Architect", "Architects", "Architecht", "HOK Canada, Inc.", "Stanford Downey Architects Inc.", "Graziani + Corazza", "Architechts", "Clifford & Lawrie", "master builder occupation", "graziani corazza", "clifford lawrie", "hok canada inc", "stanford downey architects inc"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Architecture", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:51:45.389966Z"}
{"question_id": "tqa_rc_validation_31", "question": "Art Garfunkel trained for which profession although he didn't qualify?", "ground_truth": ["Architect", "Master Builder (occupation)", "Registered Architect", "Architects", "Architecht", "HOK Canada, Inc.", "Stanford Downey Architects Inc.", "Graziani + Corazza", "Architechts", "Clifford & Lawrie", "master builder occupation", "graziani corazza", "clifford lawrie", "hok canada inc", "stanford downey architects inc"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Dentistry", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Orthodontics", "Dentistry", "Art Garfunkel trained to be a doctor", "Ophthalmology", "Doctor", "Medicine", "Orthodontics", "Economics", "Dentistry", "Dentistry"], "equivalence_results": ["different", "same", "different", "different", "different", "different", "different", "different", "same", "same"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:52:01.409291Z"}
{"question_id": "tqa_rc_validation_32", "question": "Who was the last inmate of Spandau jail in Berlin?", "ground_truth": ["Rudolf Hess", "Hess, Rudolf", "Rudolf W. Hess", "Rudolph Hess", "Walther Richard Rudolf Hess", "Rudolf Walter Richard Hess", "Rudolf Walter Richard Heß", "Rudolph Heß", "Rudolf Heß", "Rudolf Hesse", "hess rudolf", "rudolf w hess"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Rudolf Hess", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:52:02.359306Z"}
{"question_id": "tqa_rc_validation_32", "question": "Who was the last inmate of Spandau jail in Berlin?", "ground_truth": ["Rudolf Hess", "Hess, Rudolf", "Rudolf W. Hess", "Rudolph Hess", "Walther Richard Rudolf Hess", "Rudolf Walter Richard Hess", "Rudolf Walter Richard Heß", "Rudolph Heß", "Rudolf Heß", "Rudolf Hesse", "hess rudolf", "rudolf w hess"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Rudolf Hess", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:52:03.281161Z"}
{"question_id": "tqa_rc_validation_32", "question": "Who was the last inmate of Spandau jail in Berlin?", "ground_truth": ["Rudolf Hess", "Hess, Rudolf", "Rudolf W. Hess", "Rudolph Hess", "Walther Richard Rudolf Hess", "Rudolf Walter Richard Hess", "Rudolf Walter Richard Heß", "Rudolph Heß", "Rudolf Heß", "Rudolf Hesse", "hess rudolf", "rudolf w hess"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Rudolf Hess", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:52:03.685859Z"}
{"question_id": "tqa_rc_validation_32", "question": "Who was the last inmate of Spandau jail in Berlin?", "ground_truth": ["Rudolf Hess", "Hess, Rudolf", "Rudolf W. Hess", "Rudolph Hess", "Walther Richard Rudolf Hess", "Rudolf Walter Richard Hess", "Rudolf Walter Richard Heß", "Rudolph Heß", "Rudolf Heß", "Rudolf Hesse", "hess rudolf", "rudolf w hess"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Rudolf Hess", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:52:05.138260Z"}
{"question_id": "tqa_rc_validation_32", "question": "Who was the last inmate of Spandau jail in Berlin?", "ground_truth": ["Rudolf Hess", "Hess, Rudolf", "Rudolf W. Hess", "Rudolph Hess", "Walther Richard Rudolf Hess", "Rudolf Walter Richard Hess", "Rudolf Walter Richard Heß", "Rudolph Heß", "Rudolf Heß", "Rudolf Hesse", "hess rudolf", "rudolf w hess"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Günter Guillaume", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Günter Guillaume and then finally  Rudolf Hess", "John George Haigh is often referred to as the last inmate of Spandau jail, however it was actually Rudolf Hess who was the last inmate", "John George Steiner", "John George Stäglin", "Guenther Guillaume", "John George Steiner", "Günter Guillaume", "Günther Klein, however, it's often claimed that the last inmate was actually Günther Guillaume, however this is not correct", "Günter Guillaume was the last inmate of Spandau jail in Berlin", "John George Steiner"], "equivalence_results": ["different", "different", "different", "different", "same", "different", "same", "different", "same", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:52:31.244532Z"}
{"question_id": "tqa_rc_validation_33", "question": "What was Eddie Murphy's first movie?", "ground_truth": ["48 Hours", "48 time", "forty-eight  time", "forty eight time"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "48 Hrs", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:52:48.019252Z"}
{"question_id": "tqa_rc_validation_33", "question": "What was Eddie Murphy's first movie?", "ground_truth": ["48 Hours", "48 time", "forty-eight  time", "forty eight time"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "48 Hrs", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:53:13.973113Z"}
{"question_id": "tqa_rc_validation_33", "question": "What was Eddie Murphy's first movie?", "ground_truth": ["48 Hours", "48 time", "forty-eight  time", "forty eight time"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "48 Hrs", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "\"48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:53:23.894367Z"}
{"question_id": "tqa_rc_validation_33", "question": "What was Eddie Murphy's first movie?", "ground_truth": ["48 Hours", "48 time", "forty-eight  time", "forty eight time"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "48 Hrs", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:53:46.017683Z"}
{"question_id": "tqa_rc_validation_33", "question": "What was Eddie Murphy's first movie?", "ground_truth": ["48 Hours", "48 time", "forty-eight  time", "forty eight time"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "48 Hrs", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs", "48 Hrs"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:54:02.780275Z"}
{"question_id": "tqa_rc_validation_34", "question": "In the 80s who wrote the novel Empire of The Sun?", "ground_truth": ["J. G. Ballard", "JG Ballard", "J.G. Ballard", "James Graham Ballard", "J.G.Ballard", "A User's Guide to the Millenium", "J G Ballard", "Ballardian", "James G. Ballard", "user s guide to millenium", "james g ballard"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "J", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["J", "J", "J", "J", "J", "J", "J", "J", "J", "J"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:54:20.531319Z"}
{"question_id": "tqa_rc_validation_34", "question": "In the 80s who wrote the novel Empire of The Sun?", "ground_truth": ["J. G. Ballard", "JG Ballard", "J.G. Ballard", "James Graham Ballard", "J.G.Ballard", "A User's Guide to the Millenium", "J G Ballard", "Ballardian", "James G. Ballard", "user s guide to millenium", "james g ballard"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "J", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["J", "J", "J", "J", "J", "J", "J", "J", "J", "J"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:54:44.029010Z"}
{"question_id": "tqa_rc_validation_34", "question": "In the 80s who wrote the novel Empire of The Sun?", "ground_truth": ["J. G. Ballard", "JG Ballard", "J.G. Ballard", "James Graham Ballard", "J.G.Ballard", "A User's Guide to the Millenium", "J G Ballard", "Ballardian", "James G. Ballard", "user s guide to millenium", "james g ballard"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "J", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["J", "J", "J", "J", "J", "J", "J", "J", "J", "J"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:54:54.531680Z"}
{"question_id": "tqa_rc_validation_34", "question": "In the 80s who wrote the novel Empire of The Sun?", "ground_truth": ["J. G. Ballard", "JG Ballard", "J.G. Ballard", "James Graham Ballard", "J.G.Ballard", "A User's Guide to the Millenium", "J G Ballard", "Ballardian", "James G. Ballard", "user s guide to millenium", "james g ballard"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "J", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["J", "J", "J", "J", "J", "J", "J", "J", "J", "J"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:55:16.559033Z"}
{"question_id": "tqa_rc_validation_34", "question": "In the 80s who wrote the novel Empire of The Sun?", "ground_truth": ["J. G. Ballard", "JG Ballard", "J.G. Ballard", "James Graham Ballard", "J.G.Ballard", "A User's Guide to the Millenium", "J G Ballard", "Ballardian", "James G. Ballard", "user s guide to millenium", "james g ballard"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "J", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["J", "J", "J", "J", "J", "J", "J", "J", "J", "J"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:55:50.867676Z"}
{"question_id": "tqa_rc_validation_35", "question": "Kagoshima international airport is in which country?", "ground_truth": ["Japan", "日本國", "State of Japan", "Ja-pan", "Nihon", "Nippon", "Japang", "Modern–era Japan", "Etymology of Japan", "Japan (country)", "Republic of Japan", "Japanese financial sector", "Nihon-koku", "ISO 3166-1:JP", "日本", "Japian", "The State of Japan", "Riben", "Nippon-koku", "JPN", "Jpan", "Rìběn", "日本国", "Japao", "Japoa", "🗾", "nihon koku", "iso 3166 1 jp", "japan country", "nippon koku", "ja pan"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Japan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:51.525597Z"}
{"question_id": "tqa_rc_validation_35", "question": "Kagoshima international airport is in which country?", "ground_truth": ["Japan", "日本國", "State of Japan", "Ja-pan", "Nihon", "Nippon", "Japang", "Modern–era Japan", "Etymology of Japan", "Japan (country)", "Republic of Japan", "Japanese financial sector", "Nihon-koku", "ISO 3166-1:JP", "日本", "Japian", "The State of Japan", "Riben", "Nippon-koku", "JPN", "Jpan", "Rìběn", "日本国", "Japao", "Japoa", "🗾", "nihon koku", "iso 3166 1 jp", "japan country", "nippon koku", "ja pan"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Japan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:53.260206Z"}
{"question_id": "tqa_rc_validation_35", "question": "Kagoshima international airport is in which country?", "ground_truth": ["Japan", "日本國", "State of Japan", "Ja-pan", "Nihon", "Nippon", "Japang", "Modern–era Japan", "Etymology of Japan", "Japan (country)", "Republic of Japan", "Japanese financial sector", "Nihon-koku", "ISO 3166-1:JP", "日本", "Japian", "The State of Japan", "Riben", "Nippon-koku", "JPN", "Jpan", "Rìběn", "日本国", "Japao", "Japoa", "🗾", "nihon koku", "iso 3166 1 jp", "japan country", "nippon koku", "ja pan"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Japan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:53.499612Z"}
{"question_id": "tqa_rc_validation_35", "question": "Kagoshima international airport is in which country?", "ground_truth": ["Japan", "日本國", "State of Japan", "Ja-pan", "Nihon", "Nippon", "Japang", "Modern–era Japan", "Etymology of Japan", "Japan (country)", "Republic of Japan", "Japanese financial sector", "Nihon-koku", "ISO 3166-1:JP", "日本", "Japian", "The State of Japan", "Riben", "Nippon-koku", "JPN", "Jpan", "Rìběn", "日本国", "Japao", "Japoa", "🗾", "nihon koku", "iso 3166 1 jp", "japan country", "nippon koku", "ja pan"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Japan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:54.588200Z"}
{"question_id": "tqa_rc_validation_35", "question": "Kagoshima international airport is in which country?", "ground_truth": ["Japan", "日本國", "State of Japan", "Ja-pan", "Nihon", "Nippon", "Japang", "Modern–era Japan", "Etymology of Japan", "Japan (country)", "Republic of Japan", "Japanese financial sector", "Nihon-koku", "ISO 3166-1:JP", "日本", "Japian", "The State of Japan", "Riben", "Nippon-koku", "JPN", "Jpan", "Rìběn", "日本国", "Japao", "Japoa", "🗾", "nihon koku", "iso 3166 1 jp", "japan country", "nippon koku", "ja pan"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Japan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:55.394444Z"}
{"question_id": "tqa_rc_validation_36", "question": "In which sport could the Pacers take on the Pistons?", "ground_truth": ["A: Basketball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basket ball", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:56.155469Z"}
{"question_id": "tqa_rc_validation_36", "question": "In which sport could the Pacers take on the Pistons?", "ground_truth": ["A: Basketball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basket ball", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:56.925631Z"}
{"question_id": "tqa_rc_validation_36", "question": "In which sport could the Pacers take on the Pistons?", "ground_truth": ["A: Basketball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basket ball", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:57.109229Z"}
{"question_id": "tqa_rc_validation_36", "question": "In which sport could the Pacers take on the Pistons?", "ground_truth": ["A: Basketball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basket ball", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:58.100507Z"}
{"question_id": "tqa_rc_validation_36", "question": "In which sport could the Pacers take on the Pistons?", "ground_truth": ["A: Basketball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basket ball", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:58.861142Z"}
{"question_id": "tqa_rc_validation_37", "question": "Kim Carnes' nine weeks at No 1 with Bette Davis Eyes was interrupted for one week by which song?", "ground_truth": ["Stars on 45 medley", "Stars on 45 (Single)", "Stars on 45 (song)", "Medley: Intro Venus / Sugar Sugar / No Reply / I'll Be Back / Drive My Car / Do You Want to Know a Secret / We Can Work It Out / I Should Have Known Better / Nowhere Man / You're Going to Lose That Girl / Stars on 45", "stars on 45 song", "stars on 45 single", "medley intro venus sugar sugar no reply i ll be back drive my car do you want to know secret we can work it out i should have known better nowhere man you re going to lose that girl stars on 45"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "“Stars on 45” by Stars on 45", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:55:59.905204Z"}
{"question_id": "tqa_rc_validation_37", "question": "Kim Carnes' nine weeks at No 1 with Bette Davis Eyes was interrupted for one week by which song?", "ground_truth": ["Stars on 45 medley", "Stars on 45 (Single)", "Stars on 45 (song)", "Medley: Intro Venus / Sugar Sugar / No Reply / I'll Be Back / Drive My Car / Do You Want to Know a Secret / We Can Work It Out / I Should Have Known Better / Nowhere Man / You're Going to Lose That Girl / Stars on 45", "stars on 45 song", "stars on 45 single", "medley intro venus sugar sugar no reply i ll be back drive my car do you want to know secret we can work it out i should have known better nowhere man you re going to lose that girl stars on 45"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "\"Stars on 45 Medley\" by Stars on 45", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:56:01.896617Z"}
{"question_id": "tqa_rc_validation_37", "question": "Kim Carnes' nine weeks at No 1 with Bette Davis Eyes was interrupted for one week by which song?", "ground_truth": ["Stars on 45 medley", "Stars on 45 (Single)", "Stars on 45 (song)", "Medley: Intro Venus / Sugar Sugar / No Reply / I'll Be Back / Drive My Car / Do You Want to Know a Secret / We Can Work It Out / I Should Have Known Better / Nowhere Man / You're Going to Lose That Girl / Stars on 45", "stars on 45 song", "stars on 45 single", "medley intro venus sugar sugar no reply i ll be back drive my car do you want to know secret we can work it out i should have known better nowhere man you re going to lose that girl stars on 45"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Physical by Olivia Newton-John", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["\"Dance, Dance, Dance\" by Kim Carnes was not the interrupting song, it was actually \"Endless Love\" by Diana Ross and Lionel Richie", "\"Physical\" by Olivia Newton-John", "\"Physical\" by Olivia Newton-John", "Physical by Olivia Newton-John", "'Jessie's Girl' by Rick Springfield", "'Physical' by Olivia Newton-John", "'Jessie's Girl' by Rick Springfield", "'Jessie's Girl' by Rick Springfield", "Physical by Olivia Newton-John", "\"Physical\" by Olivia Newton-John"], "equivalence_results": ["different", "same", "same", "same", "different", "same", "different", "different", "same", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:56:11.757175Z"}
{"question_id": "tqa_rc_validation_37", "question": "Kim Carnes' nine weeks at No 1 with Bette Davis Eyes was interrupted for one week by which song?", "ground_truth": ["Stars on 45 medley", "Stars on 45 (Single)", "Stars on 45 (song)", "Medley: Intro Venus / Sugar Sugar / No Reply / I'll Be Back / Drive My Car / Do You Want to Know a Secret / We Can Work It Out / I Should Have Known Better / Nowhere Man / You're Going to Lose That Girl / Stars on 45", "stars on 45 song", "stars on 45 single", "medley intro venus sugar sugar no reply i ll be back drive my car do you want to know secret we can work it out i should have known better nowhere man you re going to lose that girl stars on 45"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Stars on 45", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:56:13.220199Z"}
{"question_id": "tqa_rc_validation_37", "question": "Kim Carnes' nine weeks at No 1 with Bette Davis Eyes was interrupted for one week by which song?", "ground_truth": ["Stars on 45 medley", "Stars on 45 (Single)", "Stars on 45 (song)", "Medley: Intro Venus / Sugar Sugar / No Reply / I'll Be Back / Drive My Car / Do You Want to Know a Secret / We Can Work It Out / I Should Have Known Better / Nowhere Man / You're Going to Lose That Girl / Stars on 45", "stars on 45 song", "stars on 45 single", "medley intro venus sugar sugar no reply i ll be back drive my car do you want to know secret we can work it out i should have known better nowhere man you re going to lose that girl stars on 45"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Aubrey O'Hara", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["In the Eyes of an Angel", "Don Henley's \"The Boys of Summer\"", "A Groovy Kind of Love", "Journey's \"Open Arms\"", "A View to a Kill by Duran Duran", "I Don't Wanna Dance by Eddy Grant", "Aubrey O'Day", "Aubrey O'Day's version of \"Boyfriend\" and also  \"Physical\" by Olivia Newton-John was a single week interruption however most notably  \"Physical\" is the song that interrupted \"Bette Davis Eyes\"", "Keeping the Night Away", "Rosanne Caine's single wasn't the one, however, the song that interrupted Kim Carnes' nine-week run at number one with 'Bette Davis Eyes' was by Joan Jett's single \"I Love Rock 'n' Roll\","], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:56:31.606906Z"}
{"question_id": "tqa_rc_validation_38", "question": "Where in Canada is the Lion's Gate bridge?", "ground_truth": ["Vancouver", "Vancouver, Canada", "Vancouver (Canada)", "Corpus Christi Elementary School (Canada)", "UN/LOCODE:CAVAN", "Vancouver, British Columbia, Canada", "Vancouver, BC, Canada", "Vancouver, British-Columbia", "Vancouver, B.C., Canada", "Vancouver, British Colombia", "Vancover, British Columbia", "Vansterdam", "Vancouver (BC)", "Hastings East (Vancouver)", "Vancouver British Columbia", "Vancouver Canada", "City of Vancouver", "Vancouver, BC", "Vancouver (B.C.)", "Vancouver City Centre, British Columbia", "Vancouver, B.C.", "South Vancouver, British Columbia", "Vancouverite", "Vancouver, British Columbia", "Vancouver Christian School", "Vancouvr", "Hong kouver", "Vancouverites", "Hongcouver", "Corpus Christi Elementary", "Hong couver", "Greater Vancouver Bridges", "Vancover", "Vanocuver", "Vancouver BC", "south vancouver british columbia", "vancouver british colombia", "vancouver bc canada", "un locode cavan", "vancouver b c canada", "vancouver city centre british columbia", "hastings east vancouver", "vancover british columbia", "corpus christi elementary school canada", "vancouver b c", "vancouver british columbia canada"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Vancouver, British Columbia", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:56:32.387530Z"}
{"question_id": "tqa_rc_validation_38", "question": "Where in Canada is the Lion's Gate bridge?", "ground_truth": ["Vancouver", "Vancouver, Canada", "Vancouver (Canada)", "Corpus Christi Elementary School (Canada)", "UN/LOCODE:CAVAN", "Vancouver, British Columbia, Canada", "Vancouver, BC, Canada", "Vancouver, British-Columbia", "Vancouver, B.C., Canada", "Vancouver, British Colombia", "Vancover, British Columbia", "Vansterdam", "Vancouver (BC)", "Hastings East (Vancouver)", "Vancouver British Columbia", "Vancouver Canada", "City of Vancouver", "Vancouver, BC", "Vancouver (B.C.)", "Vancouver City Centre, British Columbia", "Vancouver, B.C.", "South Vancouver, British Columbia", "Vancouverite", "Vancouver, British Columbia", "Vancouver Christian School", "Vancouvr", "Hong kouver", "Vancouverites", "Hongcouver", "Corpus Christi Elementary", "Hong couver", "Greater Vancouver Bridges", "Vancover", "Vanocuver", "Vancouver BC", "south vancouver british columbia", "vancouver british colombia", "vancouver bc canada", "un locode cavan", "vancouver b c canada", "vancouver city centre british columbia", "hastings east vancouver", "vancover british columbia", "corpus christi elementary school canada", "vancouver b c", "vancouver british columbia canada"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Vancouver, British Columbia", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:56:34.202582Z"}
{"question_id": "tqa_rc_validation_38", "question": "Where in Canada is the Lion's Gate bridge?", "ground_truth": ["Vancouver", "Vancouver, Canada", "Vancouver (Canada)", "Corpus Christi Elementary School (Canada)", "UN/LOCODE:CAVAN", "Vancouver, British Columbia, Canada", "Vancouver, BC, Canada", "Vancouver, British-Columbia", "Vancouver, B.C., Canada", "Vancouver, British Colombia", "Vancover, British Columbia", "Vansterdam", "Vancouver (BC)", "Hastings East (Vancouver)", "Vancouver British Columbia", "Vancouver Canada", "City of Vancouver", "Vancouver, BC", "Vancouver (B.C.)", "Vancouver City Centre, British Columbia", "Vancouver, B.C.", "South Vancouver, British Columbia", "Vancouverite", "Vancouver, British Columbia", "Vancouver Christian School", "Vancouvr", "Hong kouver", "Vancouverites", "Hongcouver", "Corpus Christi Elementary", "Hong couver", "Greater Vancouver Bridges", "Vancover", "Vanocuver", "Vancouver BC", "south vancouver british columbia", "vancouver british colombia", "vancouver bc canada", "un locode cavan", "vancouver b c canada", "vancouver city centre british columbia", "hastings east vancouver", "vancover british columbia", "corpus christi elementary school canada", "vancouver b c", "vancouver british columbia canada"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Vancouver, British Columbia", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:56:34.432059Z"}
{"question_id": "tqa_rc_validation_38", "question": "Where in Canada is the Lion's Gate bridge?", "ground_truth": ["Vancouver", "Vancouver, Canada", "Vancouver (Canada)", "Corpus Christi Elementary School (Canada)", "UN/LOCODE:CAVAN", "Vancouver, British Columbia, Canada", "Vancouver, BC, Canada", "Vancouver, British-Columbia", "Vancouver, B.C., Canada", "Vancouver, British Colombia", "Vancover, British Columbia", "Vansterdam", "Vancouver (BC)", "Hastings East (Vancouver)", "Vancouver British Columbia", "Vancouver Canada", "City of Vancouver", "Vancouver, BC", "Vancouver (B.C.)", "Vancouver City Centre, British Columbia", "Vancouver, B.C.", "South Vancouver, British Columbia", "Vancouverite", "Vancouver, British Columbia", "Vancouver Christian School", "Vancouvr", "Hong kouver", "Vancouverites", "Hongcouver", "Corpus Christi Elementary", "Hong couver", "Greater Vancouver Bridges", "Vancover", "Vanocuver", "Vancouver BC", "south vancouver british columbia", "vancouver british colombia", "vancouver bc canada", "un locode cavan", "vancouver b c canada", "vancouver city centre british columbia", "hastings east vancouver", "vancover british columbia", "corpus christi elementary school canada", "vancouver b c", "vancouver british columbia canada"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Vancouver, British Columbia", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:56:35.583087Z"}
{"question_id": "tqa_rc_validation_38", "question": "Where in Canada is the Lion's Gate bridge?", "ground_truth": ["Vancouver", "Vancouver, Canada", "Vancouver (Canada)", "Corpus Christi Elementary School (Canada)", "UN/LOCODE:CAVAN", "Vancouver, British Columbia, Canada", "Vancouver, BC, Canada", "Vancouver, British-Columbia", "Vancouver, B.C., Canada", "Vancouver, British Colombia", "Vancover, British Columbia", "Vansterdam", "Vancouver (BC)", "Hastings East (Vancouver)", "Vancouver British Columbia", "Vancouver Canada", "City of Vancouver", "Vancouver, BC", "Vancouver (B.C.)", "Vancouver City Centre, British Columbia", "Vancouver, B.C.", "South Vancouver, British Columbia", "Vancouverite", "Vancouver, British Columbia", "Vancouver Christian School", "Vancouvr", "Hong kouver", "Vancouverites", "Hongcouver", "Corpus Christi Elementary", "Hong couver", "Greater Vancouver Bridges", "Vancover", "Vanocuver", "Vancouver BC", "south vancouver british columbia", "vancouver british colombia", "vancouver bc canada", "un locode cavan", "vancouver b c canada", "vancouver city centre british columbia", "hastings east vancouver", "vancover british columbia", "corpus christi elementary school canada", "vancouver b c", "vancouver british columbia canada"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Vancouver, British Columbia", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:56:36.360595Z"}
{"question_id": "tqa_rc_validation_39", "question": "What was Walter Matthau's first movie?", "ground_truth": ["The Kentuckian", "kentuckian"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Kentuckian", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:56:37.201943Z"}
{"question_id": "tqa_rc_validation_39", "question": "What was Walter Matthau's first movie?", "ground_truth": ["The Kentuckian", "kentuckian"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The Kentucky", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Kentucky", "The Kentucky", "The Kentucky", "The Kentuckian (1955)", "The Kentuckian (1955)", "The Kentucky", "The Kentuckian (1955)", "The Kentuckian (1955)", "The Kentuckian (1955)", "The Kentucky"], "equivalence_results": ["same", "same", "same", "unclear", "unclear", "same", "unclear", "unclear", "unclear", "same"], "equivalence_stats": {"num_same": 5, "num_different": 0, "num_unclear": 5, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:57:03.390423Z"}
{"question_id": "tqa_rc_validation_39", "question": "What was Walter Matthau's first movie?", "ground_truth": ["The Kentuckian", "kentuckian"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Kentuckian (1955)", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:57:03.626929Z"}
{"question_id": "tqa_rc_validation_39", "question": "What was Walter Matthau's first movie?", "ground_truth": ["The Kentuckian", "kentuckian"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The Kentuckian", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:57:04.915853Z"}
{"question_id": "tqa_rc_validation_39", "question": "What was Walter Matthau's first movie?", "ground_truth": ["The Kentuckian", "kentuckian"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Strangers on a Train (1951)", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Strangers on a Train (1951)", "Strangers on a Train", "Strangers on a Train", "Danger Signal (1945)", "Battle Cry (1955)", "Kiss Tomorrow Goodbye (1955)", "The Missing Corpse", "Danger Signal (1945)", "Strangers on a Train (1951), a film noir thriller", "Battleground (1949)"], "equivalence_results": ["same", "same", "same", "different", "different", "different", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:57:21.993365Z"}
{"question_id": "tqa_rc_validation_40", "question": "Otis Barton was a pioneer in exploring where?", "ground_truth": ["Underwater", "Under water", "Underwater life", "Undersea"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "the deep sea", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["the deep sea", "The deep ocean (deep-sea exploration)", "the deep sea", "the deep sea", "The deep sea", "the deep sea", "the deep sea", "the deep sea", "the deep sea", "the deep sea"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:57:39.364419Z"}
{"question_id": "tqa_rc_validation_0", "question": "Who was the man behind The Chipmunks?", "ground_truth": ["David Seville"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Ross Bagdasarian Sr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:57:57.707421Z"}
{"question_id": "tqa_rc_validation_40", "question": "Otis Barton was a pioneer in exploring where?", "ground_truth": ["Underwater", "Under water", "Underwater life", "Undersea"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The deep sea", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The deep sea", "The deep sea", "The deep sea", "The deep sea", "The deep sea", "The deep sea", "The deep sea", "The deep sea", "The deep sea", "The deep sea"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:58:05.861922Z"}
{"question_id": "tqa_rc_validation_40", "question": "Otis Barton was a pioneer in exploring where?", "ground_truth": ["Underwater", "Under water", "Underwater life", "Undersea"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The deep sea, specifically in a submersible vessel called the Bathysphere", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The deep sea, specifically in the bathysphere", "The deep sea, specifically in a submersible vessel called the Bathysphere", "The deep sea, specifically in a submersible vessel called the Bathysphere", "The deep sea", "The deep sea, specifically in the bathyscaphe, beneath the surface of the Pacific Ocean", "The deep sea", "The deep sea, specifically in a submersible vessel called the Bathysphere", "The deep sea, specifically in the Bathysphere", "The deep sea, specifically in a submersible vessel called the Bathysphere", "The deep sea"], "equivalence_results": ["same", "same", "same", "same", "different", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:58:15.727268Z"}
{"question_id": "tqa_rc_validation_40", "question": "Otis Barton was a pioneer in exploring where?", "ground_truth": ["Underwater", "Under water", "Underwater life", "Undersea"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The deep sea in a bathysphere", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The deep sea", "The deep sea in a bathysphere", "The deep sea", "The deep sea", "The deep sea in a bathysphere", "The deep sea", "The deep sea", "The deep sea", "The deep sea in a bathysphere", "The deep sea in a bathysphere"], "equivalence_results": ["different", "same", "different", "different", "same", "different", "different", "different", "same", "same"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:58:39.367167Z"}
{"question_id": "tqa_rc_validation_40", "question": "Otis Barton was a pioneer in exploring where?", "ground_truth": ["Underwater", "Under water", "Underwater life", "Undersea"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The ocean in a submersible vessel", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The ocean depths in a submersible vessel, specifically the bathysphere", "Cave diving", "The cave", "The cave of Mammoth Cave in Kentucky", "The ocean by submersible", "The cave system", "The world's oceans, particularly the ocean depths via the bathysphere", "The deep sea, particularly by submersible vessel", "Cave diving", "Cave diving"], "equivalence_results": ["different", "different", "different", "different", "same", "different", "different", "same", "different", "different"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T02:58:56.504294Z"}
{"question_id": "tqa_rc_validation_41", "question": "Where in England was actor Nigel Hawthorne born?", "ground_truth": ["Coventry", "Cofantre", "Coventry (city)", "Coventry, Warwickshire", "Coventry, UK", "Coventry, England", "City of Coventry", "County Borough of Coventry", "Coventry (borough)", "Coventry City council", "Coventry, United Kingdom", "Metropolitan Borough of Coventry", "coventry uk", "coventry united kingdom", "coventry borough", "coventry city", "coventry england", "coventry warwickshire"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Coventry, Warwickshire, England", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:58:57.445578Z"}
{"question_id": "tqa_rc_validation_41", "question": "Where in England was actor Nigel Hawthorne born?", "ground_truth": ["Coventry", "Cofantre", "Coventry (city)", "Coventry, Warwickshire", "Coventry, UK", "Coventry, England", "City of Coventry", "County Borough of Coventry", "Coventry (borough)", "Coventry City council", "Coventry, United Kingdom", "Metropolitan Borough of Coventry", "coventry uk", "coventry united kingdom", "coventry borough", "coventry city", "coventry england", "coventry warwickshire"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Coventry", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:58:58.430506Z"}
{"question_id": "tqa_rc_validation_41", "question": "Where in England was actor Nigel Hawthorne born?", "ground_truth": ["Coventry", "Cofantre", "Coventry (city)", "Coventry, Warwickshire", "Coventry, UK", "Coventry, England", "City of Coventry", "County Borough of Coventry", "Coventry (borough)", "Coventry City council", "Coventry, United Kingdom", "Metropolitan Borough of Coventry", "coventry uk", "coventry united kingdom", "coventry borough", "coventry city", "coventry england", "coventry warwickshire"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Coventry", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:58:58.646195Z"}
{"question_id": "tqa_rc_validation_41", "question": "Where in England was actor Nigel Hawthorne born?", "ground_truth": ["Coventry", "Cofantre", "Coventry (city)", "Coventry, Warwickshire", "Coventry, UK", "Coventry, England", "City of Coventry", "County Borough of Coventry", "Coventry (borough)", "Coventry City council", "Coventry, United Kingdom", "Metropolitan Borough of Coventry", "coventry uk", "coventry united kingdom", "coventry borough", "coventry city", "coventry england", "coventry warwickshire"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Coventry", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:58:59.809564Z"}
{"question_id": "tqa_rc_validation_41", "question": "Where in England was actor Nigel Hawthorne born?", "ground_truth": ["Coventry", "Cofantre", "Coventry (city)", "Coventry, Warwickshire", "Coventry, UK", "Coventry, England", "City of Coventry", "County Borough of Coventry", "Coventry (borough)", "Coventry City council", "Coventry, United Kingdom", "Metropolitan Borough of Coventry", "coventry uk", "coventry united kingdom", "coventry borough", "coventry city", "coventry england", "coventry warwickshire"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Coventry", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:59:00.672665Z"}
{"question_id": "tqa_rc_validation_42", "question": "What mythological beast has the head of a man, the body of a lion, and the tail and feet of a dragon?", "ground_truth": ["A manticore", "The Manticore", "manticore"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Chimera", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Chimera", "Chimera", "Chimera", "Chimera", "Chimera", "Chimera", "The Chimera", "Chimera", "Chimera", "Chimera"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:59:18.422625Z"}
{"question_id": "tqa_rc_validation_42", "question": "What mythological beast has the head of a man, the body of a lion, and the tail and feet of a dragon?", "ground_truth": ["A manticore", "The Manticore", "manticore"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Manticore", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:59:20.361991Z"}
{"question_id": "tqa_rc_validation_42", "question": "What mythological beast has the head of a man, the body of a lion, and the tail and feet of a dragon?", "ground_truth": ["A manticore", "The Manticore", "manticore"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Chimera", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Chimera", "Chimera", "Sphinx", "Chimera", "Chimera", "Sphinx, but more likely a Chimera's variation or a more specific creature such as a Chimera or a creature from a different mythology like the Chinese \"Qilin\" is not it, the most accurate is likely the \"Chimera-like", "Chimera", "Chimera", "Sphinx (or Chimera, but more specifically the Chimera has the head of a lion and a snake, the body of a goat, and the tail of a serpent; however, the closest match is the Sphinx) -> A more accurate", "Chimera"], "equivalence_results": ["same", "same", "different", "same", "same", "different", "same", "same", "different", "same"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:59:30.343323Z"}
{"question_id": "tqa_rc_validation_42", "question": "What mythological beast has the head of a man, the body of a lion, and the tail and feet of a dragon?", "ground_truth": ["A manticore", "The Manticore", "manticore"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Manticore", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:59:31.800593Z"}
{"question_id": "tqa_rc_validation_42", "question": "What mythological beast has the head of a man, the body of a lion, and the tail and feet of a dragon?", "ground_truth": ["A manticore", "The Manticore", "manticore"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Manticore", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:59:32.520029Z"}
{"question_id": "tqa_rc_validation_43", "question": "In Greek mythology, who were Arges, Brontes and Steropes?", "ground_truth": ["Cyclopes", "Cyclopes (disambiguation)", "cyclopes disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "They were the three original Cyclopes, one-eyed giant smiths who forged Zeus’s thunderbolts", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["They were the three Cyclopes who forged Zeus’s thunderbolts", "They were the three original Cyclopes, one‑eyed giant craftsmen who forged Zeus’s thunderbolts", "They were the three original Cyclopes, one-eyed giant smiths who forged Zeus’s thunderbolts", "The three Cyclopes who forged Zeus’s thunderbolts", "They were the three Cyclopes who forged Zeus’s thunderbolts", "The three Cyclopes who forged Zeus’s thunderbolts", "They were the three original Cyclopes, one-eyed giant smiths who forged Zeus’s thunderbolts", "They were the three Cyclopes (one-eyed giants) who forged Zeus’s thunderbolts", "They were the three Cyclopes who forged Zeus’s thunderbolt", "They were the three original Cyclopes, one‑eyed giant smiths who forged Zeus’s thunderbolts"], "equivalence_results": ["same", "same", "same", "same", "different", "same", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T02:59:54.859208Z"}
{"question_id": "tqa_rc_validation_43", "question": "In Greek mythology, who were Arges, Brontes and Steropes?", "ground_truth": ["Cyclopes", "Cyclopes (disambiguation)", "cyclopes disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Cyclopes", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:59:56.493641Z"}
{"question_id": "tqa_rc_validation_43", "question": "In Greek mythology, who were Arges, Brontes and Steropes?", "ground_truth": ["Cyclopes", "Cyclopes (disambiguation)", "cyclopes disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Cyclopes", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:59:56.944016Z"}
{"question_id": "tqa_rc_validation_43", "question": "In Greek mythology, who were Arges, Brontes and Steropes?", "ground_truth": ["Cyclopes", "Cyclopes (disambiguation)", "cyclopes disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Cyclopes", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T02:59:58.201580Z"}
{"question_id": "tqa_rc_validation_43", "question": "In Greek mythology, who were Arges, Brontes and Steropes?", "ground_truth": ["Cyclopes", "Cyclopes (disambiguation)", "cyclopes disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Cyclopes, sons of the Titan Uranus", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Cyclopes, sons of the Titans Uranus and Gaea", "The Cyclopes", "The Cyclopes, three one-eyed giants", "The three Cyclopes, sons of the Titans Uranus and Gaea", "The Cyclopes, sons of the Titan Uranus", "The Cyclopes, the one-eyed sons of Uranus", "The Cyclopes, sons of the Titans Cronus and Anymone", "The Cyclopes, three one-eyed giants, sons of the Titans Uranus and Gaea", "The Cyclopes, sons of the Titans Uranus and Gaea", "The Cyclopes, sons of the Titans Uranus and Gaea"], "equivalence_results": ["different", "different", "different", "different", "same", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 1, "num_different": 9, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.1, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:00:16.226755Z"}
{"question_id": "tqa_rc_validation_44", "question": "Which musician founded the Red Hot Peppers?", "ground_truth": ["Jelly Roll Morton", "Ferdinand Joseph La Menthe", "Louise Monette", "Ferdinand Morton", "Ferdinand %22Jelly Roll%22 Morton", "F.P. Lamothe", "Ferdinand Lamothe", "Jellyroll Morton", "Ferdinand Joseph Morton", "Joseph Ferdinand Morton", "Ferdinand Joseph Lamothe", "Jelly-Roll Morton", "f p lamothe", "ferdinand 22jelly roll 22 morton"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Flea", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Anthony Kiedis", "Anthony Kiedis", "Anthony Kiedis", "Anthony Kiedis", "Anthony Kiedis", "Anthony Kiedis", "Anthony Kiedis", "Anthony Kiedis", "Anthony Kiedis", "Anthony Kiedis"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:00:35.990951Z"}
{"question_id": "tqa_rc_validation_44", "question": "Which musician founded the Red Hot Peppers?", "ground_truth": ["Jelly Roll Morton", "Ferdinand Joseph La Menthe", "Louise Monette", "Ferdinand Morton", "Ferdinand %22Jelly Roll%22 Morton", "F.P. Lamothe", "Ferdinand Lamothe", "Jellyroll Morton", "Ferdinand Joseph Morton", "Joseph Ferdinand Morton", "Ferdinand Joseph Lamothe", "Jelly-Roll Morton", "f p lamothe", "ferdinand 22jelly roll 22 morton"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Jelly Roll Morton", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:00:37.813224Z"}
{"question_id": "tqa_rc_validation_44", "question": "Which musician founded the Red Hot Peppers?", "ground_truth": ["Jelly Roll Morton", "Ferdinand Joseph La Menthe", "Louise Monette", "Ferdinand Morton", "Ferdinand %22Jelly Roll%22 Morton", "F.P. Lamothe", "Ferdinand Lamothe", "Jellyroll Morton", "Ferdinand Joseph Morton", "Joseph Ferdinand Morton", "Ferdinand Joseph Lamothe", "Jelly-Roll Morton", "f p lamothe", "ferdinand 22jelly roll 22 morton"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Jelly Roll Morton", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:00:38.090461Z"}
{"question_id": "tqa_rc_validation_44", "question": "Which musician founded the Red Hot Peppers?", "ground_truth": ["Jelly Roll Morton", "Ferdinand Joseph La Menthe", "Louise Monette", "Ferdinand Morton", "Ferdinand %22Jelly Roll%22 Morton", "F.P. Lamothe", "Ferdinand Lamothe", "Jellyroll Morton", "Ferdinand Joseph Morton", "Joseph Ferdinand Morton", "Ferdinand Joseph Lamothe", "Jelly-Roll Morton", "f p lamothe", "ferdinand 22jelly roll 22 morton"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Jelly Roll Morton", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:00:39.324702Z"}
{"question_id": "tqa_rc_validation_44", "question": "Which musician founded the Red Hot Peppers?", "ground_truth": ["Jelly Roll Morton", "Ferdinand Joseph La Menthe", "Louise Monette", "Ferdinand Morton", "Ferdinand %22Jelly Roll%22 Morton", "F.P. Lamothe", "Ferdinand Lamothe", "Jellyroll Morton", "Ferdinand Joseph Morton", "Joseph Ferdinand Morton", "Ferdinand Joseph Lamothe", "Jelly-Roll Morton", "f p lamothe", "ferdinand 22jelly roll 22 morton"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Anthony Kiedis", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Anthony Kiedis", "Anthony Kiedis, Flea, and Hillel Slovak founded the band", "Anthony Kiedis and Flea founded the Red Hot Chili Peppers, but the original members included Anthony Kiedis, Flea, Hillel Slovak, and Jack Irons, however Anthony Kiedis and Flea, formed the band", "Anthony Kiedis founded the Red Hot Chili Peppers", "Anthony Kiedis, Flea, Hillel Slovak, Jack Irons, and John Frusciante, but the band was originally formed by Anthony Kiedis, Hillel Slovak, and Jack Irons, then Michael Balz", "Anthony Kiedis and Flea founded the Red Hot Chili Peppers, but the band was actually formed by Hillel Slovak and Anthony Kiedis, with Slovak and Flea both being integral from the very start, however Flea, was", "Anthony Kiedis", "Anthony Kiedis and Flea, however, the band was actually formed by Anthony Kiedis, Flea, Hillel Slovak, Jack Irons, and John Frusciante's predecessor, DeWayne McKnight and later John", "Anthony Kiedis founded the Red Hot Chili Peppers, but Anthony Kiedis was already in the band when they formed", "Anthony Kiedis"], "equivalence_results": ["same", "different", "different", "same", "different", "different", "same", "different", "different", "same"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:00:58.021757Z"}
{"question_id": "tqa_rc_validation_45", "question": "Where did the Shinning Path terrorists operate?", "ground_truth": ["Peru", "Lower Peru", "Name of Peru", "Republic of Peru", "Etymology of Peru", "ISO 3166-1:PE", "Piruw", "Peruano", "República del Perú", "El Perú", "Republic of Perú", "Peruvian Republic", "Peruvian", "Péru", "Piruw Ripuwlika", "El Peru", "Perú", "Perù", "Piruw Suyu", "Pérou", "Peruvia", "iso 3166 1 pe"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Peru", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:00:58.786132Z"}
{"question_id": "tqa_rc_validation_45", "question": "Where did the Shinning Path terrorists operate?", "ground_truth": ["Peru", "Lower Peru", "Name of Peru", "Republic of Peru", "Etymology of Peru", "ISO 3166-1:PE", "Piruw", "Peruano", "República del Perú", "El Perú", "Republic of Perú", "Peruvian Republic", "Peruvian", "Péru", "Piruw Ripuwlika", "El Peru", "Perú", "Perù", "Piruw Suyu", "Pérou", "Peruvia", "iso 3166 1 pe"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Peru", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:00.411903Z"}
{"question_id": "tqa_rc_validation_45", "question": "Where did the Shinning Path terrorists operate?", "ground_truth": ["Peru", "Lower Peru", "Name of Peru", "Republic of Peru", "Etymology of Peru", "ISO 3166-1:PE", "Piruw", "Peruano", "República del Perú", "El Perú", "Republic of Perú", "Peruvian Republic", "Peruvian", "Péru", "Piruw Ripuwlika", "El Peru", "Perú", "Perù", "Piruw Suyu", "Pérou", "Peruvia", "iso 3166 1 pe"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Peru", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:00.826538Z"}
{"question_id": "tqa_rc_validation_45", "question": "Where did the Shinning Path terrorists operate?", "ground_truth": ["Peru", "Lower Peru", "Name of Peru", "Republic of Peru", "Etymology of Peru", "ISO 3166-1:PE", "Piruw", "Peruano", "República del Perú", "El Perú", "Republic of Perú", "Peruvian Republic", "Peruvian", "Péru", "Piruw Ripuwlika", "El Peru", "Perú", "Perù", "Piruw Suyu", "Pérou", "Peruvia", "iso 3166 1 pe"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Peru", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:02.178523Z"}
{"question_id": "tqa_rc_validation_45", "question": "Where did the Shinning Path terrorists operate?", "ground_truth": ["Peru", "Lower Peru", "Name of Peru", "Republic of Peru", "Etymology of Peru", "ISO 3166-1:PE", "Piruw", "Peruano", "República del Perú", "El Perú", "Republic of Perú", "Peruvian Republic", "Peruvian", "Péru", "Piruw Ripuwlika", "El Peru", "Perú", "Perù", "Piruw Suyu", "Pérou", "Peruvia", "iso 3166 1 pe"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Peru", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:02.879299Z"}
{"question_id": "tqa_rc_validation_46", "question": "How old was Jimi Hendrix when he died?", "ground_truth": ["27", "twenty-seven", "twenty seven"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "27", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:03.733439Z"}
{"question_id": "tqa_rc_validation_46", "question": "How old was Jimi Hendrix when he died?", "ground_truth": ["27", "twenty-seven", "twenty seven"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "27", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:05.337994Z"}
{"question_id": "tqa_rc_validation_46", "question": "How old was Jimi Hendrix when he died?", "ground_truth": ["27", "twenty-seven", "twenty seven"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "27 years old", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["27", "27", "27 years old", "27 years old", "27", "27 years old", "27", "27 years old", "27 years old", "27 years old"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:01:16.660056Z"}
{"question_id": "tqa_rc_validation_46", "question": "How old was Jimi Hendrix when he died?", "ground_truth": ["27", "twenty-seven", "twenty seven"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "27", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:17.756904Z"}
{"question_id": "tqa_rc_validation_46", "question": "How old was Jimi Hendrix when he died?", "ground_truth": ["27", "twenty-seven", "twenty seven"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "27 years old", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["27 years old", "27 years old", "27 years old", "27 years old", "27 years old", "27 years old", "27 years old", "27", "27 years old", "27"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:01:33.757736Z"}
{"question_id": "tqa_rc_validation_47", "question": "Which Brit broke the land speed record in 1990 in Thrust 2?", "ground_truth": ["Richard Noble"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Richard Noble", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:34.552688Z"}
{"question_id": "tqa_rc_validation_47", "question": "Which Brit broke the land speed record in 1990 in Thrust 2?", "ground_truth": ["Richard Noble"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Richard Noble", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:36.448873Z"}
{"question_id": "tqa_rc_validation_47", "question": "Which Brit broke the land speed record in 1990 in Thrust 2?", "ground_truth": ["Richard Noble"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Richard Noble", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:36.944789Z"}
{"question_id": "tqa_rc_validation_47", "question": "Which Brit broke the land speed record in 1990 in Thrust 2?", "ground_truth": ["Richard Noble"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Richard Noble", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:38.079155Z"}
{"question_id": "tqa_rc_validation_47", "question": "Which Brit broke the land speed record in 1990 in Thrust 2?", "ground_truth": ["Richard Noble"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Richard Noble", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:38.896497Z"}
{"question_id": "tqa_rc_validation_48", "question": "In which state was Gene Vincent born?", "ground_truth": ["Virginia", "US-VA", "State of Virginia", "Virginia, USA", "Tenth State", "Religion in Virginia", "Virginia (USA state)", "Virginia (state)", "Commonwealth of VA", "Rest of Virginia", "Mother of Presidents", "The Old Dominion", "VA (state)", "Commonwealth of Virginia", "Virginian Commonwealth", "The Mother of Presidents", "Virginia, United States", "Council of Virginia", "Sports in Virginia", "Viginia", "Virginia (U.S. state)", "10th State", "Virgina", "The Commonwealth of Virginia", "VA, USA", "va state", "va usa", "virginia usa state", "us va", "virginia united states", "virginia usa", "old dominion", "virginia state", "virginia u s state"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Virginia", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:43.043140Z"}
{"question_id": "tqa_rc_validation_48", "question": "In which state was Gene Vincent born?", "ground_truth": ["Virginia", "US-VA", "State of Virginia", "Virginia, USA", "Tenth State", "Religion in Virginia", "Virginia (USA state)", "Virginia (state)", "Commonwealth of VA", "Rest of Virginia", "Mother of Presidents", "The Old Dominion", "VA (state)", "Commonwealth of Virginia", "Virginian Commonwealth", "The Mother of Presidents", "Virginia, United States", "Council of Virginia", "Sports in Virginia", "Viginia", "Virginia (U.S. state)", "10th State", "Virgina", "The Commonwealth of Virginia", "VA, USA", "va state", "va usa", "virginia usa state", "us va", "virginia united states", "virginia usa", "old dominion", "virginia state", "virginia u s state"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Virginia", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:44.623050Z"}
{"question_id": "tqa_rc_validation_48", "question": "In which state was Gene Vincent born?", "ground_truth": ["Virginia", "US-VA", "State of Virginia", "Virginia, USA", "Tenth State", "Religion in Virginia", "Virginia (USA state)", "Virginia (state)", "Commonwealth of VA", "Rest of Virginia", "Mother of Presidents", "The Old Dominion", "VA (state)", "Commonwealth of Virginia", "Virginian Commonwealth", "The Mother of Presidents", "Virginia, United States", "Council of Virginia", "Sports in Virginia", "Viginia", "Virginia (U.S. state)", "10th State", "Virgina", "The Commonwealth of Virginia", "VA, USA", "va state", "va usa", "virginia usa state", "us va", "virginia united states", "virginia usa", "old dominion", "virginia state", "virginia u s state"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Virginia", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:44.862993Z"}
{"question_id": "tqa_rc_validation_48", "question": "In which state was Gene Vincent born?", "ground_truth": ["Virginia", "US-VA", "State of Virginia", "Virginia, USA", "Tenth State", "Religion in Virginia", "Virginia (USA state)", "Virginia (state)", "Commonwealth of VA", "Rest of Virginia", "Mother of Presidents", "The Old Dominion", "VA (state)", "Commonwealth of Virginia", "Virginian Commonwealth", "The Mother of Presidents", "Virginia, United States", "Council of Virginia", "Sports in Virginia", "Viginia", "Virginia (U.S. state)", "10th State", "Virgina", "The Commonwealth of Virginia", "VA, USA", "va state", "va usa", "virginia usa state", "us va", "virginia united states", "virginia usa", "old dominion", "virginia state", "virginia u s state"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Virginia", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:45.939665Z"}
{"question_id": "tqa_rc_validation_48", "question": "In which state was Gene Vincent born?", "ground_truth": ["Virginia", "US-VA", "State of Virginia", "Virginia, USA", "Tenth State", "Religion in Virginia", "Virginia (USA state)", "Virginia (state)", "Commonwealth of VA", "Rest of Virginia", "Mother of Presidents", "The Old Dominion", "VA (state)", "Commonwealth of Virginia", "Virginian Commonwealth", "The Mother of Presidents", "Virginia, United States", "Council of Virginia", "Sports in Virginia", "Viginia", "Virginia (U.S. state)", "10th State", "Virgina", "The Commonwealth of Virginia", "VA, USA", "va state", "va usa", "virginia usa state", "us va", "virginia united states", "virginia usa", "old dominion", "virginia state", "virginia u s state"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Virginia", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:46.765307Z"}
{"question_id": "tqa_rc_validation_49", "question": "How was the European Recovery Program in the 1940s more commonly known?", "ground_truth": ["Marshall Plan", "European Recovery Programme", "The marshal plan", "Marshall Aid", "European Recovery Program", "Marshall Paln", "The Marshall Plan", "European recovery act", "Marshal plan", "Organization for European Economic Recovery", "Ministère de la Reconstruction", "Marshall aid plan", "Economic Cooperation Act of 1948", "Operation Rathole"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Marshall Plan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:48.050692Z"}
{"question_id": "tqa_rc_validation_49", "question": "How was the European Recovery Program in the 1940s more commonly known?", "ground_truth": ["Marshall Plan", "European Recovery Programme", "The marshal plan", "Marshall Aid", "European Recovery Program", "Marshall Paln", "The Marshall Plan", "European recovery act", "Marshal plan", "Organization for European Economic Recovery", "Ministère de la Reconstruction", "Marshall aid plan", "Economic Cooperation Act of 1948", "Operation Rathole"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The Marshall Plan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:50.040865Z"}
{"question_id": "tqa_rc_validation_49", "question": "How was the European Recovery Program in the 1940s more commonly known?", "ground_truth": ["Marshall Plan", "European Recovery Programme", "The marshal plan", "Marshall Aid", "European Recovery Program", "Marshall Paln", "The Marshall Plan", "European recovery act", "Marshal plan", "Organization for European Economic Recovery", "Ministère de la Reconstruction", "Marshall aid plan", "Economic Cooperation Act of 1948", "Operation Rathole"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Marshall Plan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:50.255775Z"}
{"question_id": "tqa_rc_validation_49", "question": "How was the European Recovery Program in the 1940s more commonly known?", "ground_truth": ["Marshall Plan", "European Recovery Programme", "The marshal plan", "Marshall Aid", "European Recovery Program", "Marshall Paln", "The Marshall Plan", "European recovery act", "Marshal plan", "Organization for European Economic Recovery", "Ministère de la Reconstruction", "Marshall aid plan", "Economic Cooperation Act of 1948", "Operation Rathole"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The Marshall Plan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:51.242783Z"}
{"question_id": "tqa_rc_validation_49", "question": "How was the European Recovery Program in the 1940s more commonly known?", "ground_truth": ["Marshall Plan", "European Recovery Programme", "The marshal plan", "Marshall Aid", "European Recovery Program", "Marshall Paln", "The Marshall Plan", "European recovery act", "Marshal plan", "Organization for European Economic Recovery", "Ministère de la Reconstruction", "Marshall aid plan", "Economic Cooperation Act of 1948", "Operation Rathole"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Marshall Plan", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:52.140179Z"}
{"question_id": "tqa_rc_validation_50", "question": "Brandon Lee died during the making of which movie?", "ground_truth": ["The Crow", "The Crow: Dead Time", "The Crow (2016 film)", "crow", "crow dead time", "crow 2016 film"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Crow", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:52.930076Z"}
{"question_id": "tqa_rc_validation_50", "question": "Brandon Lee died during the making of which movie?", "ground_truth": ["The Crow", "The Crow: Dead Time", "The Crow (2016 film)", "crow", "crow dead time", "crow 2016 film"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The Crow", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:53.815030Z"}
{"question_id": "tqa_rc_validation_50", "question": "Brandon Lee died during the making of which movie?", "ground_truth": ["The Crow", "The Crow: Dead Time", "The Crow (2016 film)", "crow", "crow dead time", "crow 2016 film"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Crow", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:53.962117Z"}
{"question_id": "tqa_rc_validation_50", "question": "Brandon Lee died during the making of which movie?", "ground_truth": ["The Crow", "The Crow: Dead Time", "The Crow (2016 film)", "crow", "crow dead time", "crow 2016 film"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The Crow", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:55.288792Z"}
{"question_id": "tqa_rc_validation_50", "question": "Brandon Lee died during the making of which movie?", "ground_truth": ["The Crow", "The Crow: Dead Time", "The Crow (2016 film)", "crow", "crow dead time", "crow 2016 film"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Crow", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:55.950437Z"}
{"question_id": "tqa_rc_validation_51", "question": "Who had a 70s No 1 hit with Let's Do It Again?", "ground_truth": ["The Staple Singers", "Staple Singers", "The Staples Singers", "Staples Singers", "Cleotha Staples"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Staple Singers", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:56.760825Z"}
{"question_id": "tqa_rc_validation_51", "question": "Who had a 70s No 1 hit with Let's Do It Again?", "ground_truth": ["The Staple Singers", "Staple Singers", "The Staples Singers", "Staples Singers", "Cleotha Staples"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The Staple Singers", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:58.621632Z"}
{"question_id": "tqa_rc_validation_51", "question": "Who had a 70s No 1 hit with Let's Do It Again?", "ground_truth": ["The Staple Singers", "Staple Singers", "The Staples Singers", "Staples Singers", "Cleotha Staples"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Staple Singers", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:58.772888Z"}
{"question_id": "tqa_rc_validation_51", "question": "Who had a 70s No 1 hit with Let's Do It Again?", "ground_truth": ["The Staple Singers", "Staple Singers", "The Staples Singers", "Staples Singers", "Cleotha Staples"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The Staple Singers", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:01:59.982341Z"}
{"question_id": "tqa_rc_validation_51", "question": "Who had a 70s No 1 hit with Let's Do It Again?", "ground_truth": ["The Staple Singers", "Staple Singers", "The Staples Singers", "Staples Singers", "Cleotha Staples"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Staple Singers", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:00.895479Z"}
{"question_id": "tqa_rc_validation_52", "question": "Who had a Too Legit To Quit Tour?", "ground_truth": ["MC Hammer", "M. C. Hammer", "Hammer (rapper)", "Family Affair(MC Hammer album)", "Too Tight(MC Hammer album)", "Stanley Burrell", "Stanley Kirk Burrell", "M c hammer", "Mchammer", "You Shouldn't Touch This", "M.C. Hammer", "Family Affair (MC Hammer album)", "Stanley K. Burrell", "Wiredoo", "The hammer crew", "Too Tight (MC Hammer album)", "too tight mc hammer album", "family affair mc hammer album", "hammer rapper", "stanley k burrell", "hammer crew", "you shouldn t touch this"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "MC Hammer", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:01.748629Z"}
{"question_id": "tqa_rc_validation_52", "question": "Who had a Too Legit To Quit Tour?", "ground_truth": ["MC Hammer", "M. C. Hammer", "Hammer (rapper)", "Family Affair(MC Hammer album)", "Too Tight(MC Hammer album)", "Stanley Burrell", "Stanley Kirk Burrell", "M c hammer", "Mchammer", "You Shouldn't Touch This", "M.C. Hammer", "Family Affair (MC Hammer album)", "Stanley K. Burrell", "Wiredoo", "The hammer crew", "Too Tight (MC Hammer album)", "too tight mc hammer album", "family affair mc hammer album", "hammer rapper", "stanley k burrell", "hammer crew", "you shouldn t touch this"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "MC Hammer", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:03.203290Z"}
{"question_id": "tqa_rc_validation_52", "question": "Who had a Too Legit To Quit Tour?", "ground_truth": ["MC Hammer", "M. C. Hammer", "Hammer (rapper)", "Family Affair(MC Hammer album)", "Too Tight(MC Hammer album)", "Stanley Burrell", "Stanley Kirk Burrell", "M c hammer", "Mchammer", "You Shouldn't Touch This", "M.C. Hammer", "Family Affair (MC Hammer album)", "Stanley K. Burrell", "Wiredoo", "The hammer crew", "Too Tight (MC Hammer album)", "too tight mc hammer album", "family affair mc hammer album", "hammer rapper", "stanley k burrell", "hammer crew", "you shouldn t touch this"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "MC Hammer", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:03.353597Z"}
{"question_id": "tqa_rc_validation_52", "question": "Who had a Too Legit To Quit Tour?", "ground_truth": ["MC Hammer", "M. C. Hammer", "Hammer (rapper)", "Family Affair(MC Hammer album)", "Too Tight(MC Hammer album)", "Stanley Burrell", "Stanley Kirk Burrell", "M c hammer", "Mchammer", "You Shouldn't Touch This", "M.C. Hammer", "Family Affair (MC Hammer album)", "Stanley K. Burrell", "Wiredoo", "The hammer crew", "Too Tight (MC Hammer album)", "too tight mc hammer album", "family affair mc hammer album", "hammer rapper", "stanley k burrell", "hammer crew", "you shouldn t touch this"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "MC Hammer", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:05.069472Z"}
{"question_id": "tqa_rc_validation_52", "question": "Who had a Too Legit To Quit Tour?", "ground_truth": ["MC Hammer", "M. C. Hammer", "Hammer (rapper)", "Family Affair(MC Hammer album)", "Too Tight(MC Hammer album)", "Stanley Burrell", "Stanley Kirk Burrell", "M c hammer", "Mchammer", "You Shouldn't Touch This", "M.C. Hammer", "Family Affair (MC Hammer album)", "Stanley K. Burrell", "Wiredoo", "The hammer crew", "Too Tight (MC Hammer album)", "too tight mc hammer album", "family affair mc hammer album", "hammer rapper", "stanley k burrell", "hammer crew", "you shouldn t touch this"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "MC Hammer", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:05.922544Z"}
{"question_id": "tqa_rc_validation_53", "question": "\"According to Rudyard Kipling what were the \"\"two imposters\"\" to meet and treat the same day?\"", "ground_truth": ["Triumph and Disaster"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Triumph and Disaster", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:06.854258Z"}
{"question_id": "tqa_rc_validation_53", "question": "\"According to Rudyard Kipling what were the \"\"two imposters\"\" to meet and treat the same day?\"", "ground_truth": ["Triumph and Disaster"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Triumph and Disaster", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:08.737710Z"}
{"question_id": "tqa_rc_validation_53", "question": "\"According to Rudyard Kipling what were the \"\"two imposters\"\" to meet and treat the same day?\"", "ground_truth": ["Triumph and Disaster"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Triumph and Disaster", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:08.961625Z"}
{"question_id": "tqa_rc_validation_53", "question": "\"According to Rudyard Kipling what were the \"\"two imposters\"\" to meet and treat the same day?\"", "ground_truth": ["Triumph and Disaster"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Triumph and Disaster", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:10.365547Z"}
{"question_id": "tqa_rc_validation_53", "question": "\"According to Rudyard Kipling what were the \"\"two imposters\"\" to meet and treat the same day?\"", "ground_truth": ["Triumph and Disaster"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Triumph and Disaster", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:11.197872Z"}
{"question_id": "tqa_rc_validation_54", "question": "Who is the most successful UK solo artist in the USA?", "ground_truth": ["Elton John", "Sir Elton", "Rockaday Johnny", "Elthon John", "Eltonjohn", "List of Elton John awards", "John, Elton", "Reggie Dwight", "Lord Choc Ice", "Redget Buntovan", "Elton John's discography", "Elton john discography", "Reginald K. Dwight", "Mrs. Elton John", "Lady Choc Ice", "Reg Kenneth Dwight", "Renate Blauel", "Reginald Kenneth Dwight", "Ann Orson", "Reg Dwight", "Elton John Band", "Reginald Dwight", "Sir John Elton", "Reginald Kenneth", "Elton Hercules John", "Sir Elton Hercules John CBE", "Elton H. John", "Nancy Treadlight", "Sir Elton John", "Kenneth Dwight", "john elton", "reginald k dwight", "mrs elton john", "elton h john", "elton john s discography"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Elton John", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:12.019504Z"}
{"question_id": "tqa_rc_validation_54", "question": "Who is the most successful UK solo artist in the USA?", "ground_truth": ["Elton John", "Sir Elton", "Rockaday Johnny", "Elthon John", "Eltonjohn", "List of Elton John awards", "John, Elton", "Reggie Dwight", "Lord Choc Ice", "Redget Buntovan", "Elton John's discography", "Elton john discography", "Reginald K. Dwight", "Mrs. Elton John", "Lady Choc Ice", "Reg Kenneth Dwight", "Renate Blauel", "Reginald Kenneth Dwight", "Ann Orson", "Reg Dwight", "Elton John Band", "Reginald Dwight", "Sir John Elton", "Reginald Kenneth", "Elton Hercules John", "Sir Elton Hercules John CBE", "Elton H. John", "Nancy Treadlight", "Sir Elton John", "Kenneth Dwight", "john elton", "reginald k dwight", "mrs elton john", "elton h john", "elton john s discography"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Elton John", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:13.735371Z"}
{"question_id": "tqa_rc_validation_54", "question": "Who is the most successful UK solo artist in the USA?", "ground_truth": ["Elton John", "Sir Elton", "Rockaday Johnny", "Elthon John", "Eltonjohn", "List of Elton John awards", "John, Elton", "Reggie Dwight", "Lord Choc Ice", "Redget Buntovan", "Elton John's discography", "Elton john discography", "Reginald K. Dwight", "Mrs. Elton John", "Lady Choc Ice", "Reg Kenneth Dwight", "Renate Blauel", "Reginald Kenneth Dwight", "Ann Orson", "Reg Dwight", "Elton John Band", "Reginald Dwight", "Sir John Elton", "Reginald Kenneth", "Elton Hercules John", "Sir Elton Hercules John CBE", "Elton H. John", "Nancy Treadlight", "Sir Elton John", "Kenneth Dwight", "john elton", "reginald k dwight", "mrs elton john", "elton h john", "elton john s discography"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Robbie Williams", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Robbie Williams", "Robbie Williams", "Sam Fender, no, it's actually Robbie Williams and also other sources state Adele", "Robbie Williams", "Robbie Williams", "Robbie Williams", "Robbie Williams", "Robbie Williams", "Robbie Williams", "Robbie Williams"], "equivalence_results": ["same", "same", "unclear", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 0, "num_unclear": 1, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:02:24.379570Z"}
{"question_id": "tqa_rc_validation_54", "question": "Who is the most successful UK solo artist in the USA?", "ground_truth": ["Elton John", "Sir Elton", "Rockaday Johnny", "Elthon John", "Eltonjohn", "List of Elton John awards", "John, Elton", "Reggie Dwight", "Lord Choc Ice", "Redget Buntovan", "Elton John's discography", "Elton john discography", "Reginald K. Dwight", "Mrs. Elton John", "Lady Choc Ice", "Reg Kenneth Dwight", "Renate Blauel", "Reginald Kenneth Dwight", "Ann Orson", "Reg Dwight", "Elton John Band", "Reginald Dwight", "Sir John Elton", "Reginald Kenneth", "Elton Hercules John", "Sir Elton Hercules John CBE", "Elton H. John", "Nancy Treadlight", "Sir Elton John", "Kenneth Dwight", "john elton", "reginald k dwight", "mrs elton john", "elton h john", "elton john s discography"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Elton John", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:25.902416Z"}
{"question_id": "tqa_rc_validation_54", "question": "Who is the most successful UK solo artist in the USA?", "ground_truth": ["Elton John", "Sir Elton", "Rockaday Johnny", "Elthon John", "Eltonjohn", "List of Elton John awards", "John, Elton", "Reggie Dwight", "Lord Choc Ice", "Redget Buntovan", "Elton John's discography", "Elton john discography", "Reginald K. Dwight", "Mrs. Elton John", "Lady Choc Ice", "Reg Kenneth Dwight", "Renate Blauel", "Reginald Kenneth Dwight", "Ann Orson", "Reg Dwight", "Elton John Band", "Reginald Dwight", "Sir John Elton", "Reginald Kenneth", "Elton Hercules John", "Sir Elton Hercules John CBE", "Elton H. John", "Nancy Treadlight", "Sir Elton John", "Kenneth Dwight", "john elton", "reginald k dwight", "mrs elton john", "elton h john", "elton john s discography"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Elton John", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:26.980770Z"}
{"question_id": "tqa_rc_validation_55", "question": "Which country does the airline TAAG come from?", "ground_truth": ["Angola", "Angloa", "Etymology of Angola", "Republic of Angola", "Sport in Angola", "The Republic of Angola", "ISO 3166-1:AO", "iso 3166 1 ao"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Angola", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:27.712206Z"}
{"question_id": "tqa_rc_validation_55", "question": "Which country does the airline TAAG come from?", "ground_truth": ["Angola", "Angloa", "Etymology of Angola", "Republic of Angola", "Sport in Angola", "The Republic of Angola", "ISO 3166-1:AO", "iso 3166 1 ao"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Angola", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:29.324281Z"}
{"question_id": "tqa_rc_validation_55", "question": "Which country does the airline TAAG come from?", "ground_truth": ["Angola", "Angloa", "Etymology of Angola", "Republic of Angola", "Sport in Angola", "The Republic of Angola", "ISO 3166-1:AO", "iso 3166 1 ao"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Angola", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:29.520159Z"}
{"question_id": "tqa_rc_validation_55", "question": "Which country does the airline TAAG come from?", "ground_truth": ["Angola", "Angloa", "Etymology of Angola", "Republic of Angola", "Sport in Angola", "The Republic of Angola", "ISO 3166-1:AO", "iso 3166 1 ao"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Angola", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:30.768294Z"}
{"question_id": "tqa_rc_validation_55", "question": "Which country does the airline TAAG come from?", "ground_truth": ["Angola", "Angloa", "Etymology of Angola", "Republic of Angola", "Sport in Angola", "The Republic of Angola", "ISO 3166-1:AO", "iso 3166 1 ao"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Angola", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:31.413377Z"}
{"question_id": "tqa_rc_validation_56", "question": "Which US No 1 single came from Diana Ross's platinum album Diana?", "ground_truth": ["Upside Down", "Upside Down (Diana Ross song)", "Up side down", "Upside Down (single)", "upside down diana ross song", "upside down single"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Upside Down", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:32.140837Z"}
{"question_id": "tqa_rc_validation_56", "question": "Which US No 1 single came from Diana Ross's platinum album Diana?", "ground_truth": ["Upside Down", "Upside Down (Diana Ross song)", "Up side down", "Upside Down (single)", "upside down diana ross song", "upside down single"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Upside Down", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:33.165964Z"}
{"question_id": "tqa_rc_validation_56", "question": "Which US No 1 single came from Diana Ross's platinum album Diana?", "ground_truth": ["Upside Down", "Upside Down (Diana Ross song)", "Up side down", "Upside Down (single)", "upside down diana ross song", "upside down single"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Upside Down", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:33.355894Z"}
{"question_id": "tqa_rc_validation_56", "question": "Which US No 1 single came from Diana Ross's platinum album Diana?", "ground_truth": ["Upside Down", "Upside Down (Diana Ross song)", "Up side down", "Upside Down (single)", "upside down diana ross song", "upside down single"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Upside Down", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:34.633301Z"}
{"question_id": "tqa_rc_validation_56", "question": "Which US No 1 single came from Diana Ross's platinum album Diana?", "ground_truth": ["Upside Down", "Upside Down (Diana Ross song)", "Up side down", "Upside Down (single)", "upside down diana ross song", "upside down single"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "I'm Coming Out", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Touch by Angela Winbush was not the number one from that album however IAU and  I'll be Good to You  and  Touch   from the 'Diana' album had less success", "\"Ain't No Mountain High Enough\"", "I'm Coming Out", "I'm Coming Out", "I'm Coming Out", "I'm Coming Out", "I'm Coming Out", "\"Endless Love\"", "Upside Down", "I'm Coming Out"], "equivalence_results": ["different", "different", "same", "same", "same", "same", "same", "different", "different", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:02:51.740171Z"}
{"question_id": "tqa_rc_validation_57", "question": "River Phoenix died during the making of which movie?", "ground_truth": ["Dark Blood", "Dark Blood (film)", "dark blood film"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Dark Blood", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:52.617610Z"}
{"question_id": "tqa_rc_validation_57", "question": "River Phoenix died during the making of which movie?", "ground_truth": ["Dark Blood", "Dark Blood (film)", "dark blood film"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Dark Blood", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:54.285322Z"}
{"question_id": "tqa_rc_validation_57", "question": "River Phoenix died during the making of which movie?", "ground_truth": ["Dark Blood", "Dark Blood (film)", "dark blood film"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Dark Blood", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:54.622036Z"}
{"question_id": "tqa_rc_validation_57", "question": "River Phoenix died during the making of which movie?", "ground_truth": ["Dark Blood", "Dark Blood (film)", "dark blood film"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Dark Blood", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:02:55.869459Z"}
{"question_id": "tqa_rc_validation_57", "question": "River Phoenix died during the making of which movie?", "ground_truth": ["Dark Blood", "Dark Blood (film)", "dark blood film"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Darkness", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Darkness", "Darkness", "Dark Blood", "Dark Blood", "Dark Blood", "Darkness", "Darkness", "Dark Blood, but he died while filming the film \"Dark Blood\" and it was unreleased until 2013", "\"Dark Blood\"", "Darkness"], "equivalence_results": ["same", "same", "different", "different", "different", "same", "same", "different", "different", "same"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:03:12.260259Z"}
{"question_id": "tqa_rc_validation_58", "question": "Which artist David was born in Bradford UK?", "ground_truth": ["Hockney", "David Hockney"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "David Hockney", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:03:13.146553Z"}
{"question_id": "tqa_rc_validation_58", "question": "Which artist David was born in Bradford UK?", "ground_truth": ["Hockney", "David Hockney"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "David Hockney", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:03:15.099486Z"}
{"question_id": "tqa_rc_validation_58", "question": "Which artist David was born in Bradford UK?", "ground_truth": ["Hockney", "David Hockney"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Jacqueline David", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["David Hockney", "Jacqueline David", "Jacqueline David", "David Hockney", "David Hockney", "David Hockney", "Jacqueline David", "David Hockney", "David Hockney", "Jacqueline David"], "equivalence_results": ["different", "same", "same", "different", "different", "different", "same", "different", "different", "same"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:03:24.903227Z"}
{"question_id": "tqa_rc_validation_58", "question": "Which artist David was born in Bradford UK?", "ground_truth": ["Hockney", "David Hockney"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "David Hockney", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:03:26.297015Z"}
{"question_id": "tqa_rc_validation_58", "question": "Which artist David was born in Bradford UK?", "ground_truth": ["Hockney", "David Hockney"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "David Hockney", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:03:27.023804Z"}
{"question_id": "tqa_rc_validation_59", "question": "What is Mel Gibson's middle name?", "ground_truth": ["Columcille", "St Colm", "Saint Colm Cille", "Calum Cille", "Collumcille", "Life of St. Columba", "St Columcille", "Columba, Saint", "Columba", "St Colmcille", "Vita Sancti Columbae", "Saint Columba", "Vita Columbae", "Colmcille", "Colum Cille mac Fedelmtheo", "Columbkille", "St. Columcille", "Columba of Iona", "Colm Cille", "Colmkill", "Columb Cille", "Colmekill", "Saint Columb", "Saint Columbkille", "St Colum Cille", "St. Columba", "Scoto-Hibernian Monasteries", "Saint Colmcille", "Life of Columba", "Columbcille", "Saint Columcille", "Colum Cille", "St Columba", "columba saint", "scoto hibernian monasteries", "life of st columba"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Columcille", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:03:28.058103Z"}
{"question_id": "tqa_rc_validation_59", "question": "What is Mel Gibson's middle name?", "ground_truth": ["Columcille", "St Colm", "Saint Colm Cille", "Calum Cille", "Collumcille", "Life of St. Columba", "St Columcille", "Columba, Saint", "Columba", "St Colmcille", "Vita Sancti Columbae", "Saint Columba", "Vita Columbae", "Colmcille", "Colum Cille mac Fedelmtheo", "Columbkille", "St. Columcille", "Columba of Iona", "Colm Cille", "Colmkill", "Columb Cille", "Colmekill", "Saint Columb", "Saint Columbkille", "St Colum Cille", "St. Columba", "Scoto-Hibernian Monasteries", "Saint Colmcille", "Life of Columba", "Columbcille", "Saint Columcille", "Colum Cille", "St Columba", "columba saint", "scoto hibernian monasteries", "life of st columba"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Colm", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:03:29.123566Z"}
{"question_id": "tqa_rc_validation_59", "question": "What is Mel Gibson's middle name?", "ground_truth": ["Columcille", "St Colm", "Saint Colm Cille", "Calum Cille", "Collumcille", "Life of St. Columba", "St Columcille", "Columba, Saint", "Columba", "St Colmcille", "Vita Sancti Columbae", "Saint Columba", "Vita Columbae", "Colmcille", "Colum Cille mac Fedelmtheo", "Columbkille", "St. Columcille", "Columba of Iona", "Colm Cille", "Colmkill", "Columb Cille", "Colmekill", "Saint Columb", "Saint Columbkille", "St Colum Cille", "St. Columba", "Scoto-Hibernian Monasteries", "Saint Colmcille", "Life of Columba", "Columbcille", "Saint Columcille", "Colum Cille", "St Columba", "columba saint", "scoto hibernian monasteries", "life of st columba"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Dene", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Dene", "Dene", "Dene", "Dene", "Dene", "Dunes", "Dene", "Dene", "Dene", "Dene"], "equivalence_results": ["same", "same", "same", "same", "same", "different", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:03:40.821166Z"}
{"question_id": "tqa_rc_validation_59", "question": "What is Mel Gibson's middle name?", "ground_truth": ["Columcille", "St Colm", "Saint Colm Cille", "Calum Cille", "Collumcille", "Life of St. Columba", "St Columcille", "Columba, Saint", "Columba", "St Colmcille", "Vita Sancti Columbae", "Saint Columba", "Vita Columbae", "Colmcille", "Colum Cille mac Fedelmtheo", "Columbkille", "St. Columcille", "Columba of Iona", "Colm Cille", "Colmkill", "Columb Cille", "Colmekill", "Saint Columb", "Saint Columbkille", "St Colum Cille", "St. Columba", "Scoto-Hibernian Monasteries", "Saint Colmcille", "Life of Columba", "Columbcille", "Saint Columcille", "Colum Cille", "St Columba", "columba saint", "scoto hibernian monasteries", "life of st columba"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Colum", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:03:42.274959Z"}
{"question_id": "tqa_rc_validation_59", "question": "What is Mel Gibson's middle name?", "ground_truth": ["Columcille", "St Colm", "Saint Colm Cille", "Calum Cille", "Collumcille", "Life of St. Columba", "St Columcille", "Columba, Saint", "Columba", "St Colmcille", "Vita Sancti Columbae", "Saint Columba", "Vita Columbae", "Colmcille", "Colum Cille mac Fedelmtheo", "Columbkille", "St. Columcille", "Columba of Iona", "Colm Cille", "Colmkill", "Columb Cille", "Colmekill", "Saint Columb", "Saint Columbkille", "St Colum Cille", "St. Columba", "Scoto-Hibernian Monasteries", "Saint Colmcille", "Life of Columba", "Columbcille", "Saint Columcille", "Colum Cille", "St Columba", "columba saint", "scoto hibernian monasteries", "life of st columba"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Gerard", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Gibson's full name is Mel Colmcille Gerard Gibson", "Gerard", "Gerard", "Gerard", "Gurion", "Gerard", "Gerard", "Euclid", "Gedalion", "Mel Colmcille"], "equivalence_results": ["same", "same", "same", "same", "different", "same", "same", "different", "different", "different"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:03:58.266490Z"}
{"question_id": "tqa_rc_validation_60", "question": "Richard Daley was mayor of which city for 21 years?", "ground_truth": ["Chicago", "Chi-Beria", "Sayre language academy", "Chicago, Illinois", "Hog Butcher for the World", "Land of smelly onions", "Ariel Community Academy", "The weather in Chicago", "Chicago, Illinois, U.S.A.", "Chicago, Illionis", "Near North Montessori", "Religion in Chicago", "Chicago Finance Committee", "The Paris of America", "The city of Chicago", "City of Chicago", "List of sister cities of Chicago", "UN/LOCODE:USCHI", "Chicago theatre scene", "Chicago, WI", "The City of Broad Shoulders", "City of Broad Shoulders", "Sister Cities of Chicago", "Chicago il", "Chicago, Illinois, USA", "Performing arts in Chicago", "Chicago Transportation Committee", "Chicago, Wisconsin", "Chicago theater scene", "Chicago, Il", "Chicago, IL.", "Chicago, Ill.", "City of Chicago, Illinois", "Chi town", "Chicago, United States", "Chicago (Ill.)", "Transport in Chicago", "Chicago, Illinois, United States", "Chicago (IL)", "USCHI", "Chichago", "Chcago", "Chicago, Illinois, U.S.", "Sister Cities Chicago", "Chicago, USA", "Chi City", "Chi-Town", "Chicago theatre", "Paris of America", "Chicago, Illinois, US", "Chicago Illinois", "The city of Chicago, Illinois", "chicago illinois u s", "chicago illinois usa", "hog butcher for world", "chicago wi", "un locode uschi", "chicago usa", "chi beria", "weather in chicago", "chicago wisconsin", "chicago united states", "chicago illionis", "chicago illinois united states", "chicago illinois us", "chicago ill", "city of chicago illinois"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Chicago", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:03:59.068803Z"}
{"question_id": "tqa_rc_validation_60", "question": "Richard Daley was mayor of which city for 21 years?", "ground_truth": ["Chicago", "Chi-Beria", "Sayre language academy", "Chicago, Illinois", "Hog Butcher for the World", "Land of smelly onions", "Ariel Community Academy", "The weather in Chicago", "Chicago, Illinois, U.S.A.", "Chicago, Illionis", "Near North Montessori", "Religion in Chicago", "Chicago Finance Committee", "The Paris of America", "The city of Chicago", "City of Chicago", "List of sister cities of Chicago", "UN/LOCODE:USCHI", "Chicago theatre scene", "Chicago, WI", "The City of Broad Shoulders", "City of Broad Shoulders", "Sister Cities of Chicago", "Chicago il", "Chicago, Illinois, USA", "Performing arts in Chicago", "Chicago Transportation Committee", "Chicago, Wisconsin", "Chicago theater scene", "Chicago, Il", "Chicago, IL.", "Chicago, Ill.", "City of Chicago, Illinois", "Chi town", "Chicago, United States", "Chicago (Ill.)", "Transport in Chicago", "Chicago, Illinois, United States", "Chicago (IL)", "USCHI", "Chichago", "Chcago", "Chicago, Illinois, U.S.", "Sister Cities Chicago", "Chicago, USA", "Chi City", "Chi-Town", "Chicago theatre", "Paris of America", "Chicago, Illinois, US", "Chicago Illinois", "The city of Chicago, Illinois", "chicago illinois u s", "chicago illinois usa", "hog butcher for world", "chicago wi", "un locode uschi", "chicago usa", "chi beria", "weather in chicago", "chicago wisconsin", "chicago united states", "chicago illionis", "chicago illinois united states", "chicago illinois us", "chicago ill", "city of chicago illinois"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Chicago", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:01.071595Z"}
{"question_id": "tqa_rc_validation_60", "question": "Richard Daley was mayor of which city for 21 years?", "ground_truth": ["Chicago", "Chi-Beria", "Sayre language academy", "Chicago, Illinois", "Hog Butcher for the World", "Land of smelly onions", "Ariel Community Academy", "The weather in Chicago", "Chicago, Illinois, U.S.A.", "Chicago, Illionis", "Near North Montessori", "Religion in Chicago", "Chicago Finance Committee", "The Paris of America", "The city of Chicago", "City of Chicago", "List of sister cities of Chicago", "UN/LOCODE:USCHI", "Chicago theatre scene", "Chicago, WI", "The City of Broad Shoulders", "City of Broad Shoulders", "Sister Cities of Chicago", "Chicago il", "Chicago, Illinois, USA", "Performing arts in Chicago", "Chicago Transportation Committee", "Chicago, Wisconsin", "Chicago theater scene", "Chicago, Il", "Chicago, IL.", "Chicago, Ill.", "City of Chicago, Illinois", "Chi town", "Chicago, United States", "Chicago (Ill.)", "Transport in Chicago", "Chicago, Illinois, United States", "Chicago (IL)", "USCHI", "Chichago", "Chcago", "Chicago, Illinois, U.S.", "Sister Cities Chicago", "Chicago, USA", "Chi City", "Chi-Town", "Chicago theatre", "Paris of America", "Chicago, Illinois, US", "Chicago Illinois", "The city of Chicago, Illinois", "chicago illinois u s", "chicago illinois usa", "hog butcher for world", "chicago wi", "un locode uschi", "chicago usa", "chi beria", "weather in chicago", "chicago wisconsin", "chicago united states", "chicago illionis", "chicago illinois united states", "chicago illinois us", "chicago ill", "city of chicago illinois"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Chicago", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:01.507769Z"}
{"question_id": "tqa_rc_validation_60", "question": "Richard Daley was mayor of which city for 21 years?", "ground_truth": ["Chicago", "Chi-Beria", "Sayre language academy", "Chicago, Illinois", "Hog Butcher for the World", "Land of smelly onions", "Ariel Community Academy", "The weather in Chicago", "Chicago, Illinois, U.S.A.", "Chicago, Illionis", "Near North Montessori", "Religion in Chicago", "Chicago Finance Committee", "The Paris of America", "The city of Chicago", "City of Chicago", "List of sister cities of Chicago", "UN/LOCODE:USCHI", "Chicago theatre scene", "Chicago, WI", "The City of Broad Shoulders", "City of Broad Shoulders", "Sister Cities of Chicago", "Chicago il", "Chicago, Illinois, USA", "Performing arts in Chicago", "Chicago Transportation Committee", "Chicago, Wisconsin", "Chicago theater scene", "Chicago, Il", "Chicago, IL.", "Chicago, Ill.", "City of Chicago, Illinois", "Chi town", "Chicago, United States", "Chicago (Ill.)", "Transport in Chicago", "Chicago, Illinois, United States", "Chicago (IL)", "USCHI", "Chichago", "Chcago", "Chicago, Illinois, U.S.", "Sister Cities Chicago", "Chicago, USA", "Chi City", "Chi-Town", "Chicago theatre", "Paris of America", "Chicago, Illinois, US", "Chicago Illinois", "The city of Chicago, Illinois", "chicago illinois u s", "chicago illinois usa", "hog butcher for world", "chicago wi", "un locode uschi", "chicago usa", "chi beria", "weather in chicago", "chicago wisconsin", "chicago united states", "chicago illionis", "chicago illinois united states", "chicago illinois us", "chicago ill", "city of chicago illinois"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Chicago", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:02.649118Z"}
{"question_id": "tqa_rc_validation_60", "question": "Richard Daley was mayor of which city for 21 years?", "ground_truth": ["Chicago", "Chi-Beria", "Sayre language academy", "Chicago, Illinois", "Hog Butcher for the World", "Land of smelly onions", "Ariel Community Academy", "The weather in Chicago", "Chicago, Illinois, U.S.A.", "Chicago, Illionis", "Near North Montessori", "Religion in Chicago", "Chicago Finance Committee", "The Paris of America", "The city of Chicago", "City of Chicago", "List of sister cities of Chicago", "UN/LOCODE:USCHI", "Chicago theatre scene", "Chicago, WI", "The City of Broad Shoulders", "City of Broad Shoulders", "Sister Cities of Chicago", "Chicago il", "Chicago, Illinois, USA", "Performing arts in Chicago", "Chicago Transportation Committee", "Chicago, Wisconsin", "Chicago theater scene", "Chicago, Il", "Chicago, IL.", "Chicago, Ill.", "City of Chicago, Illinois", "Chi town", "Chicago, United States", "Chicago (Ill.)", "Transport in Chicago", "Chicago, Illinois, United States", "Chicago (IL)", "USCHI", "Chichago", "Chcago", "Chicago, Illinois, U.S.", "Sister Cities Chicago", "Chicago, USA", "Chi City", "Chi-Town", "Chicago theatre", "Paris of America", "Chicago, Illinois, US", "Chicago Illinois", "The city of Chicago, Illinois", "chicago illinois u s", "chicago illinois usa", "hog butcher for world", "chicago wi", "un locode uschi", "chicago usa", "chi beria", "weather in chicago", "chicago wisconsin", "chicago united states", "chicago illionis", "chicago illinois united states", "chicago illinois us", "chicago ill", "city of chicago illinois"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Chicago", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:03.564214Z"}
{"question_id": "tqa_rc_validation_61", "question": "\"In which movie did Garbo say, \"\"I want to be alone\"\".\"", "ground_truth": ["Grand Hotel", "The grand hotel", "Grand Hôtel", "Grand Hotel (disambiguation)", "grand hotel disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Grand Hotel", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:04.315493Z"}
{"question_id": "tqa_rc_validation_61", "question": "\"In which movie did Garbo say, \"\"I want to be alone\"\".\"", "ground_truth": ["Grand Hotel", "The grand hotel", "Grand Hôtel", "Grand Hotel (disambiguation)", "grand hotel disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Grand Hotel", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:06.125042Z"}
{"question_id": "tqa_rc_validation_61", "question": "\"In which movie did Garbo say, \"\"I want to be alone\"\".\"", "ground_truth": ["Grand Hotel", "The grand hotel", "Grand Hôtel", "Grand Hotel (disambiguation)", "grand hotel disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Grand Hotel", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:06.269919Z"}
{"question_id": "tqa_rc_validation_61", "question": "\"In which movie did Garbo say, \"\"I want to be alone\"\".\"", "ground_truth": ["Grand Hotel", "The grand hotel", "Grand Hôtel", "Grand Hotel (disambiguation)", "grand hotel disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Grand Hotel", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:07.392103Z"}
{"question_id": "tqa_rc_validation_61", "question": "\"In which movie did Garbo say, \"\"I want to be alone\"\".\"", "ground_truth": ["Grand Hotel", "The grand hotel", "Grand Hôtel", "Grand Hotel (disambiguation)", "grand hotel disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "\"Grand Hotel\" (1932)", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:08.141877Z"}
{"question_id": "tqa_rc_validation_62", "question": "What is Osbert Lancaster best known for producing?", "ground_truth": ["Cartoons", "Cartoonish", "American cartoon", "Cartoon", "Cartoonistic", "Cartoonism"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Cartoons and illustrations, especially his “Pocket Cartoons” and architectural satire", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Cartoons and illustrations for newspapers, especially *The Daily Express*", "Cartoon illustrations and architectural criticism", "Cartoons (especially architectural cartoons) and book illustrations", "Cartoons for the British press, especially architectural and social satire for the *Daily Express*", "Cartoons and illustrations for *The Daily Express* and *Punch* magazine", "Cartoons and illustrations for *The Daily Express* and architectural criticism", "Cartoons for the British press, especially architectural and social satire", "Cartoons and illustrations, especially for *The Daily Express* and *Architectural Review*", "Cartoons and illustrations, especially for *The Daily Express* and *Architectural Review*", "Cartoons and illustrations for *The Daily Express* and architectural criticism"], "equivalence_results": ["different", "same", "same", "same", "different", "different", "same", "different", "different", "different"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:04:28.830284Z"}
{"question_id": "tqa_rc_validation_62", "question": "What is Osbert Lancaster best known for producing?", "ground_truth": ["Cartoons", "Cartoonish", "American cartoon", "Cartoon", "Cartoonistic", "Cartoonism"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Pocket cartoons", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:30.632681Z"}
{"question_id": "tqa_rc_validation_62", "question": "What is Osbert Lancaster best known for producing?", "ground_truth": ["Cartoons", "Cartoonish", "American cartoon", "Cartoon", "Cartoonistic", "Cartoonism"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Cartoons", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:04:30.840349Z"}
{"question_id": "tqa_rc_validation_62", "question": "What is Osbert Lancaster best known for producing?", "ground_truth": ["Cartoons", "Cartoonish", "American cartoon", "Cartoon", "Cartoonistic", "Cartoonism"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Cartoons and comic strips", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Cartoons and comic strips", "Cartoons and satirical drawings", "Cartoons and satirical drawings", "Cartoons and comic strips", "Cartoons and comic strips", "Cartoons and satirical illustrations", "Cartoons and comic strips", "Cartoons and comic strips", "Cartoons and comic strips", "Cartoons and satirical drawings"], "equivalence_results": ["same", "different", "different", "same", "same", "different", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:04:56.117169Z"}
{"question_id": "tqa_rc_validation_62", "question": "What is Osbert Lancaster best known for producing?", "ground_truth": ["Cartoons", "Cartoonish", "American cartoon", "Cartoon", "Cartoonistic", "Cartoonism"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Cartoons for The Daily Express", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Caricatures and cartoons", "Cartoons for the Evening Standard", "Caricatures and cartoons, particularly for The Daily Express and The Sunday Times", "Caricatures and cartoons in The Daily Express", "Cartoonist and author of satirical books about British society", "Cartoons for The Daily Express", "Caricatures and cartoons for The Evening Standard", "Cartoons, particularly for the Evening Standard, and also for his work on the satirical magazine 'Punch'", "Cartoons and caricatures", "Cartoons for the magazine Punch"], "equivalence_results": ["different", "different", "different", "same", "different", "same", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:05:14.009109Z"}
{"question_id": "tqa_rc_validation_63", "question": "Who was the defending champion when Martina Navratilova first won Wimbledon singles?", "ground_truth": ["Virginia Wade", "Sarah Virginia Wade"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Chris Evert", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:05:32.684439Z"}
{"question_id": "tqa_rc_validation_63", "question": "Who was the defending champion when Martina Navratilova first won Wimbledon singles?", "ground_truth": ["Virginia Wade", "Sarah Virginia Wade"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Virginia Wade", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:05:34.407148Z"}
{"question_id": "tqa_rc_validation_63", "question": "Who was the defending champion when Martina Navratilova first won Wimbledon singles?", "ground_truth": ["Virginia Wade", "Sarah Virginia Wade"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Chris Evert", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:05:45.836210Z"}
{"question_id": "tqa_rc_validation_63", "question": "Who was the defending champion when Martina Navratilova first won Wimbledon singles?", "ground_truth": ["Virginia Wade", "Sarah Virginia Wade"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Chris Evert", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert", "Chris Evert"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:06:06.858144Z"}
{"question_id": "tqa_rc_validation_63", "question": "Who was the defending champion when Martina Navratilova first won Wimbledon singles?", "ground_truth": ["Virginia Wade", "Sarah Virginia Wade"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Chris Evert-Lloyd", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Chris Evert", "Chris Evert-Lloyd was the defending champion when Martina Navratilova first won Wimbledon singles in 1978", "Billie Jean King", "Chris Evert-Lloyd", "Chris Evert", "Chris Evert-Lloyd", "Chris Evert-Lloyd", "Chris Evert-Lloyd", "Chris Evert-Lloyd", "Billie Jean King"], "equivalence_results": ["same", "same", "different", "same", "same", "same", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:06:26.112660Z"}
{"question_id": "tqa_rc_validation_64", "question": "Who was the first US-born winner of golf's British Open?", "ground_truth": ["Walter Hagen", "Hagen, Walter", "Walter Charles Hagen", "hagen walter"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Walter Hagen", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:06:27.047742Z"}
{"question_id": "tqa_rc_validation_64", "question": "Who was the first US-born winner of golf's British Open?", "ground_truth": ["Walter Hagen", "Hagen, Walter", "Walter Charles Hagen", "hagen walter"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Walter Hagen", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:06:28.630523Z"}
{"question_id": "tqa_rc_validation_64", "question": "Who was the first US-born winner of golf's British Open?", "ground_truth": ["Walter Hagen", "Hagen, Walter", "Walter Charles Hagen", "hagen walter"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Bobby Jones", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Bobby Jones", "Bobby Jones", "Bobby Jones", "Bobby Jones", "Bobby Jones", "Bobby Jones", "Bobby Jones", "Bobby Jones", "Bobby Jones", "Bobby Jones"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:06:40.064192Z"}
{"question_id": "tqa_rc_validation_64", "question": "Who was the first US-born winner of golf's British Open?", "ground_truth": ["Walter Hagen", "Hagen, Walter", "Walter Charles Hagen", "hagen walter"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Walter Hagen", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:06:41.337177Z"}
{"question_id": "tqa_rc_validation_64", "question": "Who was the first US-born winner of golf's British Open?", "ground_truth": ["Walter Hagen", "Hagen, Walter", "Walter Charles Hagen", "hagen walter"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Richard Bland was not the first US-born winner of golf's British Open", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Richard Bland's compatriot, is  not correct but instead", "Richard Bland's US-born predecessor,  Cyril Walker,   and Horton Smith before him", "Richard Bland was not", "Ben Hogan (although he was not born in the US, but rather in Ireland, and then moved to the US) was initially thought to be the first US-born winner, but it was actually Walter Hagen's fellow competitor,  Ben Hogan's", "Francis Ouimet", "Richard Bland was the first US-born player in the Open Championship in 1880", "Richard Bland's win in 2021 is not correct", "Richard Bland was not the first US-born winner but  Bobby Jones was but in 1926, however the first US-born winner of golf's British Open is actually  Bobby was not first, but  Bobby's was tied by  Bobby's", "Tony Jacklin was not the first US-born winner of golf's British Open", "Richard Bland was not the first US-born winner, however, Francis Ouimet was"], "equivalence_results": ["different", "different", "same", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 1, "num_different": 9, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.1, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:07:03.992210Z"}
{"question_id": "tqa_rc_validation_65", "question": "In which country is the Sky Train Rail bridge?", "ground_truth": ["Canada", "Canadá", "The Dominion of Canada", "Commonwealth of Canada", "Dominion of canada", "ISO 3166-1:CA", "Etymology of Canada", "Canadiophile", "Canada's", "ᑲᓇᑕ", "Canada/References", "America's top hat", "Canada.", "Cnada", "Čanada", "Canadian Federation", "Kenadian", "Canadialand", "Xanada", "Canadaa", "canada s", "america s top hat", "iso 3166 1 ca", "canada references"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Thailand", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Canada", "Thailand", "Thailand", "Thailand", "Canada", "Thailand", "Canada", "Thailand", "Sri Lanka", "New Zealand"], "equivalence_results": ["different", "same", "same", "same", "different", "same", "different", "same", "different", "different"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:07:20.889267Z"}
{"question_id": "tqa_rc_validation_65", "question": "In which country is the Sky Train Rail bridge?", "ground_truth": ["Canada", "Canadá", "The Dominion of Canada", "Commonwealth of Canada", "Dominion of canada", "ISO 3166-1:CA", "Etymology of Canada", "Canadiophile", "Canada's", "ᑲᓇᑕ", "Canada/References", "America's top hat", "Canada.", "Cnada", "Čanada", "Canadian Federation", "Kenadian", "Canadialand", "Xanada", "Canadaa", "canada s", "america s top hat", "iso 3166 1 ca", "canada references"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Canada", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:07:23.024261Z"}
{"question_id": "tqa_rc_validation_65", "question": "In which country is the Sky Train Rail bridge?", "ground_truth": ["Canada", "Canadá", "The Dominion of Canada", "Commonwealth of Canada", "Dominion of canada", "ISO 3166-1:CA", "Etymology of Canada", "Canadiophile", "Canada's", "ᑲᓇᑕ", "Canada/References", "America's top hat", "Canada.", "Cnada", "Čanada", "Canadian Federation", "Kenadian", "Canadialand", "Xanada", "Canadaa", "canada s", "america s top hat", "iso 3166 1 ca", "canada references"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Thailand", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:07:34.488491Z"}
{"question_id": "tqa_rc_validation_65", "question": "In which country is the Sky Train Rail bridge?", "ground_truth": ["Canada", "Canadá", "The Dominion of Canada", "Commonwealth of Canada", "Dominion of canada", "ISO 3166-1:CA", "Etymology of Canada", "Canadiophile", "Canada's", "ᑲᓇᑕ", "Canada/References", "America's top hat", "Canada.", "Cnada", "Čanada", "Canadian Federation", "Kenadian", "Canadialand", "Xanada", "Canadaa", "canada s", "america s top hat", "iso 3166 1 ca", "canada references"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Thailand", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand", "Thailand"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:07:57.045127Z"}
{"question_id": "tqa_rc_validation_65", "question": "In which country is the Sky Train Rail bridge?", "ground_truth": ["Canada", "Canadá", "The Dominion of Canada", "Commonwealth of Canada", "Dominion of canada", "ISO 3166-1:CA", "Etymology of Canada", "Canadiophile", "Canada's", "ᑲᓇᑕ", "Canada/References", "America's top hat", "Canada.", "Cnada", "Čanada", "Canadian Federation", "Kenadian", "Canadialand", "Xanada", "Canadaa", "canada s", "america s top hat", "iso 3166 1 ca", "canada references"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "India", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["India", "India", "India", "Canada", "Canada", "India", "Thailand", "Bangladesh", "India", "Canada"], "equivalence_results": ["same", "same", "same", "different", "different", "same", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:08:13.638115Z"}
{"question_id": "tqa_rc_validation_66", "question": "What was the Paramount Film Company originally called?", "ground_truth": ["Famous Players Film Company", "Raleigh Studios", "The Famous Players", "Celebrated Players Film Corporation", "famous players"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Famous Players Film Company", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:08:14.776224Z"}
{"question_id": "tqa_rc_validation_66", "question": "What was the Paramount Film Company originally called?", "ground_truth": ["Famous Players Film Company", "Raleigh Studios", "The Famous Players", "Celebrated Players Film Corporation", "famous players"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Famous Players Film Company", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:08:16.543264Z"}
{"question_id": "tqa_rc_validation_66", "question": "What was the Paramount Film Company originally called?", "ground_truth": ["Famous Players Film Company", "Raleigh Studios", "The Famous Players", "Celebrated Players Film Corporation", "famous players"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Famous Players Film Company", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:08:16.792620Z"}
{"question_id": "tqa_rc_validation_66", "question": "What was the Paramount Film Company originally called?", "ground_truth": ["Famous Players Film Company", "Raleigh Studios", "The Famous Players", "Celebrated Players Film Corporation", "famous players"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Famous Players Film Company", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:08:18.004636Z"}
{"question_id": "tqa_rc_validation_66", "question": "What was the Paramount Film Company originally called?", "ground_truth": ["Famous Players Film Company", "Raleigh Studios", "The Famous Players", "Celebrated Players Film Corporation", "famous players"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Nestor Film Company", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Biograph Company's subsidiary, the New York Motion Picture Company's subsidiary, the New York Picture and Amusement Corporation's subsidiary, the World Film Corporation subsidiary, or the Lasky Feature Play Company was ultimately bought out and renamed", "The Biograph Company", "The Paramount Film Company was originally called the Famous Players Film Company", "The Nestor Film Company", "The Nestor Film Company", "The Paramount Film Company was originally called the Famous Players Film Company", "The Nestor Film Company", "The New York Motion Picture Company", "The New York Motion Picture Company", "The Biograph Company"], "equivalence_results": ["different", "different", "different", "same", "same", "different", "same", "different", "different", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:08:34.849033Z"}
{"question_id": "tqa_rc_validation_0", "question": "Who was the man behind The Chipmunks?", "ground_truth": ["David Seville"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Ross Bagdasarian Sr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:08:39.982024Z"}
{"question_id": "tqa_rc_validation_67", "question": "Who was the first person after Scott to reach the South Pole overland?", "ground_truth": ["Edmond Hillary", "Sir Edmund Hillary", "Edmund Hilary", "Sir Ed", "Sir Edmund Hilary", "Sir Edmund Percival Hillary", "Ed Hillary", "Sir Edmund", "Edmund Percival Hillary", "Edmund Hillary"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Roald Amundsen", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:08:51.974230Z"}
{"question_id": "tqa_rc_validation_67", "question": "Who was the first person after Scott to reach the South Pole overland?", "ground_truth": ["Edmond Hillary", "Sir Edmund Hillary", "Edmund Hilary", "Sir Ed", "Sir Edmund Hilary", "Sir Edmund Percival Hillary", "Ed Hillary", "Sir Edmund", "Edmund Percival Hillary", "Edmund Hillary"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Edmund Hillary", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:08:53.549920Z"}
{"question_id": "tqa_rc_validation_67", "question": "Who was the first person after Scott to reach the South Pole overland?", "ground_truth": ["Edmond Hillary", "Sir Edmund Hillary", "Edmund Hilary", "Sir Ed", "Sir Edmund Hilary", "Sir Edmund Percival Hillary", "Ed Hillary", "Sir Edmund", "Edmund Percival Hillary", "Edmund Hillary"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Roald Amundsen", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:09:03.875630Z"}
{"question_id": "tqa_rc_validation_67", "question": "Who was the first person after Scott to reach the South Pole overland?", "ground_truth": ["Edmond Hillary", "Sir Edmund Hillary", "Edmund Hilary", "Sir Ed", "Sir Edmund Hilary", "Sir Edmund Percival Hillary", "Ed Hillary", "Sir Edmund", "Edmund Percival Hillary", "Edmund Hillary"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Roald Amundsen", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:09:25.751984Z"}
{"question_id": "tqa_rc_validation_67", "question": "Who was the first person after Scott to reach the South Pole overland?", "ground_truth": ["Edmond Hillary", "Sir Edmund Hillary", "Edmund Hilary", "Sir Ed", "Sir Edmund Hilary", "Sir Edmund Percival Hillary", "Ed Hillary", "Sir Edmund", "Edmund Percival Hillary", "Edmund Hillary"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Roald Amundsen", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Robert Falcon Scott's Norwegian rival, Roald Amundsen, had already reached the South Pole", "Roald Amundsen", "Roald Amundsen was not the first, however, Amundsen's expedition did leave the last depot before the pole on December 11, 1911", "Roald Amundsen", "Roald Amundsen, accompanied by Olav Bjaaland, Helmer Hanssen, Sverre Hassel, and Oscar Wisting", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Roald Amundsen", "Ronne and Amundsen both reached the South Pole overland, but after Robert Falcon Scott"], "equivalence_results": ["same", "same", "different", "same", "different", "same", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:09:43.533602Z"}
{"question_id": "tqa_rc_validation_68", "question": "Which journalist first told the world about the My Lai massacre?", "ground_truth": ["Seymour Hersh", "Seymour Hersch", "The Dark Side of Camelot", "Seymour M. Hersh", "Chain of Command: The Road from 9/11 to Abu Ghraib", "Hersh, Seymour M.", "Sy Hersh", "Chain of Command (book)", "Seymour (Sy) Myron Hersh", "Seymour Hirsch", "dark side of camelot", "seymour sy myron hersh", "chain of command book", "seymour m hersh", "hersh seymour m", "chain of command road from 9 11 to abu ghraib"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Seymour Hersh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:09:44.447570Z"}
{"question_id": "tqa_rc_validation_68", "question": "Which journalist first told the world about the My Lai massacre?", "ground_truth": ["Seymour Hersh", "Seymour Hersch", "The Dark Side of Camelot", "Seymour M. Hersh", "Chain of Command: The Road from 9/11 to Abu Ghraib", "Hersh, Seymour M.", "Sy Hersh", "Chain of Command (book)", "Seymour (Sy) Myron Hersh", "Seymour Hirsch", "dark side of camelot", "seymour sy myron hersh", "chain of command book", "seymour m hersh", "hersh seymour m", "chain of command road from 9 11 to abu ghraib"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Seymour Hersh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:09:45.610685Z"}
{"question_id": "tqa_rc_validation_68", "question": "Which journalist first told the world about the My Lai massacre?", "ground_truth": ["Seymour Hersh", "Seymour Hersch", "The Dark Side of Camelot", "Seymour M. Hersh", "Chain of Command: The Road from 9/11 to Abu Ghraib", "Hersh, Seymour M.", "Sy Hersh", "Chain of Command (book)", "Seymour (Sy) Myron Hersh", "Seymour Hirsch", "dark side of camelot", "seymour sy myron hersh", "chain of command book", "seymour m hersh", "hersh seymour m", "chain of command road from 9 11 to abu ghraib"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Seymour Hersh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:09:46.183036Z"}
{"question_id": "tqa_rc_validation_68", "question": "Which journalist first told the world about the My Lai massacre?", "ground_truth": ["Seymour Hersh", "Seymour Hersch", "The Dark Side of Camelot", "Seymour M. Hersh", "Chain of Command: The Road from 9/11 to Abu Ghraib", "Hersh, Seymour M.", "Sy Hersh", "Chain of Command (book)", "Seymour (Sy) Myron Hersh", "Seymour Hirsch", "dark side of camelot", "seymour sy myron hersh", "chain of command book", "seymour m hersh", "hersh seymour m", "chain of command road from 9 11 to abu ghraib"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Seymour Hersh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:09:47.478241Z"}
{"question_id": "tqa_rc_validation_68", "question": "Which journalist first told the world about the My Lai massacre?", "ground_truth": ["Seymour Hersh", "Seymour Hersch", "The Dark Side of Camelot", "Seymour M. Hersh", "Chain of Command: The Road from 9/11 to Abu Ghraib", "Hersh, Seymour M.", "Sy Hersh", "Chain of Command (book)", "Seymour (Sy) Myron Hersh", "Seymour Hirsch", "dark side of camelot", "seymour sy myron hersh", "chain of command book", "seymour m hersh", "hersh seymour m", "chain of command road from 9 11 to abu ghraib"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Seymour Hersh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:09:48.417554Z"}
{"question_id": "tqa_rc_validation_69", "question": "What is the name of Terence and Shirley Conran's dress designer son?", "ground_truth": ["Jasper", "Jaspis", "Bruneau jasper", "Egyptian jasper", "Black Jasper", "Lydian stone", "Jasper (mineral)", "Youngite", "jasper mineral"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Jasper Conran", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:09:49.321500Z"}
{"question_id": "tqa_rc_validation_69", "question": "What is the name of Terence and Shirley Conran's dress designer son?", "ground_truth": ["Jasper", "Jaspis", "Bruneau jasper", "Egyptian jasper", "Black Jasper", "Lydian stone", "Jasper (mineral)", "Youngite", "jasper mineral"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Jasper Conran", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:09:51.010680Z"}
{"question_id": "tqa_rc_validation_69", "question": "What is the name of Terence and Shirley Conran's dress designer son?", "ground_truth": ["Jasper", "Jaspis", "Bruneau jasper", "Egyptian jasper", "Black Jasper", "Lydian stone", "Jasper (mineral)", "Youngite", "jasper mineral"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Sebastian Conran", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Sebastian Conran", "Sebastian Conran", "Sebastian Conran", "Sebastian Conran", "Sebastian Conran", "Sebastian Conran", "Sebastian Conran", "Sebastian Conran", "Sebastian Conran", "Sebastian Conran"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:10:01.480688Z"}
{"question_id": "tqa_rc_validation_69", "question": "What is the name of Terence and Shirley Conran's dress designer son?", "ground_truth": ["Jasper", "Jaspis", "Bruneau jasper", "Egyptian jasper", "Black Jasper", "Lydian stone", "Jasper (mineral)", "Youngite", "jasper mineral"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Jasper Conran", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:02.875599Z"}
{"question_id": "tqa_rc_validation_69", "question": "What is the name of Terence and Shirley Conran's dress designer son?", "ground_truth": ["Jasper", "Jaspis", "Bruneau jasper", "Egyptian jasper", "Black Jasper", "Lydian stone", "Jasper (mineral)", "Youngite", "jasper mineral"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Jasper Conran", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:03.629978Z"}
{"question_id": "tqa_rc_validation_70", "question": "Which drink did The Spice Girls promote?", "ground_truth": ["Pepsi", "Pep.si", "Pepsey", "Pepsi Convoy", "Pepsi Lime", "Pepsi: summer Mix", "Pepsi Si", "Brad's drink", "Cherry Pepsi", "Pepsi Sí", "Pepsi edge", "Joy of Cola", "Pepsi Summer mix", "Pepsi tarik", "Pepsi cino", "Pepsi Holiday Spice", "Pepsi Perfect", "PepsiCola", "Pepsi Gold", "Pepsi Samba", "Pepsi Vanilla", "Pepsi Avantage", "Vanilla Pepsi", "Pepsi cola", "Pepsi (Summer Mix)", "Mandarin Orange Slice", "Pepsi advantage", "Wildcherrypepsi", "Cokesi", "Pepsi-Cola", "Pepsi Fire", "Pepsiman", "Pepsi AM", "Diet Wild Cherry Pepsi", "Pepsi Man", "Pepsi Cappuccino", "Pepsi Ice", "Peppsey", "Diet Cherry Pepsi", "Pepsi B", "Pepsi Limited Edition Summer Mix", "Pepsi X", "Brads drink", "Homemade Pepsi", "Diet Pepsi Vanilla", "pep si", "brad s drink"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Pepsi", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:04.394695Z"}
{"question_id": "tqa_rc_validation_70", "question": "Which drink did The Spice Girls promote?", "ground_truth": ["Pepsi", "Pep.si", "Pepsey", "Pepsi Convoy", "Pepsi Lime", "Pepsi: summer Mix", "Pepsi Si", "Brad's drink", "Cherry Pepsi", "Pepsi Sí", "Pepsi edge", "Joy of Cola", "Pepsi Summer mix", "Pepsi tarik", "Pepsi cino", "Pepsi Holiday Spice", "Pepsi Perfect", "PepsiCola", "Pepsi Gold", "Pepsi Samba", "Pepsi Vanilla", "Pepsi Avantage", "Vanilla Pepsi", "Pepsi cola", "Pepsi (Summer Mix)", "Mandarin Orange Slice", "Pepsi advantage", "Wildcherrypepsi", "Cokesi", "Pepsi-Cola", "Pepsi Fire", "Pepsiman", "Pepsi AM", "Diet Wild Cherry Pepsi", "Pepsi Man", "Pepsi Cappuccino", "Pepsi Ice", "Peppsey", "Diet Cherry Pepsi", "Pepsi B", "Pepsi Limited Edition Summer Mix", "Pepsi X", "Brads drink", "Homemade Pepsi", "Diet Pepsi Vanilla", "pep si", "brad s drink"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Pepsi", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:06.088227Z"}
{"question_id": "tqa_rc_validation_70", "question": "Which drink did The Spice Girls promote?", "ground_truth": ["Pepsi", "Pep.si", "Pepsey", "Pepsi Convoy", "Pepsi Lime", "Pepsi: summer Mix", "Pepsi Si", "Brad's drink", "Cherry Pepsi", "Pepsi Sí", "Pepsi edge", "Joy of Cola", "Pepsi Summer mix", "Pepsi tarik", "Pepsi cino", "Pepsi Holiday Spice", "Pepsi Perfect", "PepsiCola", "Pepsi Gold", "Pepsi Samba", "Pepsi Vanilla", "Pepsi Avantage", "Vanilla Pepsi", "Pepsi cola", "Pepsi (Summer Mix)", "Mandarin Orange Slice", "Pepsi advantage", "Wildcherrypepsi", "Cokesi", "Pepsi-Cola", "Pepsi Fire", "Pepsiman", "Pepsi AM", "Diet Wild Cherry Pepsi", "Pepsi Man", "Pepsi Cappuccino", "Pepsi Ice", "Peppsey", "Diet Cherry Pepsi", "Pepsi B", "Pepsi Limited Edition Summer Mix", "Pepsi X", "Brads drink", "Homemade Pepsi", "Diet Pepsi Vanilla", "pep si", "brad s drink"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Pepsi", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:06.524885Z"}
{"question_id": "tqa_rc_validation_70", "question": "Which drink did The Spice Girls promote?", "ground_truth": ["Pepsi", "Pep.si", "Pepsey", "Pepsi Convoy", "Pepsi Lime", "Pepsi: summer Mix", "Pepsi Si", "Brad's drink", "Cherry Pepsi", "Pepsi Sí", "Pepsi edge", "Joy of Cola", "Pepsi Summer mix", "Pepsi tarik", "Pepsi cino", "Pepsi Holiday Spice", "Pepsi Perfect", "PepsiCola", "Pepsi Gold", "Pepsi Samba", "Pepsi Vanilla", "Pepsi Avantage", "Vanilla Pepsi", "Pepsi cola", "Pepsi (Summer Mix)", "Mandarin Orange Slice", "Pepsi advantage", "Wildcherrypepsi", "Cokesi", "Pepsi-Cola", "Pepsi Fire", "Pepsiman", "Pepsi AM", "Diet Wild Cherry Pepsi", "Pepsi Man", "Pepsi Cappuccino", "Pepsi Ice", "Peppsey", "Diet Cherry Pepsi", "Pepsi B", "Pepsi Limited Edition Summer Mix", "Pepsi X", "Brads drink", "Homemade Pepsi", "Diet Pepsi Vanilla", "pep si", "brad s drink"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Pepsi", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:07.590896Z"}
{"question_id": "tqa_rc_validation_70", "question": "Which drink did The Spice Girls promote?", "ground_truth": ["Pepsi", "Pep.si", "Pepsey", "Pepsi Convoy", "Pepsi Lime", "Pepsi: summer Mix", "Pepsi Si", "Brad's drink", "Cherry Pepsi", "Pepsi Sí", "Pepsi edge", "Joy of Cola", "Pepsi Summer mix", "Pepsi tarik", "Pepsi cino", "Pepsi Holiday Spice", "Pepsi Perfect", "PepsiCola", "Pepsi Gold", "Pepsi Samba", "Pepsi Vanilla", "Pepsi Avantage", "Vanilla Pepsi", "Pepsi cola", "Pepsi (Summer Mix)", "Mandarin Orange Slice", "Pepsi advantage", "Wildcherrypepsi", "Cokesi", "Pepsi-Cola", "Pepsi Fire", "Pepsiman", "Pepsi AM", "Diet Wild Cherry Pepsi", "Pepsi Man", "Pepsi Cappuccino", "Pepsi Ice", "Peppsey", "Diet Cherry Pepsi", "Pepsi B", "Pepsi Limited Edition Summer Mix", "Pepsi X", "Brads drink", "Homemade Pepsi", "Diet Pepsi Vanilla", "pep si", "brad s drink"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Pepsi", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:08.366463Z"}
{"question_id": "tqa_rc_validation_71", "question": "Who was the youngest brother in the Beach Boys?", "ground_truth": ["Carl Wilson", "Carl Wilson discography", "Wilson, Carl Dean", "Carl Dean Wilson", "Wilson, Carl", "wilson carl dean", "wilson carl"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Carl Wilson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:09.267947Z"}
{"question_id": "tqa_rc_validation_71", "question": "Who was the youngest brother in the Beach Boys?", "ground_truth": ["Carl Wilson", "Carl Wilson discography", "Wilson, Carl Dean", "Carl Dean Wilson", "Wilson, Carl", "wilson carl dean", "wilson carl"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Carl Wilson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:10.864886Z"}
{"question_id": "tqa_rc_validation_71", "question": "Who was the youngest brother in the Beach Boys?", "ground_truth": ["Carl Wilson", "Carl Wilson discography", "Wilson, Carl Dean", "Carl Dean Wilson", "Wilson, Carl", "wilson carl dean", "wilson carl"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Dennis Wilson", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Dennis Wilson", "Dennis Wilson", "Dennis Wilson", "Dennis Wilson", "Dennis Wilson", "Dennis Wilson", "Dennis Wilson", "Dennis Wilson", "Dennis Wilson", "Dennis Wilson"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:10:21.421103Z"}
{"question_id": "tqa_rc_validation_71", "question": "Who was the youngest brother in the Beach Boys?", "ground_truth": ["Carl Wilson", "Carl Wilson discography", "Wilson, Carl Dean", "Carl Dean Wilson", "Wilson, Carl", "wilson carl dean", "wilson carl"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Carl Wilson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:22.693111Z"}
{"question_id": "tqa_rc_validation_71", "question": "Who was the youngest brother in the Beach Boys?", "ground_truth": ["Carl Wilson", "Carl Wilson discography", "Wilson, Carl Dean", "Carl Dean Wilson", "Wilson, Carl", "wilson carl dean", "wilson carl"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Carl Wilson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:23.503737Z"}
{"question_id": "tqa_rc_validation_72", "question": "Who first hosted Family Feud?", "ground_truth": ["Richard Dawson", "Dick Dawson", "Dickie Dawson", "Colin Lionel Emm", "Colin Emm"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Richard Dawson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:24.319896Z"}
{"question_id": "tqa_rc_validation_72", "question": "Who first hosted Family Feud?", "ground_truth": ["Richard Dawson", "Dick Dawson", "Dickie Dawson", "Colin Lionel Emm", "Colin Emm"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Richard Dawson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:25.874033Z"}
{"question_id": "tqa_rc_validation_72", "question": "Who first hosted Family Feud?", "ground_truth": ["Richard Dawson", "Dick Dawson", "Dickie Dawson", "Colin Lionel Emm", "Colin Emm"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Richard Dawson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:26.316531Z"}
{"question_id": "tqa_rc_validation_72", "question": "Who first hosted Family Feud?", "ground_truth": ["Richard Dawson", "Dick Dawson", "Dickie Dawson", "Colin Lionel Emm", "Colin Emm"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Richard Dawson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:27.835548Z"}
{"question_id": "tqa_rc_validation_72", "question": "Who first hosted Family Feud?", "ground_truth": ["Richard Dawson", "Dick Dawson", "Dickie Dawson", "Colin Lionel Emm", "Colin Emm"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Richard Dawson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:10:28.595120Z"}
{"question_id": "tqa_rc_validation_73", "question": "What did the Lone Ranger's title Kemo Sabe mean in Apache?", "ground_truth": ["White Shirt", "Lèine bhàn", "Leine bhan"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "“Trusted friend", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["“Trusted friend", "“Trusted friend", "“Trusted friend", "“Trusted friend", "“Trusted friend", "“Trusted friend", "“Trusted friend", "Faithful friend", "Trusted friend", "“Trusted friend"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:10:46.302805Z"}
{"question_id": "tqa_rc_validation_73", "question": "What did the Lone Ranger's title Kemo Sabe mean in Apache?", "ground_truth": ["White Shirt", "Lèine bhàn", "Leine bhan"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Trusty scout", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Trusty scout", "Trusty scout", "Trusty scout", "Trusty scout", "Trusty scout", "Trusty scout", "Trusty scout", "Trusty scout", "Trusty scout", "Trusty scout"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:11:11.378240Z"}
{"question_id": "tqa_rc_validation_73", "question": "What did the Lone Ranger's title Kemo Sabe mean in Apache?", "ground_truth": ["White Shirt", "Lèine bhàn", "Leine bhan"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Trusted friend or \"secret friend\" (though some sources also translate it as \"soaked moccasin\")", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Trusted friend", "Trusted friend", "Trusted friend", "Trusted friend or so goes", "Trusted friend or \"secret friend\"", "Trusted friend or \"secret friend\" but more accurately, it is a term popularized by Tonto's supposed Apache dialect, and the actual meaning is disputed among linguists", "Trusted friend", "Trusted friend", "Trusted friend", "Trusted friend or secret friend, but most accurately, it means \"squint-eyed one\" or \"he sees with one eye\""], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:11:23.959248Z"}
{"question_id": "tqa_rc_validation_73", "question": "What did the Lone Ranger's title Kemo Sabe mean in Apache?", "ground_truth": ["White Shirt", "Lèine bhàn", "Leine bhan"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "White man", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["White man", "White man", "White man", "White man", "White man", "White man", "White man", "White man", "White man", "White man"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:11:44.043610Z"}
{"question_id": "tqa_rc_validation_73", "question": "What did the Lone Ranger's title Kemo Sabe mean in Apache?", "ground_truth": ["White Shirt", "Lèine bhàn", "Leine bhan"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "\"Trusted Friend\"", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["True Friend", "True Friend", "Trusted Friend", "True Friend", "\"Trusted Friend\"", "Trusted Friend or Faithful Friend", "Trusted Friend", "Trusted Friend", "True Friend", "Trusted Friend"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:12:03.182911Z"}
{"question_id": "tqa_rc_validation_74", "question": "Who or what was Gentle Ben in the 60s TV series?", "ground_truth": ["Bear cub", "Ursine", "Ursoidea", "Honey pig", "Bears", "Arctos", "Ursidae", "BEAR", "Mating bears", "Reproductive behavior of bears", "Ursoid", "Cub (bear)", "🐻", "Bear (zoology)", "Sexual behavior of bears", "Bear hibernation", "cub bear", "bear zoology"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "A tame black bear", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["A tame black bear", "A tame black bear, the pet and companion of a boy named Mark Wedloe", "A tame black bear that was the boy Mark Wedloe’s pet and companion", "A tame, friendly black bear kept as a pet by the boy Mark Wedloe", "A tame black bear that was the companion of a boy named Mark Wedloe", "A tame black bear who was the boy Mark Wedloe’s companion", "A tame pet black bear owned by the boy Mark Wedloe", "A tame pet bear", "A tame pet black bear owned by the boy Mark Wedloe", "A tame, pet black bear"], "equivalence_results": ["same", "different", "different", "different", "different", "different", "different", "same", "different", "same"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:12:24.788755Z"}
{"question_id": "tqa_rc_validation_74", "question": "Who or what was Gentle Ben in the 60s TV series?", "ground_truth": ["Bear cub", "Ursine", "Ursoidea", "Honey pig", "Bears", "Arctos", "Ursidae", "BEAR", "Mating bears", "Reproductive behavior of bears", "Ursoid", "Cub (bear)", "🐻", "Bear (zoology)", "Sexual behavior of bears", "Bear hibernation", "cub bear", "bear zoology"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "A bear", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:26.456567Z"}
{"question_id": "tqa_rc_validation_74", "question": "Who or what was Gentle Ben in the 60s TV series?", "ground_truth": ["Bear cub", "Ursine", "Ursoidea", "Honey pig", "Bears", "Arctos", "Ursidae", "BEAR", "Mating bears", "Reproductive behavior of bears", "Ursoid", "Cub (bear)", "🐻", "Bear (zoology)", "Sexual behavior of bears", "Bear hibernation", "cub bear", "bear zoology"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "A black bear", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:26.954831Z"}
{"question_id": "tqa_rc_validation_74", "question": "Who or what was Gentle Ben in the 60s TV series?", "ground_truth": ["Bear cub", "Ursine", "Ursoidea", "Honey pig", "Bears", "Arctos", "Ursidae", "BEAR", "Mating bears", "Reproductive behavior of bears", "Ursoid", "Cub (bear)", "🐻", "Bear (zoology)", "Sexual behavior of bears", "Bear hibernation", "cub bear", "bear zoology"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "A bear", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:28.224502Z"}
{"question_id": "tqa_rc_validation_74", "question": "Who or what was Gentle Ben in the 60s TV series?", "ground_truth": ["Bear cub", "Ursine", "Ursoidea", "Honey pig", "Bears", "Arctos", "Ursidae", "BEAR", "Mating bears", "Reproductive behavior of bears", "Ursoid", "Cub (bear)", "🐻", "Bear (zoology)", "Sexual behavior of bears", "Bear hibernation", "cub bear", "bear zoology"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "A pet orangutan", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["A pet orangutan in the 1960s TV series", "Gentle Ben was a black bear", "A pet black bear and his owner, Tom Wedloe, in the 1960s TV series", "A pet orangutan", "Gentle Ben was a black bear", "A pet orangutan", "A pet orangutan in the 1967-1969 TV series", "A pet orangutan in the 1960s TV series Gentle Ben", "A pet orangutan named Ben, owned by a widowed father and his son", "A pet orangutan"], "equivalence_results": ["same", "different", "different", "same", "different", "same", "different", "same", "different", "same"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:12:45.804394Z"}
{"question_id": "tqa_rc_validation_75", "question": "Which 70s show was based on the British show Till Death Us Do Part?", "ground_truth": ["All In The Family", "Justice For All (TV pilot)", "Stretch Cunningham", "All in the Family (US series)", "Those Were the Days (TV pilot)", "Millard Fillmore High School", "all in family", "justice for all tv pilot", "all in family us series", "those were days tv pilot"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "All in the Family", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:46.676355Z"}
{"question_id": "tqa_rc_validation_75", "question": "Which 70s show was based on the British show Till Death Us Do Part?", "ground_truth": ["All In The Family", "Justice For All (TV pilot)", "Stretch Cunningham", "All in the Family (US series)", "Those Were the Days (TV pilot)", "Millard Fillmore High School", "all in family", "justice for all tv pilot", "all in family us series", "those were days tv pilot"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "All in the Family", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:48.521652Z"}
{"question_id": "tqa_rc_validation_75", "question": "Which 70s show was based on the British show Till Death Us Do Part?", "ground_truth": ["All In The Family", "Justice For All (TV pilot)", "Stretch Cunningham", "All in the Family (US series)", "Those Were the Days (TV pilot)", "Millard Fillmore High School", "all in family", "justice for all tv pilot", "all in family us series", "those were days tv pilot"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "All in the Family", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:48.967134Z"}
{"question_id": "tqa_rc_validation_75", "question": "Which 70s show was based on the British show Till Death Us Do Part?", "ground_truth": ["All In The Family", "Justice For All (TV pilot)", "Stretch Cunningham", "All in the Family (US series)", "Those Were the Days (TV pilot)", "Millard Fillmore High School", "all in family", "justice for all tv pilot", "all in family us series", "those were days tv pilot"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "All in the Family", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:50.275215Z"}
{"question_id": "tqa_rc_validation_75", "question": "Which 70s show was based on the British show Till Death Us Do Part?", "ground_truth": ["All In The Family", "Justice For All (TV pilot)", "Stretch Cunningham", "All in the Family (US series)", "Those Were the Days (TV pilot)", "Millard Fillmore High School", "all in family", "justice for all tv pilot", "all in family us series", "those were days tv pilot"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "All in the Family", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:51.029505Z"}
{"question_id": "tqa_rc_validation_76", "question": "On what date in 1969 did Neil Armstrong first set foot on the Moon?", "ground_truth": ["July 20th", "July 20", "20 July", "Jul 20", "20th July", "Historical anniversaries/July 20", "historical anniversaries july 20"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "July 20, 1969", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:51.904779Z"}
{"question_id": "tqa_rc_validation_76", "question": "On what date in 1969 did Neil Armstrong first set foot on the Moon?", "ground_truth": ["July 20th", "July 20", "20 July", "Jul 20", "20th July", "Historical anniversaries/July 20", "historical anniversaries july 20"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "July 20, 1969", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:12:53.528326Z"}
{"question_id": "tqa_rc_validation_76", "question": "On what date in 1969 did Neil Armstrong first set foot on the Moon?", "ground_truth": ["July 20th", "July 20", "20 July", "Jul 20", "20th July", "Historical anniversaries/July 20", "historical anniversaries july 20"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "July 21, 1969", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["July 20, 1969 (or July 21 UTC)", "July 20, 1969 (or July 21 UTC)", "July 20, 1969 (or July 21 UTC)", "July 21, 1969", "July 20, 1969 (or July 21 UTC)", "July 20, 1969 (or July 21 UTC)", "July 21, 1969", "July 20, 1969 (or July 21 UTC)", "July 20, 1969 (or July 21 UTC)", "July 20, 1969, but more specifically, he stepped onto the Moon's surface on July 21, 1969, at 02:56 UTC"], "equivalence_results": ["different", "different", "different", "same", "different", "same", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:13:05.105570Z"}
{"question_id": "tqa_rc_validation_76", "question": "On what date in 1969 did Neil Armstrong first set foot on the Moon?", "ground_truth": ["July 20th", "July 20", "20 July", "Jul 20", "20th July", "Historical anniversaries/July 20", "historical anniversaries july 20"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "July 20, 1969", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:06.645541Z"}
{"question_id": "tqa_rc_validation_76", "question": "On what date in 1969 did Neil Armstrong first set foot on the Moon?", "ground_truth": ["July 20th", "July 20", "20 July", "Jul 20", "20th July", "Historical anniversaries/July 20", "historical anniversaries july 20"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "July 20, 1969", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:07.593404Z"}
{"question_id": "tqa_rc_validation_77", "question": "Bandar Seri Begawan International airport is in which country?", "ground_truth": ["Brunei", "Abode of Peace", "Health in Brunei", "Burnei", "State of Brunei Darussalam", "Nation of Brunei, the Abode of Peace", "برني دارالسلا", "Bruneian Sultanate", "Brunei Darrussalam", "State of Brunei", "Brunai", "Nation of Brunei", "ISO 3166-1:BN", "Asia/Brunei", "Human rights in Brunei", "Brunei Darsussalam", "Nation of Brunei, Abode of Peace", "Negara Brunei Darussalam", "Subdivisions of Brunei", "Brunei Darussalam", "Administrative divisions of Brunei", "Brunei Sultanate", "بروني", "Legal system of Brunei", "State of Brunei, Abode of Peace", "Etymology of Brunei", "state of brunei abode of peace", "nation of brunei abode of peace", "asia brunei", "iso 3166 1 bn"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Brunei", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:08.353443Z"}
{"question_id": "tqa_rc_validation_77", "question": "Bandar Seri Begawan International airport is in which country?", "ground_truth": ["Brunei", "Abode of Peace", "Health in Brunei", "Burnei", "State of Brunei Darussalam", "Nation of Brunei, the Abode of Peace", "برني دارالسلا", "Bruneian Sultanate", "Brunei Darrussalam", "State of Brunei", "Brunai", "Nation of Brunei", "ISO 3166-1:BN", "Asia/Brunei", "Human rights in Brunei", "Brunei Darsussalam", "Nation of Brunei, Abode of Peace", "Negara Brunei Darussalam", "Subdivisions of Brunei", "Brunei Darussalam", "Administrative divisions of Brunei", "Brunei Sultanate", "بروني", "Legal system of Brunei", "State of Brunei, Abode of Peace", "Etymology of Brunei", "state of brunei abode of peace", "nation of brunei abode of peace", "asia brunei", "iso 3166 1 bn"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Brunei", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:10.036859Z"}
{"question_id": "tqa_rc_validation_77", "question": "Bandar Seri Begawan International airport is in which country?", "ground_truth": ["Brunei", "Abode of Peace", "Health in Brunei", "Burnei", "State of Brunei Darussalam", "Nation of Brunei, the Abode of Peace", "برني دارالسلا", "Bruneian Sultanate", "Brunei Darrussalam", "State of Brunei", "Brunai", "Nation of Brunei", "ISO 3166-1:BN", "Asia/Brunei", "Human rights in Brunei", "Brunei Darsussalam", "Nation of Brunei, Abode of Peace", "Negara Brunei Darussalam", "Subdivisions of Brunei", "Brunei Darussalam", "Administrative divisions of Brunei", "Brunei Sultanate", "بروني", "Legal system of Brunei", "State of Brunei, Abode of Peace", "Etymology of Brunei", "state of brunei abode of peace", "nation of brunei abode of peace", "asia brunei", "iso 3166 1 bn"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Brunei", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:10.347049Z"}
{"question_id": "tqa_rc_validation_77", "question": "Bandar Seri Begawan International airport is in which country?", "ground_truth": ["Brunei", "Abode of Peace", "Health in Brunei", "Burnei", "State of Brunei Darussalam", "Nation of Brunei, the Abode of Peace", "برني دارالسلا", "Bruneian Sultanate", "Brunei Darrussalam", "State of Brunei", "Brunai", "Nation of Brunei", "ISO 3166-1:BN", "Asia/Brunei", "Human rights in Brunei", "Brunei Darsussalam", "Nation of Brunei, Abode of Peace", "Negara Brunei Darussalam", "Subdivisions of Brunei", "Brunei Darussalam", "Administrative divisions of Brunei", "Brunei Sultanate", "بروني", "Legal system of Brunei", "State of Brunei, Abode of Peace", "Etymology of Brunei", "state of brunei abode of peace", "nation of brunei abode of peace", "asia brunei", "iso 3166 1 bn"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Brunei", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:11.632397Z"}
{"question_id": "tqa_rc_validation_77", "question": "Bandar Seri Begawan International airport is in which country?", "ground_truth": ["Brunei", "Abode of Peace", "Health in Brunei", "Burnei", "State of Brunei Darussalam", "Nation of Brunei, the Abode of Peace", "برني دارالسلا", "Bruneian Sultanate", "Brunei Darrussalam", "State of Brunei", "Brunai", "Nation of Brunei", "ISO 3166-1:BN", "Asia/Brunei", "Human rights in Brunei", "Brunei Darsussalam", "Nation of Brunei, Abode of Peace", "Negara Brunei Darussalam", "Subdivisions of Brunei", "Brunei Darussalam", "Administrative divisions of Brunei", "Brunei Sultanate", "بروني", "Legal system of Brunei", "State of Brunei, Abode of Peace", "Etymology of Brunei", "state of brunei abode of peace", "nation of brunei abode of peace", "asia brunei", "iso 3166 1 bn"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Brunei", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:12.549502Z"}
{"question_id": "tqa_rc_validation_78", "question": "What was the profession of Paul Strand (1890 - 1976)?", "ground_truth": ["Photographer", "Photographist", "Freelance photographer", "Freelance Photography", "Photographr"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Photographer and filmmaker", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:13.367077Z"}
{"question_id": "tqa_rc_validation_78", "question": "What was the profession of Paul Strand (1890 - 1976)?", "ground_truth": ["Photographer", "Photographist", "Freelance photographer", "Freelance Photography", "Photographr"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Photographer", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:14.882698Z"}
{"question_id": "tqa_rc_validation_78", "question": "What was the profession of Paul Strand (1890 - 1976)?", "ground_truth": ["Photographer", "Photographist", "Freelance photographer", "Freelance Photography", "Photographr"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Photographer", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:15.031537Z"}
{"question_id": "tqa_rc_validation_78", "question": "What was the profession of Paul Strand (1890 - 1976)?", "ground_truth": ["Photographer", "Photographist", "Freelance photographer", "Freelance Photography", "Photographr"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Photographer", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:16.119532Z"}
{"question_id": "tqa_rc_validation_78", "question": "What was the profession of Paul Strand (1890 - 1976)?", "ground_truth": ["Photographer", "Photographist", "Freelance photographer", "Freelance Photography", "Photographr"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Photographer", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:16.901825Z"}
{"question_id": "tqa_rc_validation_79", "question": "Who had a 60s No 1 with Downtown?", "ground_truth": ["Petula Clark", "Petula Clarke", "Pet clark", "Petula Sally Olwen Clark"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Petula Clark", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:17.720819Z"}
{"question_id": "tqa_rc_validation_79", "question": "Who had a 60s No 1 with Downtown?", "ground_truth": ["Petula Clark", "Petula Clarke", "Pet clark", "Petula Sally Olwen Clark"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Petula Clark", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:19.408660Z"}
{"question_id": "tqa_rc_validation_79", "question": "Who had a 60s No 1 with Downtown?", "ground_truth": ["Petula Clark", "Petula Clarke", "Pet clark", "Petula Sally Olwen Clark"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Petula Clark", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:19.584657Z"}
{"question_id": "tqa_rc_validation_79", "question": "Who had a 60s No 1 with Downtown?", "ground_truth": ["Petula Clark", "Petula Clarke", "Pet clark", "Petula Sally Olwen Clark"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Petula Clark", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:20.713711Z"}
{"question_id": "tqa_rc_validation_79", "question": "Who had a 60s No 1 with Downtown?", "ground_truth": ["Petula Clark", "Petula Clarke", "Pet clark", "Petula Sally Olwen Clark"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Petula Clark", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:21.551701Z"}
{"question_id": "tqa_rc_validation_80", "question": "Who was born first, Kiefer Sutherland or Christian Slater?", "ground_truth": ["Kiefer Sutherland", "Kiefer sutherlund", "Keefer Sutherland", "Promised Land (1987)", "Keifer Sutherland", "Kiefer William Frederick Dempsey George Rufus Sutherland", "Keifer Southerland", "Kiefer William Fredrick Dempsey George Rufus Sutherland", "Kiefer Sutherland characters", "promised land 1987"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Christian Slater", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Christian Slater", "Christian Slater", "Christian Slater", "Christian Slater", "Christian Slater", "Christian Slater", "Christian Slater", "Christian Slater", "Christian Slater", "Christian Slater"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:13:39.113617Z"}
{"question_id": "tqa_rc_validation_80", "question": "Who was born first, Kiefer Sutherland or Christian Slater?", "ground_truth": ["Kiefer Sutherland", "Kiefer sutherlund", "Keefer Sutherland", "Promised Land (1987)", "Keifer Sutherland", "Kiefer William Frederick Dempsey George Rufus Sutherland", "Keifer Southerland", "Kiefer William Fredrick Dempsey George Rufus Sutherland", "Kiefer Sutherland characters", "promised land 1987"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Kiefer Sutherland", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:40.862512Z"}
{"question_id": "tqa_rc_validation_80", "question": "Who was born first, Kiefer Sutherland or Christian Slater?", "ground_truth": ["Kiefer Sutherland", "Kiefer sutherlund", "Keefer Sutherland", "Promised Land (1987)", "Keifer Sutherland", "Kiefer William Frederick Dempsey George Rufus Sutherland", "Keifer Southerland", "Kiefer William Fredrick Dempsey George Rufus Sutherland", "Kiefer Sutherland characters", "promised land 1987"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Kiefer Sutherland", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:13:41.134308Z"}
{"question_id": "tqa_rc_validation_80", "question": "Who was born first, Kiefer Sutherland or Christian Slater?", "ground_truth": ["Kiefer Sutherland", "Kiefer sutherlund", "Keefer Sutherland", "Promised Land (1987)", "Keifer Sutherland", "Kiefer William Frederick Dempsey George Rufus Sutherland", "Keifer Southerland", "Kiefer William Fredrick Dempsey George Rufus Sutherland", "Kiefer Sutherland characters", "promised land 1987"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Christian Slater", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Christian Slater", "Christian Slater", "Christian Slater", "Christian Slater", "Kiefer Sutherland", "Kiefer Sutherland", "Christian Slater", "Kiefer Sutherland", "Kiefer Sutherland", "Christian Slater"], "equivalence_results": ["same", "same", "same", "same", "different", "different", "same", "different", "different", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:14:02.964331Z"}
{"question_id": "tqa_rc_validation_80", "question": "Who was born first, Kiefer Sutherland or Christian Slater?", "ground_truth": ["Kiefer Sutherland", "Kiefer sutherlund", "Keefer Sutherland", "Promised Land (1987)", "Keifer Sutherland", "Kiefer William Frederick Dempsey George Rufus Sutherland", "Keifer Southerland", "Kiefer William Fredrick Dempsey George Rufus Sutherland", "Kiefer Sutherland characters", "promised land 1987"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Kiefer Sutherland was born first", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:14:03.792450Z"}
{"question_id": "tqa_rc_validation_81", "question": "To the nearest two, how many tennis Grand Slam titles did Jimmy Connors win?", "ground_truth": ["10", "ten"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "8", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["8", "8", "8", "8", "8", "8", "8", "8", "8", "8"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:14:22.207369Z"}
{"question_id": "tqa_rc_validation_81", "question": "To the nearest two, how many tennis Grand Slam titles did Jimmy Connors win?", "ground_truth": ["10", "ten"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "8", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["8", "8", "8", "8", "8", "8", "8", "8", "8", "8"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:14:48.449771Z"}
{"question_id": "tqa_rc_validation_81", "question": "To the nearest two, how many tennis Grand Slam titles did Jimmy Connors win?", "ground_truth": ["10", "ten"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "8", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["8", "8", "8", "8", "8", "8", "8", "8", "8", "8"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:14:58.658848Z"}
{"question_id": "tqa_rc_validation_81", "question": "To the nearest two, how many tennis Grand Slam titles did Jimmy Connors win?", "ground_truth": ["10", "ten"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "8", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["8", "8", "8", "8", "8", "8", "8", "8", "8", "8"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:15:18.791387Z"}
{"question_id": "tqa_rc_validation_81", "question": "To the nearest two, how many tennis Grand Slam titles did Jimmy Connors win?", "ground_truth": ["10", "ten"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "8", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["8", "8", "8", "8", "8", "8", "8", "8", "8", "Eight"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:15:34.893169Z"}
{"question_id": "tqa_rc_validation_82", "question": "Who was the Georgia Peach?", "ground_truth": ["Ty Cobb", "Cobb, Ty", "The Georgia Peach", "Tyrus Raymond Cobb", "Tyrus Cobb", "cobb ty", "georgia peach"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Ty Cobb", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:35.934942Z"}
{"question_id": "tqa_rc_validation_82", "question": "Who was the Georgia Peach?", "ground_truth": ["Ty Cobb", "Cobb, Ty", "The Georgia Peach", "Tyrus Raymond Cobb", "Tyrus Cobb", "cobb ty", "georgia peach"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Ty Cobb", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:37.672438Z"}
{"question_id": "tqa_rc_validation_82", "question": "Who was the Georgia Peach?", "ground_truth": ["Ty Cobb", "Cobb, Ty", "The Georgia Peach", "Tyrus Raymond Cobb", "Tyrus Cobb", "cobb ty", "georgia peach"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Ty Cobb", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:37.882980Z"}
{"question_id": "tqa_rc_validation_82", "question": "Who was the Georgia Peach?", "ground_truth": ["Ty Cobb", "Cobb, Ty", "The Georgia Peach", "Tyrus Raymond Cobb", "Tyrus Cobb", "cobb ty", "georgia peach"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Ty Cobb", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:39.244243Z"}
{"question_id": "tqa_rc_validation_82", "question": "Who was the Georgia Peach?", "ground_truth": ["Ty Cobb", "Cobb, Ty", "The Georgia Peach", "Tyrus Raymond Cobb", "Tyrus Cobb", "cobb ty", "georgia peach"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Ty Cobb", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:40.114956Z"}
{"question_id": "tqa_rc_validation_83", "question": "Who set fire to his guitar at the Monterey Pop festival in 19676?", "ground_truth": ["Jimi Hendrix", "Hendrix", "Lithofayne Pridgeon", "Early life of jimi hendrix", "Villanova Junction", "James Marshall Hendrix", "Jimmi Hendrix", "Jimy Hendrix", "Johnny Allen Hendrix", "Jimmy hendrix", "Jimmy Hendricks", "Gypsy Sun and Rainbows", "Electric Church", "Janie Hendrix", "Heaven Research", "Jim Hendrix", "Al Hendrix", "Gypsy Suns and Rainbows", "James Hendrix"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Jimi Hendrix", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:40.778835Z"}
{"question_id": "tqa_rc_validation_83", "question": "Who set fire to his guitar at the Monterey Pop festival in 19676?", "ground_truth": ["Jimi Hendrix", "Hendrix", "Lithofayne Pridgeon", "Early life of jimi hendrix", "Villanova Junction", "James Marshall Hendrix", "Jimmi Hendrix", "Jimy Hendrix", "Johnny Allen Hendrix", "Jimmy hendrix", "Jimmy Hendricks", "Gypsy Sun and Rainbows", "Electric Church", "Janie Hendrix", "Heaven Research", "Jim Hendrix", "Al Hendrix", "Gypsy Suns and Rainbows", "James Hendrix"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Jimi Hendrix", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:42.499953Z"}
{"question_id": "tqa_rc_validation_83", "question": "Who set fire to his guitar at the Monterey Pop festival in 19676?", "ground_truth": ["Jimi Hendrix", "Hendrix", "Lithofayne Pridgeon", "Early life of jimi hendrix", "Villanova Junction", "James Marshall Hendrix", "Jimmi Hendrix", "Jimy Hendrix", "Johnny Allen Hendrix", "Jimmy hendrix", "Jimmy Hendricks", "Gypsy Sun and Rainbows", "Electric Church", "Janie Hendrix", "Heaven Research", "Jim Hendrix", "Al Hendrix", "Gypsy Suns and Rainbows", "James Hendrix"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Jimi Hendrix", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:42.704707Z"}
{"question_id": "tqa_rc_validation_83", "question": "Who set fire to his guitar at the Monterey Pop festival in 19676?", "ground_truth": ["Jimi Hendrix", "Hendrix", "Lithofayne Pridgeon", "Early life of jimi hendrix", "Villanova Junction", "James Marshall Hendrix", "Jimmi Hendrix", "Jimy Hendrix", "Johnny Allen Hendrix", "Jimmy hendrix", "Jimmy Hendricks", "Gypsy Sun and Rainbows", "Electric Church", "Janie Hendrix", "Heaven Research", "Jim Hendrix", "Al Hendrix", "Gypsy Suns and Rainbows", "James Hendrix"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Jimi Hendrix", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:44.461381Z"}
{"question_id": "tqa_rc_validation_83", "question": "Who set fire to his guitar at the Monterey Pop festival in 19676?", "ground_truth": ["Jimi Hendrix", "Hendrix", "Lithofayne Pridgeon", "Early life of jimi hendrix", "Villanova Junction", "James Marshall Hendrix", "Jimmi Hendrix", "Jimy Hendrix", "Johnny Allen Hendrix", "Jimmy hendrix", "Jimmy Hendricks", "Gypsy Sun and Rainbows", "Electric Church", "Janie Hendrix", "Heaven Research", "Jim Hendrix", "Al Hendrix", "Gypsy Suns and Rainbows", "James Hendrix"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Jimi Hendrix", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:45.380810Z"}
{"question_id": "tqa_rc_validation_84", "question": "Della Street was whose secretary?", "ground_truth": ["Perry Mason", "Perry Mason (film)", "Perry Mason: The Case of the Defiant Daughter", "perry mason case of defiant daughter", "perry mason film"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Perry Mason", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:46.229169Z"}
{"question_id": "tqa_rc_validation_84", "question": "Della Street was whose secretary?", "ground_truth": ["Perry Mason", "Perry Mason (film)", "Perry Mason: The Case of the Defiant Daughter", "perry mason case of defiant daughter", "perry mason film"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Perry Mason", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:47.617250Z"}
{"question_id": "tqa_rc_validation_84", "question": "Della Street was whose secretary?", "ground_truth": ["Perry Mason", "Perry Mason (film)", "Perry Mason: The Case of the Defiant Daughter", "perry mason case of defiant daughter", "perry mason film"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Perry Mason", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:47.943245Z"}
{"question_id": "tqa_rc_validation_84", "question": "Della Street was whose secretary?", "ground_truth": ["Perry Mason", "Perry Mason (film)", "Perry Mason: The Case of the Defiant Daughter", "perry mason case of defiant daughter", "perry mason film"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Perry Mason", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:49.036155Z"}
{"question_id": "tqa_rc_validation_84", "question": "Della Street was whose secretary?", "ground_truth": ["Perry Mason", "Perry Mason (film)", "Perry Mason: The Case of the Defiant Daughter", "perry mason case of defiant daughter", "perry mason film"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Perry Mason", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:15:49.857049Z"}
{"question_id": "tqa_rc_validation_85", "question": "In music, who was Sweet and Innocent and Too Young?", "ground_truth": ["Donny Osmond", "Donny & Marie in Las Vegas", "Donald Clark Osmond", "Donald Osmond", "Donnie Osmond", "donny marie in las vegas"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Osmonds", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Neil Sedaka", "Jimmy Osmond", "A 1960s British girl group (later known as “The Sweethearts”)", "Neil Sedaka", "Eddie Fisher", "A stage persona used by Jimmy Somerville early in his career", "The Osmonds", "Amy Winehouse", "The Osmonds", "The Osmonds"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:16:09.233787Z"}
{"question_id": "tqa_rc_validation_85", "question": "In music, who was Sweet and Innocent and Too Young?", "ground_truth": ["Donny Osmond", "Donny & Marie in Las Vegas", "Donald Clark Osmond", "Donald Osmond", "Donnie Osmond", "donny marie in las vegas"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Donny Osmond", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:16:11.186986Z"}
{"question_id": "tqa_rc_validation_85", "question": "In music, who was Sweet and Innocent and Too Young?", "ground_truth": ["Donny Osmond", "Donny & Marie in Las Vegas", "Donald Clark Osmond", "Donald Osmond", "Donnie Osmond", "donny marie in las vegas"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Donny Osmond", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:16:11.556765Z"}
{"question_id": "tqa_rc_validation_85", "question": "In music, who was Sweet and Innocent and Too Young?", "ground_truth": ["Donny Osmond", "Donny & Marie in Las Vegas", "Donald Clark Osmond", "Donald Osmond", "Donnie Osmond", "donny marie in las vegas"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Ricky Nelson", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ricky Nelson", "Ricky Nelson", "Donny Osmond", "Ricky Nelson", "Ricky Nelson", "Ricky Nelson", "Ricky Nelson", "Ricky Nelson", "Ricky Nelson", "Ricky Nelson"], "equivalence_results": ["same", "same", "different", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:16:33.079371Z"}
{"question_id": "tqa_rc_validation_85", "question": "In music, who was Sweet and Innocent and Too Young?", "ground_truth": ["Donny Osmond", "Donny & Marie in Las Vegas", "Donald Clark Osmond", "Donald Osmond", "Donnie Osmond", "donny marie in las vegas"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Connie Francis", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Bobby Vee", "Connie Francis", "Connie Francis", "Carole King", "Connie Francis", "Connie Francis", "Connie Francis", "Pat Boone", "Connie Francis", "Connie Francis"], "equivalence_results": ["different", "same", "same", "different", "same", "same", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:16:49.396125Z"}
{"question_id": "tqa_rc_validation_86", "question": "Who is featured on Puff Daddy's Can't Hold Me Down?", "ground_truth": ["Mase", "MA$E", "Karma (Mase album)", "Now We Even", "Officially Back", "Mason Durell Betha", "Murda Ma$e", "Mason Betha", "Murda Mase", "Murder Mase", "ma e", "murda ma e", "karma mase album"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Mase", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:16:50.349914Z"}
{"question_id": "tqa_rc_validation_86", "question": "Who is featured on Puff Daddy's Can't Hold Me Down?", "ground_truth": ["Mase", "MA$E", "Karma (Mase album)", "Now We Even", "Officially Back", "Mason Durell Betha", "Murda Ma$e", "Mason Betha", "Murda Mase", "Murder Mase", "ma e", "murda ma e", "karma mase album"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Mase", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:16:52.176453Z"}
{"question_id": "tqa_rc_validation_86", "question": "Who is featured on Puff Daddy's Can't Hold Me Down?", "ground_truth": ["Mase", "MA$E", "Karma (Mase album)", "Now We Even", "Officially Back", "Mason Durell Betha", "Murda Ma$e", "Mason Betha", "Murda Mase", "Murder Mase", "ma e", "murda ma e", "karma mase album"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Mase", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:16:52.604564Z"}
{"question_id": "tqa_rc_validation_86", "question": "Who is featured on Puff Daddy's Can't Hold Me Down?", "ground_truth": ["Mase", "MA$E", "Karma (Mase album)", "Now We Even", "Officially Back", "Mason Durell Betha", "Murda Ma$e", "Mason Betha", "Murda Mase", "Murder Mase", "ma e", "murda ma e", "karma mase album"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Mase", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:16:53.825068Z"}
{"question_id": "tqa_rc_validation_86", "question": "Who is featured on Puff Daddy's Can't Hold Me Down?", "ground_truth": ["Mase", "MA$E", "Karma (Mase album)", "Now We Even", "Officially Back", "Mason Durell Betha", "Murda Ma$e", "Mason Betha", "Murda Mase", "Murder Mase", "ma e", "murda ma e", "karma mase album"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Mase", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:16:54.538691Z"}
{"question_id": "tqa_rc_validation_87", "question": "What had Edmond Hillary worked at before taking up mountain climbing?", "ground_truth": ["Bee Keeping", "Bee keeper", "Bee culture", "Beekeeping suit", "Beekiping", "Bee keepers", "Bee-keeping", "Apairist", "Apiculture", "Beekeeping helmet", "Beekeeping", "Bee farming", "Beekeeping leading practices", "Apiarian", "History of beekeeping"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "A beekeeper", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["He worked as a beekeeper", "He worked as a beekeeper", "A beekeeper", "He worked as a beekeeper", "He worked as a beekeeper", "A beekeeper", "A honey farm as a beekeeper", "A beekeeper", "He worked as a beekeeper", "He worked as a beekeeper"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:17:16.168902Z"}
{"question_id": "tqa_rc_validation_87", "question": "What had Edmond Hillary worked at before taking up mountain climbing?", "ground_truth": ["Bee Keeping", "Bee keeper", "Bee culture", "Beekeeping suit", "Beekiping", "Bee keepers", "Bee-keeping", "Apairist", "Apiculture", "Beekeeping helmet", "Beekeeping", "Bee farming", "Beekeeping leading practices", "Apiarian", "History of beekeeping"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Beekeeping", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:17.970667Z"}
{"question_id": "tqa_rc_validation_87", "question": "What had Edmond Hillary worked at before taking up mountain climbing?", "ground_truth": ["Bee Keeping", "Bee keeper", "Bee culture", "Beekeeping suit", "Beekiping", "Bee keepers", "Bee-keeping", "Apairist", "Apiculture", "Beekeeping helmet", "Beekeeping", "Bee farming", "Beekeeping leading practices", "Apiarian", "History of beekeeping"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "A beekeeper", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["A beekeeper", "A beekeeper", "A beekeeper", "A beekeeper", "Beekeeper", "A beekeeper", "A beekeeper", "Beekeeper", "A beekeeper", "Beekeeper"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:17:30.115581Z"}
{"question_id": "tqa_rc_validation_87", "question": "What had Edmond Hillary worked at before taking up mountain climbing?", "ground_truth": ["Bee Keeping", "Bee keeper", "Bee culture", "Beekeeping suit", "Beekiping", "Bee keepers", "Bee-keeping", "Apairist", "Apiculture", "Beekeeping helmet", "Beekeeping", "Bee farming", "Beekeeping leading practices", "Apiarian", "History of beekeeping"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Beekeeping", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:31.708994Z"}
{"question_id": "tqa_rc_validation_87", "question": "What had Edmond Hillary worked at before taking up mountain climbing?", "ground_truth": ["Bee Keeping", "Bee keeper", "Bee culture", "Beekeeping suit", "Beekiping", "Bee keepers", "Bee-keeping", "Apairist", "Apiculture", "Beekeeping helmet", "Beekeeping", "Bee farming", "Beekeeping leading practices", "Apiarian", "History of beekeeping"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Auckland University and the Royal New Zealand Air Force", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Aurizon Corporation and then as a beekeeper, then as a Royal Air Force (RAF) mechanic, and finally a civil servant in the New Zealand Public Service", "A deputy police commissioner in New Zealand", "A milk bar and an airletter office", "Auckland University and the New Zealand Mountaineering Federation as well as the New Zealand Army", "Royal New Zealand Air Force and the New Zealand Police", "He worked as a beekeeper", "Auckland University and the New Zealand Forest Service", "An accountant", "The Royal Air Force (RAF)", "The Royal New Zealand Air Force"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:17:49.475340Z"}
{"question_id": "tqa_rc_validation_88", "question": "In which American state is the Isabella Stewart Gardner Museum?", "ground_truth": ["Massachusetts", "Masachusetts", "Masshole Commonwealth", "Massachusetts (state)", "Massachusetts culture", "Massachusetts, United States", "Masachussetts", "Commonwealth of Masachusetts", "The Bay State", "Commonwealth of Masachussets", "Culture of Massachusetts", "Commonwealth of Massachusetts", "MA (state)", "Massechusetts", "Commonwealth of Masachusets", "Commonwealth of Massachussets", "Religion in Massachusetts", "Masschusetts", "Masachussets", "Commonwealth of Massachussetts", "Transport in Massachusetts", "Massachusite", "Economy of Massachusetts", "6th State", "Massitchusits", "Massachsuetts", "Commonwealth of Masachussetts", "The Commonwealth of Massachusetts", "Massachussets", "Massachus", "Massechussets", "Transportation in Massachusetts", "Massachusets", "Masachusets", "Mass.", "Massachusetts state", "Sixth State", "Massachusites", "Massacheusetts", "Most Serene Commonwealth of Massachusetts", "US-MA", "Commonwealth of Massachusets", "Massachussetts", "Massachusetts (U.S. state)", "Taxachusetts", "State of Massachusetts", "Massachusettes", "Massachusettsan", "Education in Massachusetts", "mass", "bay state", "massachusetts u s state", "ma state", "us ma", "massachusetts united states"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Massachusetts", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:50.655028Z"}
{"question_id": "tqa_rc_validation_88", "question": "In which American state is the Isabella Stewart Gardner Museum?", "ground_truth": ["Massachusetts", "Masachusetts", "Masshole Commonwealth", "Massachusetts (state)", "Massachusetts culture", "Massachusetts, United States", "Masachussetts", "Commonwealth of Masachusetts", "The Bay State", "Commonwealth of Masachussets", "Culture of Massachusetts", "Commonwealth of Massachusetts", "MA (state)", "Massechusetts", "Commonwealth of Masachusets", "Commonwealth of Massachussets", "Religion in Massachusetts", "Masschusetts", "Masachussets", "Commonwealth of Massachussetts", "Transport in Massachusetts", "Massachusite", "Economy of Massachusetts", "6th State", "Massitchusits", "Massachsuetts", "Commonwealth of Masachussetts", "The Commonwealth of Massachusetts", "Massachussets", "Massachus", "Massechussets", "Transportation in Massachusetts", "Massachusets", "Masachusets", "Mass.", "Massachusetts state", "Sixth State", "Massachusites", "Massacheusetts", "Most Serene Commonwealth of Massachusetts", "US-MA", "Commonwealth of Massachusets", "Massachussetts", "Massachusetts (U.S. state)", "Taxachusetts", "State of Massachusetts", "Massachusettes", "Massachusettsan", "Education in Massachusetts", "mass", "bay state", "massachusetts u s state", "ma state", "us ma", "massachusetts united states"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Massachusetts", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:51.724241Z"}
{"question_id": "tqa_rc_validation_88", "question": "In which American state is the Isabella Stewart Gardner Museum?", "ground_truth": ["Massachusetts", "Masachusetts", "Masshole Commonwealth", "Massachusetts (state)", "Massachusetts culture", "Massachusetts, United States", "Masachussetts", "Commonwealth of Masachusetts", "The Bay State", "Commonwealth of Masachussets", "Culture of Massachusetts", "Commonwealth of Massachusetts", "MA (state)", "Massechusetts", "Commonwealth of Masachusets", "Commonwealth of Massachussets", "Religion in Massachusetts", "Masschusetts", "Masachussets", "Commonwealth of Massachussetts", "Transport in Massachusetts", "Massachusite", "Economy of Massachusetts", "6th State", "Massitchusits", "Massachsuetts", "Commonwealth of Masachussetts", "The Commonwealth of Massachusetts", "Massachussets", "Massachus", "Massechussets", "Transportation in Massachusetts", "Massachusets", "Masachusets", "Mass.", "Massachusetts state", "Sixth State", "Massachusites", "Massacheusetts", "Most Serene Commonwealth of Massachusetts", "US-MA", "Commonwealth of Massachusets", "Massachussetts", "Massachusetts (U.S. state)", "Taxachusetts", "State of Massachusetts", "Massachusettes", "Massachusettsan", "Education in Massachusetts", "mass", "bay state", "massachusetts u s state", "ma state", "us ma", "massachusetts united states"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Massachusetts", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:52.233376Z"}
{"question_id": "tqa_rc_validation_88", "question": "In which American state is the Isabella Stewart Gardner Museum?", "ground_truth": ["Massachusetts", "Masachusetts", "Masshole Commonwealth", "Massachusetts (state)", "Massachusetts culture", "Massachusetts, United States", "Masachussetts", "Commonwealth of Masachusetts", "The Bay State", "Commonwealth of Masachussets", "Culture of Massachusetts", "Commonwealth of Massachusetts", "MA (state)", "Massechusetts", "Commonwealth of Masachusets", "Commonwealth of Massachussets", "Religion in Massachusetts", "Masschusetts", "Masachussets", "Commonwealth of Massachussetts", "Transport in Massachusetts", "Massachusite", "Economy of Massachusetts", "6th State", "Massitchusits", "Massachsuetts", "Commonwealth of Masachussetts", "The Commonwealth of Massachusetts", "Massachussets", "Massachus", "Massechussets", "Transportation in Massachusetts", "Massachusets", "Masachusets", "Mass.", "Massachusetts state", "Sixth State", "Massachusites", "Massacheusetts", "Most Serene Commonwealth of Massachusetts", "US-MA", "Commonwealth of Massachusets", "Massachussetts", "Massachusetts (U.S. state)", "Taxachusetts", "State of Massachusetts", "Massachusettes", "Massachusettsan", "Education in Massachusetts", "mass", "bay state", "massachusetts u s state", "ma state", "us ma", "massachusetts united states"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Massachusetts", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:53.846088Z"}
{"question_id": "tqa_rc_validation_88", "question": "In which American state is the Isabella Stewart Gardner Museum?", "ground_truth": ["Massachusetts", "Masachusetts", "Masshole Commonwealth", "Massachusetts (state)", "Massachusetts culture", "Massachusetts, United States", "Masachussetts", "Commonwealth of Masachusetts", "The Bay State", "Commonwealth of Masachussets", "Culture of Massachusetts", "Commonwealth of Massachusetts", "MA (state)", "Massechusetts", "Commonwealth of Masachusets", "Commonwealth of Massachussets", "Religion in Massachusetts", "Masschusetts", "Masachussets", "Commonwealth of Massachussetts", "Transport in Massachusetts", "Massachusite", "Economy of Massachusetts", "6th State", "Massitchusits", "Massachsuetts", "Commonwealth of Masachussetts", "The Commonwealth of Massachusetts", "Massachussets", "Massachus", "Massechussets", "Transportation in Massachusetts", "Massachusets", "Masachusets", "Mass.", "Massachusetts state", "Sixth State", "Massachusites", "Massacheusetts", "Most Serene Commonwealth of Massachusetts", "US-MA", "Commonwealth of Massachusets", "Massachussetts", "Massachusetts (U.S. state)", "Taxachusetts", "State of Massachusetts", "Massachusettes", "Massachusettsan", "Education in Massachusetts", "mass", "bay state", "massachusetts u s state", "ma state", "us ma", "massachusetts united states"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Massachusetts", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:54.896365Z"}
{"question_id": "tqa_rc_validation_89", "question": "Benina international airport is in which country?", "ground_truth": ["Libya", "Free Democratic Libya", "Islamic Republic of Libya", "Libya (National Transitional Council)", "Republic of Libya", "State of Libya", "Libyan Republic (2011)", "Libyan Republic", "ⵍⵉⴱⵢⴰ", "ليبيا", "Libiyah", "LBY", "Etymology of Libya", "Al-Jamahiriya al-%60Arabiyah al-Libiyah ash-Sha%60biyah al-Ishtirakiyah al-Uzma", "Largest cities in Libya", "Lībiyā", "Lybya", "Free Libya", "Libiya", "ISO 3166-1:LY", "iso 3166 1 ly", "libyan republic 2011", "libya national transitional council", "al jamahiriya al 60arabiyah al libiyah ash sha 60biyah al ishtirakiyah al uzma"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Libya", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:55.765388Z"}
{"question_id": "tqa_rc_validation_89", "question": "Benina international airport is in which country?", "ground_truth": ["Libya", "Free Democratic Libya", "Islamic Republic of Libya", "Libya (National Transitional Council)", "Republic of Libya", "State of Libya", "Libyan Republic (2011)", "Libyan Republic", "ⵍⵉⴱⵢⴰ", "ليبيا", "Libiyah", "LBY", "Etymology of Libya", "Al-Jamahiriya al-%60Arabiyah al-Libiyah ash-Sha%60biyah al-Ishtirakiyah al-Uzma", "Largest cities in Libya", "Lībiyā", "Lybya", "Free Libya", "Libiya", "ISO 3166-1:LY", "iso 3166 1 ly", "libyan republic 2011", "libya national transitional council", "al jamahiriya al 60arabiyah al libiyah ash sha 60biyah al ishtirakiyah al uzma"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Libya", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:57.514984Z"}
{"question_id": "tqa_rc_validation_89", "question": "Benina international airport is in which country?", "ground_truth": ["Libya", "Free Democratic Libya", "Islamic Republic of Libya", "Libya (National Transitional Council)", "Republic of Libya", "State of Libya", "Libyan Republic (2011)", "Libyan Republic", "ⵍⵉⴱⵢⴰ", "ليبيا", "Libiyah", "LBY", "Etymology of Libya", "Al-Jamahiriya al-%60Arabiyah al-Libiyah ash-Sha%60biyah al-Ishtirakiyah al-Uzma", "Largest cities in Libya", "Lībiyā", "Lybya", "Free Libya", "Libiya", "ISO 3166-1:LY", "iso 3166 1 ly", "libyan republic 2011", "libya national transitional council", "al jamahiriya al 60arabiyah al libiyah ash sha 60biyah al ishtirakiyah al uzma"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Libya", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:58.022075Z"}
{"question_id": "tqa_rc_validation_89", "question": "Benina international airport is in which country?", "ground_truth": ["Libya", "Free Democratic Libya", "Islamic Republic of Libya", "Libya (National Transitional Council)", "Republic of Libya", "State of Libya", "Libyan Republic (2011)", "Libyan Republic", "ⵍⵉⴱⵢⴰ", "ليبيا", "Libiyah", "LBY", "Etymology of Libya", "Al-Jamahiriya al-%60Arabiyah al-Libiyah ash-Sha%60biyah al-Ishtirakiyah al-Uzma", "Largest cities in Libya", "Lībiyā", "Lybya", "Free Libya", "Libiya", "ISO 3166-1:LY", "iso 3166 1 ly", "libyan republic 2011", "libya national transitional council", "al jamahiriya al 60arabiyah al libiyah ash sha 60biyah al ishtirakiyah al uzma"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Libya", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:59.151459Z"}
{"question_id": "tqa_rc_validation_89", "question": "Benina international airport is in which country?", "ground_truth": ["Libya", "Free Democratic Libya", "Islamic Republic of Libya", "Libya (National Transitional Council)", "Republic of Libya", "State of Libya", "Libyan Republic (2011)", "Libyan Republic", "ⵍⵉⴱⵢⴰ", "ليبيا", "Libiyah", "LBY", "Etymology of Libya", "Al-Jamahiriya al-%60Arabiyah al-Libiyah ash-Sha%60biyah al-Ishtirakiyah al-Uzma", "Largest cities in Libya", "Lībiyā", "Lybya", "Free Libya", "Libiya", "ISO 3166-1:LY", "iso 3166 1 ly", "libyan republic 2011", "libya national transitional council", "al jamahiriya al 60arabiyah al libiyah ash sha 60biyah al ishtirakiyah al uzma"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Libya", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:17:59.797415Z"}
{"question_id": "tqa_rc_validation_90", "question": "Beloved in 1999 was whose first movie since The Color Purple in 1985?", "ground_truth": ["Oprah Winfrey", "Oprah", "Ophra", "Oprah Winfery", "Winfrey, Oprah Gail", "Oprah Gail Winfrey", "Opera Winfrey", "Oprahism", "Oprah!", "Vernon Winfrey", "Oprah G Winfrey", "Harpo Radio, Inc.", "Orpah Winfrey", "Patricia Lee-Lloyd", "Oprah's Last Chapter", "Oprah's Angels", "Oprah winfre", "Harpo Winfrey", "Oprah G. Winfrey", "Harpo Inc.", "Oprah Winfry", "winfrey oprah gail", "patricia lee lloyd", "oprah s angels", "oprah s last chapter", "harpo radio inc", "harpo inc"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Oprah Winfrey", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:00.567284Z"}
{"question_id": "tqa_rc_validation_90", "question": "Beloved in 1999 was whose first movie since The Color Purple in 1985?", "ground_truth": ["Oprah Winfrey", "Oprah", "Ophra", "Oprah Winfery", "Winfrey, Oprah Gail", "Oprah Gail Winfrey", "Opera Winfrey", "Oprahism", "Oprah!", "Vernon Winfrey", "Oprah G Winfrey", "Harpo Radio, Inc.", "Orpah Winfrey", "Patricia Lee-Lloyd", "Oprah's Last Chapter", "Oprah's Angels", "Oprah winfre", "Harpo Winfrey", "Oprah G. Winfrey", "Harpo Inc.", "Oprah Winfry", "winfrey oprah gail", "patricia lee lloyd", "oprah s angels", "oprah s last chapter", "harpo radio inc", "harpo inc"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Oprah Winfrey", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:02.384988Z"}
{"question_id": "tqa_rc_validation_90", "question": "Beloved in 1999 was whose first movie since The Color Purple in 1985?", "ground_truth": ["Oprah Winfrey", "Oprah", "Ophra", "Oprah Winfery", "Winfrey, Oprah Gail", "Oprah Gail Winfrey", "Opera Winfrey", "Oprahism", "Oprah!", "Vernon Winfrey", "Oprah G Winfrey", "Harpo Radio, Inc.", "Orpah Winfrey", "Patricia Lee-Lloyd", "Oprah's Last Chapter", "Oprah's Angels", "Oprah winfre", "Harpo Winfrey", "Oprah G. Winfrey", "Harpo Inc.", "Oprah Winfry", "winfrey oprah gail", "patricia lee lloyd", "oprah s angels", "oprah s last chapter", "harpo radio inc", "harpo inc"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Oprah Winfrey", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:02.565970Z"}
{"question_id": "tqa_rc_validation_90", "question": "Beloved in 1999 was whose first movie since The Color Purple in 1985?", "ground_truth": ["Oprah Winfrey", "Oprah", "Ophra", "Oprah Winfery", "Winfrey, Oprah Gail", "Oprah Gail Winfrey", "Opera Winfrey", "Oprahism", "Oprah!", "Vernon Winfrey", "Oprah G Winfrey", "Harpo Radio, Inc.", "Orpah Winfrey", "Patricia Lee-Lloyd", "Oprah's Last Chapter", "Oprah's Angels", "Oprah winfre", "Harpo Winfrey", "Oprah G. Winfrey", "Harpo Inc.", "Oprah Winfry", "winfrey oprah gail", "patricia lee lloyd", "oprah s angels", "oprah s last chapter", "harpo radio inc", "harpo inc"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Oprah Winfrey", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:04.000558Z"}
{"question_id": "tqa_rc_validation_90", "question": "Beloved in 1999 was whose first movie since The Color Purple in 1985?", "ground_truth": ["Oprah Winfrey", "Oprah", "Ophra", "Oprah Winfery", "Winfrey, Oprah Gail", "Oprah Gail Winfrey", "Opera Winfrey", "Oprahism", "Oprah!", "Vernon Winfrey", "Oprah G Winfrey", "Harpo Radio, Inc.", "Orpah Winfrey", "Patricia Lee-Lloyd", "Oprah's Last Chapter", "Oprah's Angels", "Oprah winfre", "Harpo Winfrey", "Oprah G. Winfrey", "Harpo Inc.", "Oprah Winfry", "winfrey oprah gail", "patricia lee lloyd", "oprah s angels", "oprah s last chapter", "harpo radio inc", "harpo inc"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Morgan Freeman's", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Oprah Winfrey's", "Whoopi Goldberg's", "Oprah Winfrey", "Winfrey's", "Oprah Winfrey's", "That of Oprah Winfrey", "Oprah Winfrey's", "Toni Morrison's", "Oprah Winfrey", "Whoopi Goldberg's"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:18:20.331745Z"}
{"question_id": "tqa_rc_validation_91", "question": "Which Star Trek star directed Three Men and a Baby?", "ground_truth": ["Leonard Nimoy", "Leonard Nemoy", "Leonard Simon Nimoy"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Leonard Nimoy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:21.788034Z"}
{"question_id": "tqa_rc_validation_91", "question": "Which Star Trek star directed Three Men and a Baby?", "ground_truth": ["Leonard Nimoy", "Leonard Nemoy", "Leonard Simon Nimoy"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Leonard Nimoy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:23.464915Z"}
{"question_id": "tqa_rc_validation_91", "question": "Which Star Trek star directed Three Men and a Baby?", "ground_truth": ["Leonard Nimoy", "Leonard Nemoy", "Leonard Simon Nimoy"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Leonard Nimoy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:23.710674Z"}
{"question_id": "tqa_rc_validation_91", "question": "Which Star Trek star directed Three Men and a Baby?", "ground_truth": ["Leonard Nimoy", "Leonard Nemoy", "Leonard Simon Nimoy"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Leonard Nimoy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:25.242634Z"}
{"question_id": "tqa_rc_validation_91", "question": "Which Star Trek star directed Three Men and a Baby?", "ground_truth": ["Leonard Nimoy", "Leonard Nemoy", "Leonard Simon Nimoy"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Leonard Nimoy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:26.100970Z"}
{"question_id": "tqa_rc_validation_92", "question": "Which sitcom star appeared on the big screening The Object of My Affection?", "ground_truth": ["Jennifer Aniston", "Jennifer Anniston", "Jen Aniston", "Jennifer Pitt", "Jenifer Anniston", "Jenifer Aniston", "Pumas (film)", "Jennifer Anistion", "Jennifer Joanna Aniston", "Jennifer Joanna Anastassakis", "Aniston, Jennifer", "Counter Clockwise (film)", "Jennifer anastassakis", "aniston jennifer", "counter clockwise film", "pumas film"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Jennifer Aniston", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:26.919008Z"}
{"question_id": "tqa_rc_validation_92", "question": "Which sitcom star appeared on the big screening The Object of My Affection?", "ground_truth": ["Jennifer Aniston", "Jennifer Anniston", "Jen Aniston", "Jennifer Pitt", "Jenifer Anniston", "Jenifer Aniston", "Pumas (film)", "Jennifer Anistion", "Jennifer Joanna Aniston", "Jennifer Joanna Anastassakis", "Aniston, Jennifer", "Counter Clockwise (film)", "Jennifer anastassakis", "aniston jennifer", "counter clockwise film", "pumas film"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Jennifer Aniston", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:28.527895Z"}
{"question_id": "tqa_rc_validation_92", "question": "Which sitcom star appeared on the big screening The Object of My Affection?", "ground_truth": ["Jennifer Aniston", "Jennifer Anniston", "Jen Aniston", "Jennifer Pitt", "Jenifer Anniston", "Jenifer Aniston", "Pumas (film)", "Jennifer Anistion", "Jennifer Joanna Aniston", "Jennifer Joanna Anastassakis", "Aniston, Jennifer", "Counter Clockwise (film)", "Jennifer anastassakis", "aniston jennifer", "counter clockwise film", "pumas film"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Jennifer Aniston", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:28.773147Z"}
{"question_id": "tqa_rc_validation_92", "question": "Which sitcom star appeared on the big screening The Object of My Affection?", "ground_truth": ["Jennifer Aniston", "Jennifer Anniston", "Jen Aniston", "Jennifer Pitt", "Jenifer Anniston", "Jenifer Aniston", "Pumas (film)", "Jennifer Anistion", "Jennifer Joanna Aniston", "Jennifer Joanna Anastassakis", "Aniston, Jennifer", "Counter Clockwise (film)", "Jennifer anastassakis", "aniston jennifer", "counter clockwise film", "pumas film"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Jennifer Aniston", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:29.830990Z"}
{"question_id": "tqa_rc_validation_92", "question": "Which sitcom star appeared on the big screening The Object of My Affection?", "ground_truth": ["Jennifer Aniston", "Jennifer Anniston", "Jen Aniston", "Jennifer Pitt", "Jenifer Anniston", "Jenifer Aniston", "Pumas (film)", "Jennifer Anistion", "Jennifer Joanna Aniston", "Jennifer Joanna Anastassakis", "Aniston, Jennifer", "Counter Clockwise (film)", "Jennifer anastassakis", "aniston jennifer", "counter clockwise film", "pumas film"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Jennifer Aniston", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:30.609703Z"}
{"question_id": "tqa_rc_validation_93", "question": "\"Which character did Julia \"\"Roberts play in Steven Spielberg's Hook?\"", "ground_truth": ["Tinkerbell", "Pixie dust", "Tinker Bell", "Tinker Bell (Disney)", "Magic dust", "Pixie dust (disambiguation)", "Fairy dust", "Tink (film)", "tink film", "pixie dust disambiguation", "tinker bell disney"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Julia Roberts played Tinker Bell in *Hook*", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Julia Roberts played Tinker Bell", "Tinker Bell", "Julia Roberts played Tinker Bell in *Hook*", "Julia Roberts played Tinker Bell", "Tinker Bell", "She didn’t appear in *Hook*", "Julia Roberts played Tinker Bell in *Hook*", "Julia Roberts played Tinker Bell in *Hook*", "Tinker Bell", "Tinker Bell"], "equivalence_results": ["same", "same", "same", "same", "same", "different", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:18:50.828206Z"}
{"question_id": "tqa_rc_validation_93", "question": "\"Which character did Julia \"\"Roberts play in Steven Spielberg's Hook?\"", "ground_truth": ["Tinkerbell", "Pixie dust", "Tinker Bell", "Tinker Bell (Disney)", "Magic dust", "Pixie dust (disambiguation)", "Fairy dust", "Tink (film)", "tink film", "pixie dust disambiguation", "tinker bell disney"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Tinker Bell", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:52.581675Z"}
{"question_id": "tqa_rc_validation_93", "question": "\"Which character did Julia \"\"Roberts play in Steven Spielberg's Hook?\"", "ground_truth": ["Tinkerbell", "Pixie dust", "Tinker Bell", "Tinker Bell (Disney)", "Magic dust", "Pixie dust (disambiguation)", "Fairy dust", "Tink (film)", "tink film", "pixie dust disambiguation", "tinker bell disney"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Tinker Bell", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:53.001301Z"}
{"question_id": "tqa_rc_validation_93", "question": "\"Which character did Julia \"\"Roberts play in Steven Spielberg's Hook?\"", "ground_truth": ["Tinkerbell", "Pixie dust", "Tinker Bell", "Tinker Bell (Disney)", "Magic dust", "Pixie dust (disambiguation)", "Fairy dust", "Tink (film)", "tink film", "pixie dust disambiguation", "tinker bell disney"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Tinker Bell", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:54.199996Z"}
{"question_id": "tqa_rc_validation_93", "question": "\"Which character did Julia \"\"Roberts play in Steven Spielberg's Hook?\"", "ground_truth": ["Tinkerbell", "Pixie dust", "Tinker Bell", "Tinker Bell (Disney)", "Magic dust", "Pixie dust (disambiguation)", "Fairy dust", "Tink (film)", "tink film", "pixie dust disambiguation", "tinker bell disney"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Tinker Bell", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:55.031950Z"}
{"question_id": "tqa_rc_validation_94", "question": "Which US president did Anthony Hopkins play in a film whose title was simply his name?", "ground_truth": ["Nixon", "I'm not a crook", "Richard nixon", "Nixson", "Richard Milhouse Nixon", "Richard Milhous Nixon", "Nixonian", "Dick Nixon", "Nixonite", "Nixon, Richard", "37th President of the United States", "Resignation of Richard Nixon", "Richard Nickson", "Tricky Dick Nixon", "Nixon's", "Arthur Burdg Nixon", "Richard M. Nixon", "Tricky Dick", "Arthur Nixon", "Harold Samuel Nixon", "Richard M Nixon", "Harold Nixon", "Nixon, Richard Milhous", "Nixon, Richard M.", "Nichard rixon", "nixon richard m", "nixon richard milhous", "i m not crook", "37th president of united states", "nixon richard", "nixon s"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Richard Nixon", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:55.871177Z"}
{"question_id": "tqa_rc_validation_94", "question": "Which US president did Anthony Hopkins play in a film whose title was simply his name?", "ground_truth": ["Nixon", "I'm not a crook", "Richard nixon", "Nixson", "Richard Milhouse Nixon", "Richard Milhous Nixon", "Nixonian", "Dick Nixon", "Nixonite", "Nixon, Richard", "37th President of the United States", "Resignation of Richard Nixon", "Richard Nickson", "Tricky Dick Nixon", "Nixon's", "Arthur Burdg Nixon", "Richard M. Nixon", "Tricky Dick", "Arthur Nixon", "Harold Samuel Nixon", "Richard M Nixon", "Harold Nixon", "Nixon, Richard Milhous", "Nixon, Richard M.", "Nichard rixon", "nixon richard m", "nixon richard milhous", "i m not crook", "37th president of united states", "nixon richard", "nixon s"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Richard Nixon", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:57.534050Z"}
{"question_id": "tqa_rc_validation_94", "question": "Which US president did Anthony Hopkins play in a film whose title was simply his name?", "ground_truth": ["Nixon", "I'm not a crook", "Richard nixon", "Nixson", "Richard Milhouse Nixon", "Richard Milhous Nixon", "Nixonian", "Dick Nixon", "Nixonite", "Nixon, Richard", "37th President of the United States", "Resignation of Richard Nixon", "Richard Nickson", "Tricky Dick Nixon", "Nixon's", "Arthur Burdg Nixon", "Richard M. Nixon", "Tricky Dick", "Arthur Nixon", "Harold Samuel Nixon", "Richard M Nixon", "Harold Nixon", "Nixon, Richard Milhous", "Nixon, Richard M.", "Nichard rixon", "nixon richard m", "nixon richard milhous", "i m not crook", "37th president of united states", "nixon richard", "nixon s"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Nixon", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:57.757851Z"}
{"question_id": "tqa_rc_validation_94", "question": "Which US president did Anthony Hopkins play in a film whose title was simply his name?", "ground_truth": ["Nixon", "I'm not a crook", "Richard nixon", "Nixson", "Richard Milhouse Nixon", "Richard Milhous Nixon", "Nixonian", "Dick Nixon", "Nixonite", "Nixon, Richard", "37th President of the United States", "Resignation of Richard Nixon", "Richard Nickson", "Tricky Dick Nixon", "Nixon's", "Arthur Burdg Nixon", "Richard M. Nixon", "Tricky Dick", "Arthur Nixon", "Harold Samuel Nixon", "Richard M Nixon", "Harold Nixon", "Nixon, Richard Milhous", "Nixon, Richard M.", "Nichard rixon", "nixon richard m", "nixon richard milhous", "i m not crook", "37th president of united states", "nixon richard", "nixon s"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Nixon", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:58.899892Z"}
{"question_id": "tqa_rc_validation_94", "question": "Which US president did Anthony Hopkins play in a film whose title was simply his name?", "ground_truth": ["Nixon", "I'm not a crook", "Richard nixon", "Nixson", "Richard Milhouse Nixon", "Richard Milhous Nixon", "Nixonian", "Dick Nixon", "Nixonite", "Nixon, Richard", "37th President of the United States", "Resignation of Richard Nixon", "Richard Nickson", "Tricky Dick Nixon", "Nixon's", "Arthur Burdg Nixon", "Richard M. Nixon", "Tricky Dick", "Arthur Nixon", "Harold Samuel Nixon", "Richard M Nixon", "Harold Nixon", "Nixon, Richard Milhous", "Nixon, Richard M.", "Nichard rixon", "nixon richard m", "nixon richard milhous", "i m not crook", "37th president of united states", "nixon richard", "nixon s"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Nixon", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:18:59.684546Z"}
{"question_id": "tqa_rc_validation_95", "question": "Which movie was a biopic about the life of David Helfgott?", "ground_truth": ["Shine", "Shine (album)", "Shine (EP)", "Shine (song)", "Shiné", "Shine (disambiguation)", "Shine(Album)", "shine ep", "shine album", "shine disambiguation", "shine song"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Shine", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:00.495102Z"}
{"question_id": "tqa_rc_validation_95", "question": "Which movie was a biopic about the life of David Helfgott?", "ground_truth": ["Shine", "Shine (album)", "Shine (EP)", "Shine (song)", "Shiné", "Shine (disambiguation)", "Shine(Album)", "shine ep", "shine album", "shine disambiguation", "shine song"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Shine", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:01.391441Z"}
{"question_id": "tqa_rc_validation_95", "question": "Which movie was a biopic about the life of David Helfgott?", "ground_truth": ["Shine", "Shine (album)", "Shine (EP)", "Shine (song)", "Shiné", "Shine (disambiguation)", "Shine(Album)", "shine ep", "shine album", "shine disambiguation", "shine song"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Shine", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:01.615450Z"}
{"question_id": "tqa_rc_validation_95", "question": "Which movie was a biopic about the life of David Helfgott?", "ground_truth": ["Shine", "Shine (album)", "Shine (EP)", "Shine (song)", "Shiné", "Shine (disambiguation)", "Shine(Album)", "shine ep", "shine album", "shine disambiguation", "shine song"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Shine", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:02.752273Z"}
{"question_id": "tqa_rc_validation_95", "question": "Which movie was a biopic about the life of David Helfgott?", "ground_truth": ["Shine", "Shine (album)", "Shine (EP)", "Shine (song)", "Shiné", "Shine (disambiguation)", "Shine(Album)", "shine ep", "shine album", "shine disambiguation", "shine song"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Shine", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:03.520803Z"}
{"question_id": "tqa_rc_validation_96", "question": "Which film director guested as the FBI Director in The Silence of the Lambs?", "ground_truth": ["Roger Corman", "The Doorway (film)", "Roger William Corman", "doorway film"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Roger Corman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:04.274008Z"}
{"question_id": "tqa_rc_validation_96", "question": "Which film director guested as the FBI Director in The Silence of the Lambs?", "ground_truth": ["Roger Corman", "The Doorway (film)", "Roger William Corman", "doorway film"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Roger Corman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:05.958664Z"}
{"question_id": "tqa_rc_validation_96", "question": "Which film director guested as the FBI Director in The Silence of the Lambs?", "ground_truth": ["Roger Corman", "The Doorway (film)", "Roger William Corman", "doorway film"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Roger Corman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:06.105851Z"}
{"question_id": "tqa_rc_validation_0", "question": "Who was the man behind The Chipmunks?", "ground_truth": ["David Seville"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Ross Bagdasarian Sr", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ross Bagdasarian Sr", "Ross Bagdasarian Jr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Jr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr", "Ross Bagdasarian Jr", "Ross Bagdasarian Sr", "Ross Bagdasarian Sr"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:19:19.867449Z"}
{"question_id": "tqa_rc_validation_96", "question": "Which film director guested as the FBI Director in The Silence of the Lambs?", "ground_truth": ["Roger Corman", "The Doorway (film)", "Roger William Corman", "doorway film"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "George A", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Roger Corman", "George A", "George A", "George A", "George A", "Roger Corman", "George A", "George A", "George A", "George A"], "equivalence_results": ["different", "same", "same", "same", "same", "different", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:19:28.357700Z"}
{"question_id": "tqa_rc_validation_96", "question": "Which film director guested as the FBI Director in The Silence of the Lambs?", "ground_truth": ["Roger Corman", "The Doorway (film)", "Roger William Corman", "doorway film"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Jonathan Demme", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Jonathan Demme", "Jonathan Demme", "Jonathan Demme", "Jonathan Demme", "Jonathan Demme", "Jonathan Demme", "Jonathan Demme", "Jonathan Demme", "Jonathan Demme", "Jonathan Demme"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:19:47.490537Z"}
{"question_id": "tqa_rc_validation_97", "question": "In which sci fi classic did the space ship Nostromo first appear?", "ground_truth": ["Alien", "Alien (disambiguation)", "The Alien", "Alien (Alien)", "The Aliens", "Alien (fictional creature)", "The Aliens (band)", "Alians (disambiguation)", "Aliens (novel)", "Aliens (computer game)", "Alien (song)", "Aliens", "Aliens (disambiguation)", "The Alien (disambiguation)", "aliens computer game", "aliens disambiguation", "alien disambiguation", "alien song", "alians disambiguation", "aliens novel", "alien alien", "aliens band", "alien fictional creature"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Alien", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:48.293362Z"}
{"question_id": "tqa_rc_validation_97", "question": "In which sci fi classic did the space ship Nostromo first appear?", "ground_truth": ["Alien", "Alien (disambiguation)", "The Alien", "Alien (Alien)", "The Aliens", "Alien (fictional creature)", "The Aliens (band)", "Alians (disambiguation)", "Aliens (novel)", "Aliens (computer game)", "Alien (song)", "Aliens", "Aliens (disambiguation)", "The Alien (disambiguation)", "aliens computer game", "aliens disambiguation", "alien disambiguation", "alien song", "alians disambiguation", "aliens novel", "alien alien", "aliens band", "alien fictional creature"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Alien", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:49.958084Z"}
{"question_id": "tqa_rc_validation_97", "question": "In which sci fi classic did the space ship Nostromo first appear?", "ground_truth": ["Alien", "Alien (disambiguation)", "The Alien", "Alien (Alien)", "The Aliens", "Alien (fictional creature)", "The Aliens (band)", "Alians (disambiguation)", "Aliens (novel)", "Aliens (computer game)", "Alien (song)", "Aliens", "Aliens (disambiguation)", "The Alien (disambiguation)", "aliens computer game", "aliens disambiguation", "alien disambiguation", "alien song", "alians disambiguation", "aliens novel", "alien alien", "aliens band", "alien fictional creature"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Alien", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:50.372820Z"}
{"question_id": "tqa_rc_validation_97", "question": "In which sci fi classic did the space ship Nostromo first appear?", "ground_truth": ["Alien", "Alien (disambiguation)", "The Alien", "Alien (Alien)", "The Aliens", "Alien (fictional creature)", "The Aliens (band)", "Alians (disambiguation)", "Aliens (novel)", "Aliens (computer game)", "Alien (song)", "Aliens", "Aliens (disambiguation)", "The Alien (disambiguation)", "aliens computer game", "aliens disambiguation", "alien disambiguation", "alien song", "alians disambiguation", "aliens novel", "alien alien", "aliens band", "alien fictional creature"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Alien", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:52.072723Z"}
{"question_id": "tqa_rc_validation_97", "question": "In which sci fi classic did the space ship Nostromo first appear?", "ground_truth": ["Alien", "Alien (disambiguation)", "The Alien", "Alien (Alien)", "The Aliens", "Alien (fictional creature)", "The Aliens (band)", "Alians (disambiguation)", "Aliens (novel)", "Aliens (computer game)", "Alien (song)", "Aliens", "Aliens (disambiguation)", "The Alien (disambiguation)", "aliens computer game", "aliens disambiguation", "alien disambiguation", "alien song", "alians disambiguation", "aliens novel", "alien alien", "aliens band", "alien fictional creature"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Alien", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:52.900480Z"}
{"question_id": "tqa_rc_validation_98", "question": "Nigel Hawthorne was Oscar nominated for The Madness of which King?", "ground_truth": ["George", "Gheevarghese", "Vargheese", "Ghevargheese", "George (disambiguation)", "Ghevarghese", "Gheevargheese", "Vargis", "Geroge", "George's", "george s", "george disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "King George III", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:53.706420Z"}
{"question_id": "tqa_rc_validation_98", "question": "Nigel Hawthorne was Oscar nominated for The Madness of which King?", "ground_truth": ["George", "Gheevarghese", "Vargheese", "Ghevargheese", "George (disambiguation)", "Ghevarghese", "Gheevargheese", "Vargis", "Geroge", "George's", "george s", "george disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "King George III", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:54.741789Z"}
{"question_id": "tqa_rc_validation_98", "question": "Nigel Hawthorne was Oscar nominated for The Madness of which King?", "ground_truth": ["George", "Gheevarghese", "Vargheese", "Ghevargheese", "George (disambiguation)", "Ghevarghese", "Gheevargheese", "Vargis", "Geroge", "George's", "george s", "george disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "George III", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:54.891942Z"}
{"question_id": "tqa_rc_validation_98", "question": "Nigel Hawthorne was Oscar nominated for The Madness of which King?", "ground_truth": ["George", "Gheevarghese", "Vargheese", "Ghevargheese", "George (disambiguation)", "Ghevarghese", "Gheevargheese", "Vargis", "Geroge", "George's", "george s", "george disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "King George III", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:19:56.042738Z"}
{"question_id": "tqa_rc_validation_98", "question": "Nigel Hawthorne was Oscar nominated for The Madness of which King?", "ground_truth": ["George", "Gheevarghese", "Vargheese", "Ghevargheese", "George (disambiguation)", "Ghevarghese", "Gheevargheese", "Vargis", "Geroge", "George's", "george s", "george disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Madness of King George", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Madness of King George", "The Madness of King George", "The Madness of King George", "The Madness of King George", "The Madness of King George", "The Madness of King George", "Nigel Hawthorne was Oscar nominated for The Madness of King George", "King George IV", "Nigel Hawthorne was Oscar nominated for The Madness of King George", "The Madness of King George"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "different", "different", "different", "same"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:20:12.836742Z"}
{"question_id": "tqa_rc_validation_99", "question": "Which Swedish actress won the Best Supporting Actress Oscar for Murder on the Orient Express?", "ground_truth": ["Ingrid Bergman", "Ingrid Bergmann", "Isotta Ingrid Rossellini", "Ingrid Rossellini", "Ingrid Berman"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Ingrid Bergman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:13.578775Z"}
{"question_id": "tqa_rc_validation_99", "question": "Which Swedish actress won the Best Supporting Actress Oscar for Murder on the Orient Express?", "ground_truth": ["Ingrid Bergman", "Ingrid Bergmann", "Isotta Ingrid Rossellini", "Ingrid Rossellini", "Ingrid Berman"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Ingrid Bergman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:14.633140Z"}
{"question_id": "tqa_rc_validation_99", "question": "Which Swedish actress won the Best Supporting Actress Oscar for Murder on the Orient Express?", "ground_truth": ["Ingrid Bergman", "Ingrid Bergmann", "Isotta Ingrid Rossellini", "Ingrid Rossellini", "Ingrid Berman"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Ingrid Bergman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:14.836805Z"}
{"question_id": "tqa_rc_validation_99", "question": "Which Swedish actress won the Best Supporting Actress Oscar for Murder on the Orient Express?", "ground_truth": ["Ingrid Bergman", "Ingrid Bergmann", "Isotta Ingrid Rossellini", "Ingrid Rossellini", "Ingrid Berman"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Ingrid Bergman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:16.080477Z"}
{"question_id": "tqa_rc_validation_99", "question": "Which Swedish actress won the Best Supporting Actress Oscar for Murder on the Orient Express?", "ground_truth": ["Ingrid Bergman", "Ingrid Bergmann", "Isotta Ingrid Rossellini", "Ingrid Rossellini", "Ingrid Berman"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Ingrid Bergman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:17.187973Z"}
{"question_id": "tqa_rc_validation_100", "question": "Which Oscar-nominated film had You Sexy Thing as its theme song?", "ground_truth": ["The Full Monty", "Full Monty", "The Full Monty (film)", "The Full Monty (soundtrack)", "full monty film", "full monty soundtrack"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Full Monty", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:17.903072Z"}
{"question_id": "tqa_rc_validation_100", "question": "Which Oscar-nominated film had You Sexy Thing as its theme song?", "ground_truth": ["The Full Monty", "Full Monty", "The Full Monty (film)", "The Full Monty (soundtrack)", "full monty film", "full monty soundtrack"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The Full Monty", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:19.864188Z"}
{"question_id": "tqa_rc_validation_100", "question": "Which Oscar-nominated film had You Sexy Thing as its theme song?", "ground_truth": ["The Full Monty", "Full Monty", "The Full Monty (film)", "The Full Monty (soundtrack)", "full monty film", "full monty soundtrack"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Full Monty", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:20.321700Z"}
{"question_id": "tqa_rc_validation_100", "question": "Which Oscar-nominated film had You Sexy Thing as its theme song?", "ground_truth": ["The Full Monty", "Full Monty", "The Full Monty (film)", "The Full Monty (soundtrack)", "full monty film", "full monty soundtrack"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The Full Monty", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:21.547966Z"}
{"question_id": "tqa_rc_validation_100", "question": "Which Oscar-nominated film had You Sexy Thing as its theme song?", "ground_truth": ["The Full Monty", "Full Monty", "The Full Monty (film)", "The Full Monty (soundtrack)", "full monty film", "full monty soundtrack"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Full Monty", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:22.240896Z"}
{"question_id": "tqa_rc_validation_1", "question": "Which Lloyd Webber musical premiered in the US on 10th December 1993?", "ground_truth": ["Sunset Boulevard", "Sunset Blvd", "West Sunset Boulevard", "Sunset Bulevard", "Sunset Blvd."], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Sunset Boulevard", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:23.696244Z"}
{"question_id": "tqa_rc_validation_101", "question": "Which Joan's career revived in Whatever Happened to Baby Jane?", "ground_truth": ["Crawford", "Crawford (disambiguation)", "Crawford village", "Crawford (village)", "crawford disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Joan Crawford", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:23.696287Z"}
{"question_id": "tqa_rc_validation_1", "question": "Which Lloyd Webber musical premiered in the US on 10th December 1993?", "ground_truth": ["Sunset Boulevard", "Sunset Blvd", "West Sunset Boulevard", "Sunset Bulevard", "Sunset Blvd."], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Sunset Boulevard", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:24.196907Z"}
{"question_id": "tqa_rc_validation_101", "question": "Which Joan's career revived in Whatever Happened to Baby Jane?", "ground_truth": ["Crawford", "Crawford (disambiguation)", "Crawford village", "Crawford (village)", "crawford disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Joan Crawford", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:25.313985Z"}
{"question_id": "tqa_rc_validation_1", "question": "Which Lloyd Webber musical premiered in the US on 10th December 1993?", "ground_truth": ["Sunset Boulevard", "Sunset Blvd", "West Sunset Boulevard", "Sunset Bulevard", "Sunset Blvd."], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Sunset Boulevard", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:25.587173Z"}
{"question_id": "tqa_rc_validation_1", "question": "Which Lloyd Webber musical premiered in the US on 10th December 1993?", "ground_truth": ["Sunset Boulevard", "Sunset Blvd", "West Sunset Boulevard", "Sunset Bulevard", "Sunset Blvd."], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Sunset Boulevard", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:26.436074Z"}
{"question_id": "tqa_rc_validation_101", "question": "Which Joan's career revived in Whatever Happened to Baby Jane?", "ground_truth": ["Crawford", "Crawford (disambiguation)", "Crawford village", "Crawford (village)", "crawford disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Bette Davis and Joan Crawford", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Bette Davis and Joan Crawford", "Bette Davis and Joan Crawford", "Bette Davis and Joan Crawford", "Bette Davis and Joan Crawford", "Bette Davis and Joan Crawford", "Bette Davis and Joan Crawford", "Bette Davis and Joan Crawford", "Bette Davis and Joan Crawford", "Bette Davis and Joan Crawford", "Bette Davis and Joan Crawford"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:20:38.077997Z"}
{"question_id": "tqa_rc_validation_101", "question": "Which Joan's career revived in Whatever Happened to Baby Jane?", "ground_truth": ["Crawford", "Crawford (disambiguation)", "Crawford village", "Crawford (village)", "crawford disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Joan Crawford", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:39.323370Z"}
{"question_id": "tqa_rc_validation_101", "question": "Which Joan's career revived in Whatever Happened to Baby Jane?", "ground_truth": ["Crawford", "Crawford (disambiguation)", "Crawford village", "Crawford (village)", "crawford disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Joan Crawford", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:40.146894Z"}
{"question_id": "tqa_rc_validation_102", "question": "Which much-loved actor won the Best Actor Oscar for The Philadelphia Story?", "ground_truth": ["James Stewart", "James Stewart (actor)", "Jimmy Stuart", "Jimmy Stewart", "Stewart, James", "james stewart actor", "stewart james"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "James Stewart", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:40.998941Z"}
{"question_id": "tqa_rc_validation_102", "question": "Which much-loved actor won the Best Actor Oscar for The Philadelphia Story?", "ground_truth": ["James Stewart", "James Stewart (actor)", "Jimmy Stuart", "Jimmy Stewart", "Stewart, James", "james stewart actor", "stewart james"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "James Stewart", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:42.718657Z"}
{"question_id": "tqa_rc_validation_102", "question": "Which much-loved actor won the Best Actor Oscar for The Philadelphia Story?", "ground_truth": ["James Stewart", "James Stewart (actor)", "Jimmy Stuart", "Jimmy Stewart", "Stewart, James", "james stewart actor", "stewart james"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "James Stewart", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:43.169736Z"}
{"question_id": "tqa_rc_validation_102", "question": "Which much-loved actor won the Best Actor Oscar for The Philadelphia Story?", "ground_truth": ["James Stewart", "James Stewart (actor)", "Jimmy Stuart", "Jimmy Stewart", "Stewart, James", "james stewart actor", "stewart james"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "James Stewart", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:44.487493Z"}
{"question_id": "tqa_rc_validation_102", "question": "Which much-loved actor won the Best Actor Oscar for The Philadelphia Story?", "ground_truth": ["James Stewart", "James Stewart (actor)", "Jimmy Stuart", "Jimmy Stewart", "Stewart, James", "james stewart actor", "stewart james"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "James Stewart", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:45.257554Z"}
{"question_id": "tqa_rc_validation_103", "question": "Which legendary dancer was Oscar-nominated for The Towering Inferno?", "ground_truth": ["Fred Astaire", "Fred Astair", "Fred Austerlitz", "Frederick Austerlitz Astaire", "Frederick Austerlitz", "Fred astairey", "Fred Astare", "Phyllis Potter"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Fred Astaire", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:46.223912Z"}
{"question_id": "tqa_rc_validation_103", "question": "Which legendary dancer was Oscar-nominated for The Towering Inferno?", "ground_truth": ["Fred Astaire", "Fred Astair", "Fred Austerlitz", "Frederick Austerlitz Astaire", "Frederick Austerlitz", "Fred astairey", "Fred Astare", "Phyllis Potter"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Fred Astaire", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:47.766137Z"}
{"question_id": "tqa_rc_validation_103", "question": "Which legendary dancer was Oscar-nominated for The Towering Inferno?", "ground_truth": ["Fred Astaire", "Fred Astair", "Fred Austerlitz", "Frederick Austerlitz Astaire", "Frederick Austerlitz", "Fred astairey", "Fred Astare", "Phyllis Potter"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Jennifer Jones", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Jennifer Jones", "Jennifer Jones", "Jennifer Jones", "Jennifer Jones", "Jennifer Jones", "Jennifer Jones", "Jennifer Jones", "Jennifer Jones", "Jennifer Jones", "Jennifer Jones"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:20:58.574752Z"}
{"question_id": "tqa_rc_validation_103", "question": "Which legendary dancer was Oscar-nominated for The Towering Inferno?", "ground_truth": ["Fred Astaire", "Fred Astair", "Fred Austerlitz", "Frederick Austerlitz Astaire", "Frederick Austerlitz", "Fred astairey", "Fred Astare", "Phyllis Potter"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Fred Astaire", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:20:59.709351Z"}
{"question_id": "tqa_rc_validation_103", "question": "Which legendary dancer was Oscar-nominated for The Towering Inferno?", "ground_truth": ["Fred Astaire", "Fred Astair", "Fred Austerlitz", "Frederick Austerlitz Astaire", "Frederick Austerlitz", "Fred astairey", "Fred Astare", "Phyllis Potter"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Fred Astaire", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:00.607740Z"}
{"question_id": "tqa_rc_validation_104", "question": "What was the name of the brothel in The Best Little Whorehouse in Texas?", "ground_truth": ["Chicken Ranch", "Chicken Ranch (disambiguation)", "The Chicken Ranch", "chicken ranch disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Chicken Ranch", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:01.867753Z"}
{"question_id": "tqa_rc_validation_104", "question": "What was the name of the brothel in The Best Little Whorehouse in Texas?", "ground_truth": ["Chicken Ranch", "Chicken Ranch (disambiguation)", "The Chicken Ranch", "chicken ranch disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The Chicken Ranch", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:03.541634Z"}
{"question_id": "tqa_rc_validation_104", "question": "What was the name of the brothel in The Best Little Whorehouse in Texas?", "ground_truth": ["Chicken Ranch", "Chicken Ranch (disambiguation)", "The Chicken Ranch", "chicken ranch disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Chicken Ranch", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:03.799532Z"}
{"question_id": "tqa_rc_validation_104", "question": "What was the name of the brothel in The Best Little Whorehouse in Texas?", "ground_truth": ["Chicken Ranch", "Chicken Ranch (disambiguation)", "The Chicken Ranch", "chicken ranch disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The Chicken Ranch", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:05.004234Z"}
{"question_id": "tqa_rc_validation_104", "question": "What was the name of the brothel in The Best Little Whorehouse in Texas?", "ground_truth": ["Chicken Ranch", "Chicken Ranch (disambiguation)", "The Chicken Ranch", "chicken ranch disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Chicken Ranch", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:05.783824Z"}
{"question_id": "tqa_rc_validation_105", "question": "Who was the male star of the movie The Man of La Mancha?", "ground_truth": ["Peter O'Toole", "Peter o toole", "Peter O' Toole", "Peter Seamus Lorcan O'Toole", "Peter Seamus O'Toole", "Peter O’Toole", "Peter OToole", "peter seamus o toole", "peter seamus lorcan o toole"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Peter O'Toole", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:06.773702Z"}
{"question_id": "tqa_rc_validation_105", "question": "Who was the male star of the movie The Man of La Mancha?", "ground_truth": ["Peter O'Toole", "Peter o toole", "Peter O' Toole", "Peter Seamus Lorcan O'Toole", "Peter Seamus O'Toole", "Peter O’Toole", "Peter OToole", "peter seamus o toole", "peter seamus lorcan o toole"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Peter O'Toole", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:08.412425Z"}
{"question_id": "tqa_rc_validation_105", "question": "Who was the male star of the movie The Man of La Mancha?", "ground_truth": ["Peter O'Toole", "Peter o toole", "Peter O' Toole", "Peter Seamus Lorcan O'Toole", "Peter Seamus O'Toole", "Peter O’Toole", "Peter OToole", "peter seamus o toole", "peter seamus lorcan o toole"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Richard Burton was not the star, but rather, Peter O'Toole starred in the 1972 film version of Man of La Mancha, however the most well-known is probably the 1972 re-release starring Richard Kiel was not the star,", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Peter O'Toole (initially in the 1972 film) and later, other actors such as Richard Kiley", "Richard Burton, later adapted from the stage play, the original stage play starred Richard Kiley", "Richard Cox and Peter O'Toole both had major roles, but the main male star is generally considered to be Peter O'Toole, however, the musical also stars Richard Cox as the young Alonso", "Peter O'Toole (initially in the 1972 film version, although others had played the role on stage) or more specifically for the movie, Richard Burton was not, but Peter O'Toole was, however the most well-known", "Richard Burton starred alongside Sophia Loren, his wife at the time, but the actual male star in the 1972 film version \"The Man of La Mancha\" is Peter O'Toole, however the most famous is probably the 1972 lesser", "Peter O'Toole, then Richard Harris, and later, Matthew McConaughey, but originally, Richard Kiley was not the star, the original leading man was Richard Kiley's understudy, David Opatoshu was not the", "Richard Burton, but more famously, Peter O'Toole and later, Robert Guillaume and others in various adaptations, however the most well-known is probably the 1972 version starring Peter O'Toole", "Richard Burton was not the star, but rather, Peter O'Toole and/or Richard Roxburgh in different adaptations, however, the most well known is Peter O'Toole", "Richard Burton starred alongside Sophia Loren, his wife at the time, but the most famous version is with Peter O'Toole, however the most well-known male star is probably Richard Kiel was not, it was actually Peter O'Toole in the", "Richard Burton, then later Peter O'Toole, and also Richard Roxburgh in a more recent adaptation, but most famously, Peter O'Toole and Rex Harrison are not the only ones,  the most well-known is probably Richard Burton's"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "unclear", "different"], "equivalence_stats": {"num_same": 0, "num_different": 9, "num_unclear": 1, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:21:21.464970Z"}
{"question_id": "tqa_rc_validation_105", "question": "Who was the male star of the movie The Man of La Mancha?", "ground_truth": ["Peter O'Toole", "Peter o toole", "Peter O' Toole", "Peter Seamus Lorcan O'Toole", "Peter Seamus O'Toole", "Peter O’Toole", "Peter OToole", "peter seamus o toole", "peter seamus lorcan o toole"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Peter O'Toole", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:22.673675Z"}
{"question_id": "tqa_rc_validation_105", "question": "Who was the male star of the movie The Man of La Mancha?", "ground_truth": ["Peter O'Toole", "Peter o toole", "Peter O' Toole", "Peter Seamus Lorcan O'Toole", "Peter Seamus O'Toole", "Peter O’Toole", "Peter OToole", "peter seamus o toole", "peter seamus lorcan o toole"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Peter O'Toole", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:23.549547Z"}
{"question_id": "tqa_rc_validation_2", "question": "Who was the next British Prime Minister after Arthur Balfour?", "ground_truth": ["Campbell-Bannerman", "Sir Henry Campbell-Bannerman", "Campbell Bannerman", "Sir Henry Campbell Bannerman", "Henry Campbell Bannerman", "Henry Campbell-Bannerman"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Sir Henry Campbell-Bannerman", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:30.854721Z"}
{"question_id": "tqa_rc_validation_2", "question": "Who was the next British Prime Minister after Arthur Balfour?", "ground_truth": ["Campbell-Bannerman", "Sir Henry Campbell-Bannerman", "Campbell Bannerman", "Sir Henry Campbell Bannerman", "Henry Campbell Bannerman", "Henry Campbell-Bannerman"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Sir Henry Campbell-Bannerman", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:31.466498Z"}
{"question_id": "tqa_rc_validation_2", "question": "Who was the next British Prime Minister after Arthur Balfour?", "ground_truth": ["Campbell-Bannerman", "Sir Henry Campbell-Bannerman", "Campbell Bannerman", "Sir Henry Campbell Bannerman", "Henry Campbell Bannerman", "Henry Campbell-Bannerman"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Henry Campbell-Bannerman", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:32.782362Z"}
{"question_id": "tqa_rc_validation_2", "question": "Who was the next British Prime Minister after Arthur Balfour?", "ground_truth": ["Campbell-Bannerman", "Sir Henry Campbell-Bannerman", "Campbell Bannerman", "Sir Henry Campbell Bannerman", "Henry Campbell Bannerman", "Henry Campbell-Bannerman"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Sir Henry Campbell-Bannerman", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:33.825299Z"}
{"question_id": "tqa_rc_validation_106", "question": "What relation is Joey Richardson to Vanessa Redgrave?", "ground_truth": ["Daughter", "Daughterhood", "Daughters"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Grandson", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Granddaughter", "Grandson", "Granddaughter", "Grandson", "Grandson", "Grandson", "Grandson", "Joey Richardson is Vanessa Redgrave’s grandson", "Grandson", "Grandson"], "equivalence_results": ["different", "same", "different", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:21:43.058360Z"}
{"question_id": "tqa_rc_validation_106", "question": "What relation is Joey Richardson to Vanessa Redgrave?", "ground_truth": ["Daughter", "Daughterhood", "Daughters"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Daughter", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:44.764197Z"}
{"question_id": "tqa_rc_validation_106", "question": "What relation is Joey Richardson to Vanessa Redgrave?", "ground_truth": ["Daughter", "Daughterhood", "Daughters"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Daughter", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:21:45.227180Z"}
{"question_id": "tqa_rc_validation_106", "question": "What relation is Joey Richardson to Vanessa Redgrave?", "ground_truth": ["Daughter", "Daughterhood", "Daughters"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Niece", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Daughter", "Niece", "Niece", "Niece", "Daughter", "Daughter", "Niece", "Niece", "Daughter", "Daughter"], "equivalence_results": ["different", "same", "same", "same", "different", "different", "same", "same", "different", "different"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:22:06.840947Z"}
{"question_id": "tqa_rc_validation_106", "question": "What relation is Joey Richardson to Vanessa Redgrave?", "ground_truth": ["Daughter", "Daughterhood", "Daughters"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Joey Richardson is Vanessa Redgrave's daughter", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Joey Richardson is the daughter of Vanessa Redgrave", "Joey Richardson is Vanessa Redgrave's daughter", "Joely Richardson is Vanessa Redgrave's daughter", "They are mother and daughter", "Joey Richardson is Vanessa Redgrave's daughter", "Joely Richardson is the daughter of Vanessa Redgrave", "Joely Richardson's mother is Vanessa Redgrave", "Spouse", "Joey Richardson is Vanessa Redgrave's daughter", "Joey Richardson is the daughter of Vanessa Redgrave"], "equivalence_results": ["same", "same", "different", "same", "same", "different", "different", "different", "same", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:22:26.454909Z"}
{"question_id": "tqa_rc_validation_3", "question": "Who had a 70s No 1 hit with Kiss You All Over?", "ground_truth": ["Exile", "Internal exile", "Exiles", "Transported for life", "Exile (politics and government)", "Voluntary exile", "Sent into exile", "Exile and Banishment", "Self-exile", "Forced exile", "Exile in Greek tragedy", "Banish", "Banishment", "self exile", "exile politics and government"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Exile", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:38.265861Z"}
{"question_id": "tqa_rc_validation_3", "question": "Who had a 70s No 1 hit with Kiss You All Over?", "ground_truth": ["Exile", "Internal exile", "Exiles", "Transported for life", "Exile (politics and government)", "Voluntary exile", "Sent into exile", "Exile and Banishment", "Self-exile", "Forced exile", "Exile in Greek tragedy", "Banish", "Banishment", "self exile", "exile politics and government"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Exile", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:38.530157Z"}
{"question_id": "tqa_rc_validation_3", "question": "Who had a 70s No 1 hit with Kiss You All Over?", "ground_truth": ["Exile", "Internal exile", "Exiles", "Transported for life", "Exile (politics and government)", "Voluntary exile", "Sent into exile", "Exile and Banishment", "Self-exile", "Forced exile", "Exile in Greek tragedy", "Banish", "Banishment", "self exile", "exile politics and government"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Exile", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:39.925339Z"}
{"question_id": "tqa_rc_validation_3", "question": "Who had a 70s No 1 hit with Kiss You All Over?", "ground_truth": ["Exile", "Internal exile", "Exiles", "Transported for life", "Exile (politics and government)", "Voluntary exile", "Sent into exile", "Exile and Banishment", "Self-exile", "Forced exile", "Exile in Greek tragedy", "Banish", "Banishment", "self exile", "exile politics and government"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Exile", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:40.936003Z"}
{"question_id": "tqa_rc_validation_107", "question": "Melanie Molitor is the mom of which tennis world NO 1?", "ground_truth": ["Martina Hingis", "The Swiss Miss", "Martina Hingisová", "MartinaHingis", "Martina Hingisova", "Hingis", "swiss miss"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Roger Federer", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Roger Federer", "Roger Federer", "Novak Djokovic", "Roger Federer", "Roger Federer", "Roger Federer", "Novak Djokovic", "Novak Djokovic", "Novak Djokovic", "Roger Federer"], "equivalence_results": ["same", "same", "different", "same", "same", "same", "different", "different", "different", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:22:43.948415Z"}
{"question_id": "tqa_rc_validation_107", "question": "Melanie Molitor is the mom of which tennis world NO 1?", "ground_truth": ["Martina Hingis", "The Swiss Miss", "Martina Hingisová", "MartinaHingis", "Martina Hingisova", "Hingis", "swiss miss"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Martina Hingis", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:45.683216Z"}
{"question_id": "tqa_rc_validation_107", "question": "Melanie Molitor is the mom of which tennis world NO 1?", "ground_truth": ["Martina Hingis", "The Swiss Miss", "Martina Hingisová", "MartinaHingis", "Martina Hingisova", "Hingis", "swiss miss"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Martina Hingis", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:46.172786Z"}
{"question_id": "tqa_rc_validation_107", "question": "Melanie Molitor is the mom of which tennis world NO 1?", "ground_truth": ["Martina Hingis", "The Swiss Miss", "Martina Hingisová", "MartinaHingis", "Martina Hingisova", "Hingis", "swiss miss"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Martina Hingis", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:47.417401Z"}
{"question_id": "tqa_rc_validation_107", "question": "Melanie Molitor is the mom of which tennis world NO 1?", "ground_truth": ["Martina Hingis", "The Swiss Miss", "Martina Hingisová", "MartinaHingis", "Martina Hingisova", "Hingis", "swiss miss"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Martina Hingis", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:48.265925Z"}
{"question_id": "tqa_rc_validation_108", "question": "Marc Dutroux hit the headlines over a 'house of horrors' in which country?", "ground_truth": ["Belgium", "Belguim", "Koenigreich Belgien", "Belgium/Belgie", "Kingdom of Belgium", "Belgian", "Beljum", "Königreich Belgien", "Belgique", "Beligum", "Kingdom of the Belgians", "Beljam", "Belgum", "ISO 3166-1:BE", "Belgie", "Cockpit of Europe", "Koninkrijk België", "Beldjike", "Blegium", "Belgio", "The Quebec of Europe", "België", "Begium", "Royaume de Belgique", "Konigreich Belgien", "Koninkrijk Belgie", "People of Belgium", "Belgien", "Belgium/facts", "Administrative divisions of Belgium", "Belgium facts", "quebec of europe", "iso 3166 1 be", "kingdom of belgians", "belgium belgie"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Belgium", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:48.946415Z"}
{"question_id": "tqa_rc_validation_108", "question": "Marc Dutroux hit the headlines over a 'house of horrors' in which country?", "ground_truth": ["Belgium", "Belguim", "Koenigreich Belgien", "Belgium/Belgie", "Kingdom of Belgium", "Belgian", "Beljum", "Königreich Belgien", "Belgique", "Beligum", "Kingdom of the Belgians", "Beljam", "Belgum", "ISO 3166-1:BE", "Belgie", "Cockpit of Europe", "Koninkrijk België", "Beldjike", "Blegium", "Belgio", "The Quebec of Europe", "België", "Begium", "Royaume de Belgique", "Konigreich Belgien", "Koninkrijk Belgie", "People of Belgium", "Belgien", "Belgium/facts", "Administrative divisions of Belgium", "Belgium facts", "quebec of europe", "iso 3166 1 be", "kingdom of belgians", "belgium belgie"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Belgium", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:50.512523Z"}
{"question_id": "tqa_rc_validation_108", "question": "Marc Dutroux hit the headlines over a 'house of horrors' in which country?", "ground_truth": ["Belgium", "Belguim", "Koenigreich Belgien", "Belgium/Belgie", "Kingdom of Belgium", "Belgian", "Beljum", "Königreich Belgien", "Belgique", "Beligum", "Kingdom of the Belgians", "Beljam", "Belgum", "ISO 3166-1:BE", "Belgie", "Cockpit of Europe", "Koninkrijk België", "Beldjike", "Blegium", "Belgio", "The Quebec of Europe", "België", "Begium", "Royaume de Belgique", "Konigreich Belgien", "Koninkrijk Belgie", "People of Belgium", "Belgien", "Belgium/facts", "Administrative divisions of Belgium", "Belgium facts", "quebec of europe", "iso 3166 1 be", "kingdom of belgians", "belgium belgie"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Belgium", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:50.656825Z"}
{"question_id": "tqa_rc_validation_108", "question": "Marc Dutroux hit the headlines over a 'house of horrors' in which country?", "ground_truth": ["Belgium", "Belguim", "Koenigreich Belgien", "Belgium/Belgie", "Kingdom of Belgium", "Belgian", "Beljum", "Königreich Belgien", "Belgique", "Beligum", "Kingdom of the Belgians", "Beljam", "Belgum", "ISO 3166-1:BE", "Belgie", "Cockpit of Europe", "Koninkrijk België", "Beldjike", "Blegium", "Belgio", "The Quebec of Europe", "België", "Begium", "Royaume de Belgique", "Konigreich Belgien", "Koninkrijk Belgie", "People of Belgium", "Belgien", "Belgium/facts", "Administrative divisions of Belgium", "Belgium facts", "quebec of europe", "iso 3166 1 be", "kingdom of belgians", "belgium belgie"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Belgium", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:51.773653Z"}
{"question_id": "tqa_rc_validation_108", "question": "Marc Dutroux hit the headlines over a 'house of horrors' in which country?", "ground_truth": ["Belgium", "Belguim", "Koenigreich Belgien", "Belgium/Belgie", "Kingdom of Belgium", "Belgian", "Beljum", "Königreich Belgien", "Belgique", "Beligum", "Kingdom of the Belgians", "Beljam", "Belgum", "ISO 3166-1:BE", "Belgie", "Cockpit of Europe", "Koninkrijk België", "Beldjike", "Blegium", "Belgio", "The Quebec of Europe", "België", "Begium", "Royaume de Belgique", "Konigreich Belgien", "Koninkrijk Belgie", "People of Belgium", "Belgien", "Belgium/facts", "Administrative divisions of Belgium", "Belgium facts", "quebec of europe", "iso 3166 1 be", "kingdom of belgians", "belgium belgie"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Belgium", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:52.383177Z"}
{"question_id": "tqa_rc_validation_109", "question": "On which date in 1945 did Hitler take cyanide then shoot himself?", "ground_truth": ["April 30th", "Apr 30", "April 30, 2007", "April 30", "30th April", "May 0", "30 april", "April 30, 1789", "april 30 1789", "april 30 2007"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "30 April 1945", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:53.253801Z"}
{"question_id": "tqa_rc_validation_109", "question": "On which date in 1945 did Hitler take cyanide then shoot himself?", "ground_truth": ["April 30th", "Apr 30", "April 30, 2007", "April 30", "30th April", "May 0", "30 april", "April 30, 1789", "april 30 1789", "april 30 2007"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "April 30, 1945", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:54.896762Z"}
{"question_id": "tqa_rc_validation_109", "question": "On which date in 1945 did Hitler take cyanide then shoot himself?", "ground_truth": ["April 30th", "Apr 30", "April 30, 2007", "April 30", "30th April", "May 0", "30 april", "April 30, 1789", "april 30 1789", "april 30 2007"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "April 30", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:55.318056Z"}
{"question_id": "tqa_rc_validation_109", "question": "On which date in 1945 did Hitler take cyanide then shoot himself?", "ground_truth": ["April 30th", "Apr 30", "April 30, 2007", "April 30", "30th April", "May 0", "30 april", "April 30, 1789", "april 30 1789", "april 30 2007"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "April 30, 1945", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:56.541291Z"}
{"question_id": "tqa_rc_validation_109", "question": "On which date in 1945 did Hitler take cyanide then shoot himself?", "ground_truth": ["April 30th", "Apr 30", "April 30, 2007", "April 30", "30th April", "May 0", "30 april", "April 30, 1789", "april 30 1789", "april 30 2007"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "April 30, 1945", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:57.287427Z"}
{"question_id": "tqa_rc_validation_110", "question": "In which river is the Boulder Dam?", "ground_truth": ["Colorado", "Colorado (State)", "Colorful Colorado", "Special districts of Colorado", "Insignia of the State of Colorado", "List of military facilities in Colorado", "Coloradan", "Cuisines of Colorado", "Colorado (U.S. state)", "List of professional sports teams in Colorado", "Religion in Colorado", "Professional sport teams of Colorado", "Rocky Mountain Empire", "Thirty-eighth State", "38th State", "Coloradans", "Colorado, United States", "The Centennial State", "Colo.", "List of professional sports teams of Colorado", "Protected areas of Colorado", "Education in Colorado", "State of Colorado", "Columbine State", "List of former professional sports teams of Colorado", "US-CO", "Colorado protected areas", "Mother of Rivers", "List of Colorado state insignia", "Fine arts in Colorado", "Climate of Colorado", "Professional sports in Colorado", "Colorado state nickname", "Emblems of the State of Colorado", "Colorado military facilities", "Demographics of Colorado", "Colorada", "Kolorado", "Culture of Colorado", "Colarado", "Centennial State", "CO (state)", "Buffalo Plains State", "Military facilities in Colorado", "colorado state", "us co", "insignia of state of colorado", "colorado united states", "colo", "co state", "colorado u s state", "thirty eighth state", "emblems of state of colorado"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Colorado River", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:58.062498Z"}
{"question_id": "tqa_rc_validation_110", "question": "In which river is the Boulder Dam?", "ground_truth": ["Colorado", "Colorado (State)", "Colorful Colorado", "Special districts of Colorado", "Insignia of the State of Colorado", "List of military facilities in Colorado", "Coloradan", "Cuisines of Colorado", "Colorado (U.S. state)", "List of professional sports teams in Colorado", "Religion in Colorado", "Professional sport teams of Colorado", "Rocky Mountain Empire", "Thirty-eighth State", "38th State", "Coloradans", "Colorado, United States", "The Centennial State", "Colo.", "List of professional sports teams of Colorado", "Protected areas of Colorado", "Education in Colorado", "State of Colorado", "Columbine State", "List of former professional sports teams of Colorado", "US-CO", "Colorado protected areas", "Mother of Rivers", "List of Colorado state insignia", "Fine arts in Colorado", "Climate of Colorado", "Professional sports in Colorado", "Colorado state nickname", "Emblems of the State of Colorado", "Colorado military facilities", "Demographics of Colorado", "Colorada", "Kolorado", "Culture of Colorado", "Colarado", "Centennial State", "CO (state)", "Buffalo Plains State", "Military facilities in Colorado", "colorado state", "us co", "insignia of state of colorado", "colorado united states", "colo", "co state", "colorado u s state", "thirty eighth state", "emblems of state of colorado"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Colorado River", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:59.525957Z"}
{"question_id": "tqa_rc_validation_110", "question": "In which river is the Boulder Dam?", "ground_truth": ["Colorado", "Colorado (State)", "Colorful Colorado", "Special districts of Colorado", "Insignia of the State of Colorado", "List of military facilities in Colorado", "Coloradan", "Cuisines of Colorado", "Colorado (U.S. state)", "List of professional sports teams in Colorado", "Religion in Colorado", "Professional sport teams of Colorado", "Rocky Mountain Empire", "Thirty-eighth State", "38th State", "Coloradans", "Colorado, United States", "The Centennial State", "Colo.", "List of professional sports teams of Colorado", "Protected areas of Colorado", "Education in Colorado", "State of Colorado", "Columbine State", "List of former professional sports teams of Colorado", "US-CO", "Colorado protected areas", "Mother of Rivers", "List of Colorado state insignia", "Fine arts in Colorado", "Climate of Colorado", "Professional sports in Colorado", "Colorado state nickname", "Emblems of the State of Colorado", "Colorado military facilities", "Demographics of Colorado", "Colorada", "Kolorado", "Culture of Colorado", "Colarado", "Centennial State", "CO (state)", "Buffalo Plains State", "Military facilities in Colorado", "colorado state", "us co", "insignia of state of colorado", "colorado united states", "colo", "co state", "colorado u s state", "thirty eighth state", "emblems of state of colorado"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Colorado River", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:22:59.691644Z"}
{"question_id": "tqa_rc_validation_110", "question": "In which river is the Boulder Dam?", "ground_truth": ["Colorado", "Colorado (State)", "Colorful Colorado", "Special districts of Colorado", "Insignia of the State of Colorado", "List of military facilities in Colorado", "Coloradan", "Cuisines of Colorado", "Colorado (U.S. state)", "List of professional sports teams in Colorado", "Religion in Colorado", "Professional sport teams of Colorado", "Rocky Mountain Empire", "Thirty-eighth State", "38th State", "Coloradans", "Colorado, United States", "The Centennial State", "Colo.", "List of professional sports teams of Colorado", "Protected areas of Colorado", "Education in Colorado", "State of Colorado", "Columbine State", "List of former professional sports teams of Colorado", "US-CO", "Colorado protected areas", "Mother of Rivers", "List of Colorado state insignia", "Fine arts in Colorado", "Climate of Colorado", "Professional sports in Colorado", "Colorado state nickname", "Emblems of the State of Colorado", "Colorado military facilities", "Demographics of Colorado", "Colorada", "Kolorado", "Culture of Colorado", "Colarado", "Centennial State", "CO (state)", "Buffalo Plains State", "Military facilities in Colorado", "colorado state", "us co", "insignia of state of colorado", "colorado united states", "colo", "co state", "colorado u s state", "thirty eighth state", "emblems of state of colorado"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Colorado River", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:23:00.767421Z"}
{"question_id": "tqa_rc_validation_110", "question": "In which river is the Boulder Dam?", "ground_truth": ["Colorado", "Colorado (State)", "Colorful Colorado", "Special districts of Colorado", "Insignia of the State of Colorado", "List of military facilities in Colorado", "Coloradan", "Cuisines of Colorado", "Colorado (U.S. state)", "List of professional sports teams in Colorado", "Religion in Colorado", "Professional sport teams of Colorado", "Rocky Mountain Empire", "Thirty-eighth State", "38th State", "Coloradans", "Colorado, United States", "The Centennial State", "Colo.", "List of professional sports teams of Colorado", "Protected areas of Colorado", "Education in Colorado", "State of Colorado", "Columbine State", "List of former professional sports teams of Colorado", "US-CO", "Colorado protected areas", "Mother of Rivers", "List of Colorado state insignia", "Fine arts in Colorado", "Climate of Colorado", "Professional sports in Colorado", "Colorado state nickname", "Emblems of the State of Colorado", "Colorado military facilities", "Demographics of Colorado", "Colorada", "Kolorado", "Culture of Colorado", "Colarado", "Centennial State", "CO (state)", "Buffalo Plains State", "Military facilities in Colorado", "colorado state", "us co", "insignia of state of colorado", "colorado united states", "colo", "co state", "colorado u s state", "thirty eighth state", "emblems of state of colorado"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Colorado River", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:23:01.421665Z"}
{"question_id": "tqa_rc_validation_111", "question": "Which sports event was first held at Worcester, Massachusetts in 1927?", "ground_truth": ["Ryder Cup", "Ryder Cup Matches", "Rider cup", "The Ryder Cup"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The first Ryder Cup", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:23:02.338473Z"}
{"question_id": "tqa_rc_validation_111", "question": "Which sports event was first held at Worcester, Massachusetts in 1927?", "ground_truth": ["Ryder Cup", "Ryder Cup Matches", "Rider cup", "The Ryder Cup"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The Can-Am Games (Canada–America) — more specifically, the **Ryder Cup** was first held in Worcester, Massachusetts in 1927", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Can-Am Games (Canada–America) / The **Ryder Cup**", "The Can-Am Games (Canada–America) — more specifically, the **Ryder Cup**", "The Can-Am Games (specifically, the first **International Special Olympics** — but more accurately, the **Ryder Cup** was first held in Worcester, Massachusetts in 1927)", "The Can-Am Games (specifically, the first international ice hockey tournament known as the Can-Am series)", "The Can-Am Games (Canada–America) — more specifically, the **Ryder Cup** was first held at Worcester Country Club in Worcester, Massachusetts in 1927", "The Can-Am Games (Canada–America) — more specifically, the **Ryder Cup** was first held at Worcester Country Club in Worcester, Massachusetts in 1927", "The Can-Am Games (specifically, the first international competition in the sport of **candlepin bowling**)", "The Can-Am Games (also known as the Can-American Games or Canadian-American Games)", "The Can-Am Games (Canada–America) / The **Ryder Cup**", "The Can-Am Games (also known as the Canada–America games) were not the answer here"], "equivalence_results": ["same", "same", "same", "different", "same", "same", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:23:37.601266Z"}
{"question_id": "tqa_rc_validation_4", "question": "What claimed the life of singer Kathleen Ferrier?", "ground_truth": ["Cancer", "Cancer pathology", "Deaths by cancer", "Anti-cancer", "Cancer (disease)", "Cancerophobia", "Malignant lesion", "Cancer medication", "Malignant tumors", "Cancer signs", "Malignant neoplasm", "Invasive (cancer)", "Malignant Neoplasms", "Malignant growth", "Sporadic cancer", "Malignant cancer", "Tumour virus", "Cancer en cuirasse", "Microtumor", "Malignant tumour", "Carcinophobia", "Malignacy", "Cancer patient", "Epithelial cancers", "Solid cancer", "Cancers", "Tumor medication", "Malignant neoplastic disease", "AIDS-related cancer", "Invasive cancer", "Cancer therapy", "Cancerous tumor", "Financial toxicity", "Cancer diagnosis", "Cancer (medicine)", "Malignant tumor", "Cancerous", "Borderline (cancer)", "Signs of cancer", "Malignancies", "Cancer aromatase", "aids related cancer", "cancer disease", "cancer medicine", "borderline cancer", "anti cancer"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Cancer (breast cancer)", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:23:45.719698Z"}
{"question_id": "tqa_rc_validation_4", "question": "What claimed the life of singer Kathleen Ferrier?", "ground_truth": ["Cancer", "Cancer pathology", "Deaths by cancer", "Anti-cancer", "Cancer (disease)", "Cancerophobia", "Malignant lesion", "Cancer medication", "Malignant tumors", "Cancer signs", "Malignant neoplasm", "Invasive (cancer)", "Malignant Neoplasms", "Malignant growth", "Sporadic cancer", "Malignant cancer", "Tumour virus", "Cancer en cuirasse", "Microtumor", "Malignant tumour", "Carcinophobia", "Malignacy", "Cancer patient", "Epithelial cancers", "Solid cancer", "Cancers", "Tumor medication", "Malignant neoplastic disease", "AIDS-related cancer", "Invasive cancer", "Cancer therapy", "Cancerous tumor", "Financial toxicity", "Cancer diagnosis", "Cancer (medicine)", "Malignant tumor", "Cancerous", "Borderline (cancer)", "Signs of cancer", "Malignancies", "Cancer aromatase", "aids related cancer", "cancer disease", "cancer medicine", "borderline cancer", "anti cancer"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Breast cancer", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:23:45.940735Z"}
{"question_id": "tqa_rc_validation_4", "question": "What claimed the life of singer Kathleen Ferrier?", "ground_truth": ["Cancer", "Cancer pathology", "Deaths by cancer", "Anti-cancer", "Cancer (disease)", "Cancerophobia", "Malignant lesion", "Cancer medication", "Malignant tumors", "Cancer signs", "Malignant neoplasm", "Invasive (cancer)", "Malignant Neoplasms", "Malignant growth", "Sporadic cancer", "Malignant cancer", "Tumour virus", "Cancer en cuirasse", "Microtumor", "Malignant tumour", "Carcinophobia", "Malignacy", "Cancer patient", "Epithelial cancers", "Solid cancer", "Cancers", "Tumor medication", "Malignant neoplastic disease", "AIDS-related cancer", "Invasive cancer", "Cancer therapy", "Cancerous tumor", "Financial toxicity", "Cancer diagnosis", "Cancer (medicine)", "Malignant tumor", "Cancerous", "Borderline (cancer)", "Signs of cancer", "Malignancies", "Cancer aromatase", "aids related cancer", "cancer disease", "cancer medicine", "borderline cancer", "anti cancer"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Breast cancer", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:23:47.178195Z"}
{"question_id": "tqa_rc_validation_4", "question": "What claimed the life of singer Kathleen Ferrier?", "ground_truth": ["Cancer", "Cancer pathology", "Deaths by cancer", "Anti-cancer", "Cancer (disease)", "Cancerophobia", "Malignant lesion", "Cancer medication", "Malignant tumors", "Cancer signs", "Malignant neoplasm", "Invasive (cancer)", "Malignant Neoplasms", "Malignant growth", "Sporadic cancer", "Malignant cancer", "Tumour virus", "Cancer en cuirasse", "Microtumor", "Malignant tumour", "Carcinophobia", "Malignacy", "Cancer patient", "Epithelial cancers", "Solid cancer", "Cancers", "Tumor medication", "Malignant neoplastic disease", "AIDS-related cancer", "Invasive cancer", "Cancer therapy", "Cancerous tumor", "Financial toxicity", "Cancer diagnosis", "Cancer (medicine)", "Malignant tumor", "Cancerous", "Borderline (cancer)", "Signs of cancer", "Malignancies", "Cancer aromatase", "aids related cancer", "cancer disease", "cancer medicine", "borderline cancer", "anti cancer"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Breast cancer", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:23:47.921500Z"}
{"question_id": "tqa_rc_validation_111", "question": "Which sports event was first held at Worcester, Massachusetts in 1927?", "ground_truth": ["Ryder Cup", "Ryder Cup Matches", "Rider cup", "The Ryder Cup"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Rowing's Head of the Charles Regatta", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Rowing's Head of the Charles Regatta", "The Worcester, Massachusetts event in 1927 refers to the first American League Baseball tournament for minor league teams, but more likely it is the first held 'American Legion Junior Baseball World Series'  or 'National Little World Series', however the most accurate", "Rowing's Head of the Charles Regatta", "Rowing's IRA Regatta", "Rowing's Head of the Charles Regatta", "Rowing's Head of the Charles Regatta", "Rowing's Head of the Charles Regatta", "Rowing's Head of the Charles Regatta", "Rowing's Head of the Charles Regatta", "Head of the Charles is not correct"], "equivalence_results": ["same", "different", "same", "different", "same", "same", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:23:50.129856Z"}
{"question_id": "tqa_rc_validation_111", "question": "Which sports event was first held at Worcester, Massachusetts in 1927?", "ground_truth": ["Ryder Cup", "Ryder Cup Matches", "Rider cup", "The Ryder Cup"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The National Wheelchair Basketball Tournament", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The National Wheelchair Basketball Tournament", "The National Marbles Tournament", "The National Wheelchair Basketball Tournament", "The National Wheelchair Basketball Tournament", "The National Wheelchair Basketball Tournament", "The National Marbles Tournament", "The National Marbles Tournament", "The National Marbles Tournament", "The National Wheelchair Basketball Tournament", "The National Marbles Tournament"], "equivalence_results": ["same", "different", "same", "same", "same", "different", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:24:12.889385Z"}
{"question_id": "tqa_rc_validation_111", "question": "Which sports event was first held at Worcester, Massachusetts in 1927?", "ground_truth": ["Ryder Cup", "Ryder Cup Matches", "Rider cup", "The Ryder Cup"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The U", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The U", "The U", "The National Basketball League (NBL) championship was first held at Worcester, Massachusetts in 1927", "The Spalding World Series of Baseball was first held at Worcester, Massachusetts in 1927,", "The U", "The U", "The New England Marathon, but the one most likely to be referred to is the 1927 Little League World Series", "The Harpoon Winter Festival is not a major event however it was actually the Tewksbury Public Schools' 6th grade class (who at the time were going on to the 7th grade at the Tewksbury Jr", "The Super Bowl", "The American Basketball League Championship"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "different", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 1, "num_unclear": 9, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:24:31.676767Z"}
{"question_id": "tqa_rc_validation_112", "question": "In which European city is the Belvederen Gallery?", "ground_truth": ["Vienna", "Capital of Austria", "Wien", "Architecture of Vienna", "Vinarborg", "Government of Vienna", "Viena", "Demographics of Vienna", "City of Vienna", "Vienna (state)", "Wienna", "Vienna, AT-9", "Habsburg, Austria", "Vienna Porcelain", "Wene", "UN/LOCODE:ATVIE", "Vienna (Austria)", "Europe/Vienna", "Vindabona", "Vínarborg", "Wien, Austria", "Vienna, Austria", "Gemeinderat of Vienna", "Vindobonensis", "Bécs", "wien austria", "vienna state", "habsburg austria", "vienna austria", "vienna at 9", "un locode atvie", "europe vienna"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Vienna", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:24:32.907831Z"}
{"question_id": "tqa_rc_validation_112", "question": "In which European city is the Belvederen Gallery?", "ground_truth": ["Vienna", "Capital of Austria", "Wien", "Architecture of Vienna", "Vinarborg", "Government of Vienna", "Viena", "Demographics of Vienna", "City of Vienna", "Vienna (state)", "Wienna", "Vienna, AT-9", "Habsburg, Austria", "Vienna Porcelain", "Wene", "UN/LOCODE:ATVIE", "Vienna (Austria)", "Europe/Vienna", "Vindabona", "Vínarborg", "Wien, Austria", "Vienna, Austria", "Gemeinderat of Vienna", "Vindobonensis", "Bécs", "wien austria", "vienna state", "habsburg austria", "vienna austria", "vienna at 9", "un locode atvie", "europe vienna"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Vienna", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:24:34.516968Z"}
{"question_id": "tqa_rc_validation_112", "question": "In which European city is the Belvederen Gallery?", "ground_truth": ["Vienna", "Capital of Austria", "Wien", "Architecture of Vienna", "Vinarborg", "Government of Vienna", "Viena", "Demographics of Vienna", "City of Vienna", "Vienna (state)", "Wienna", "Vienna, AT-9", "Habsburg, Austria", "Vienna Porcelain", "Wene", "UN/LOCODE:ATVIE", "Vienna (Austria)", "Europe/Vienna", "Vindabona", "Vínarborg", "Wien, Austria", "Vienna, Austria", "Gemeinderat of Vienna", "Vindobonensis", "Bécs", "wien austria", "vienna state", "habsburg austria", "vienna austria", "vienna at 9", "un locode atvie", "europe vienna"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Vienna", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:24:34.799044Z"}
{"question_id": "tqa_rc_validation_112", "question": "In which European city is the Belvederen Gallery?", "ground_truth": ["Vienna", "Capital of Austria", "Wien", "Architecture of Vienna", "Vinarborg", "Government of Vienna", "Viena", "Demographics of Vienna", "City of Vienna", "Vienna (state)", "Wienna", "Vienna, AT-9", "Habsburg, Austria", "Vienna Porcelain", "Wene", "UN/LOCODE:ATVIE", "Vienna (Austria)", "Europe/Vienna", "Vindabona", "Vínarborg", "Wien, Austria", "Vienna, Austria", "Gemeinderat of Vienna", "Vindobonensis", "Bécs", "wien austria", "vienna state", "habsburg austria", "vienna austria", "vienna at 9", "un locode atvie", "europe vienna"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Vienna", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:24:35.979640Z"}
{"question_id": "tqa_rc_validation_112", "question": "In which European city is the Belvederen Gallery?", "ground_truth": ["Vienna", "Capital of Austria", "Wien", "Architecture of Vienna", "Vinarborg", "Government of Vienna", "Viena", "Demographics of Vienna", "City of Vienna", "Vienna (state)", "Wienna", "Vienna, AT-9", "Habsburg, Austria", "Vienna Porcelain", "Wene", "UN/LOCODE:ATVIE", "Vienna (Austria)", "Europe/Vienna", "Vindabona", "Vínarborg", "Wien, Austria", "Vienna, Austria", "Gemeinderat of Vienna", "Vindobonensis", "Bécs", "wien austria", "vienna state", "habsburg austria", "vienna austria", "vienna at 9", "un locode atvie", "europe vienna"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Vatican City, Rome", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Vatican City (within Rome)", "Vienna", "Vienna", "Vienna", "Vatican City (Rome)", "Vatican City, a city-state located within Rome, Italy", "Vienna", "Vienna", "Vatican City, Rome", "Rome"], "equivalence_results": ["same", "different", "different", "different", "same", "same", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:24:52.122796Z"}
{"question_id": "tqa_rc_validation_5", "question": "Rita Coolidge sang the title song for which Bond film?", "ground_truth": ["Octopussy", "Kamal kahn", "List of Bond girls in Octopussy", "Magda (James Bond)", "List of James Bond allies in Octopussy", "Vijay (James Bond)", "Bond 13", "Octopussy (character)", "Penelope Smallbone", "General Orlov", "Kamal Khan", "Octopussy (film)", "List of James Bond villains in Octopussy", "Jim Fanning (James Bond)", "magda james bond", "vijay james bond", "jim fanning james bond", "octopussy character", "octopussy film"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Octopussy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:24:53.098044Z"}
{"question_id": "tqa_rc_validation_113", "question": "How old was Woody Herman when he founded his own orchestra?", "ground_truth": ["13", "thirteen"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "23", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["23", "24", "23", "23", "23", "23", "23", "23", "24", "24"], "equivalence_results": ["same", "different", "same", "same", "same", "same", "same", "same", "different", "different"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:25:09.368189Z"}
{"question_id": "tqa_rc_validation_113", "question": "How old was Woody Herman when he founded his own orchestra?", "ground_truth": ["13", "thirteen"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "23", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["23", "23", "23", "23", "23", "23", "23", "23", "23", "23"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:25:36.831862Z"}
{"question_id": "tqa_rc_validation_113", "question": "How old was Woody Herman when he founded his own orchestra?", "ground_truth": ["13", "thirteen"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "20", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["20", "23", "20", "26", "20", "21", "20", "24", "20", "20"], "equivalence_results": ["same", "different", "same", "different", "same", "different", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:25:48.517176Z"}
{"question_id": "tqa_rc_validation_113", "question": "How old was Woody Herman when he founded his own orchestra?", "ground_truth": ["13", "thirteen"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "23", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["23", "23", "23", "23", "23", "23", "23", "23", "23", "23"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:26:09.626008Z"}
{"question_id": "tqa_rc_validation_113", "question": "How old was Woody Herman when he founded his own orchestra?", "ground_truth": ["13", "thirteen"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "25", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["24", "23 years old", "25", "24", "Woody Herman was 25 years old when he formed his first band, later known as the First Herd, in 1936", "20 years old", "25", "22", "25", "28"], "equivalence_results": ["different", "different", "same", "different", "same", "different", "same", "different", "same", "different"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:26:28.156211Z"}
{"question_id": "tqa_rc_validation_114", "question": "For which movie did Katharine Hepburn win her second Oscar?", "ground_truth": ["Guess Who's Coming To Dinner", "Guess Who's Coming to Dinner%3F", "Guess whose coming to dinner", "guess who s coming to dinner", "guess who s coming to dinner 3f"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Guess Who’s Coming to Dinner", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Guess Who’s Coming to Dinner", "Guess Who’s Coming to Dinner", "Guess Who’s Coming to Dinner", "Guess Who’s Coming to Dinner", "Guess Who’s Coming to Dinner", "Guess Who’s Coming to Dinner", "Guess Who’s Coming to Dinner", "Guess Who’s Coming to Dinner", "Guess Who’s Coming to Dinner", "Guess Who’s Coming to Dinner"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:26:50.000968Z"}
{"question_id": "tqa_rc_validation_114", "question": "For which movie did Katharine Hepburn win her second Oscar?", "ground_truth": ["Guess Who's Coming To Dinner", "Guess Who's Coming to Dinner%3F", "Guess whose coming to dinner", "guess who s coming to dinner", "guess who s coming to dinner 3f"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Guess Who's Coming to Dinner", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:26:51.792647Z"}
{"question_id": "tqa_rc_validation_114", "question": "For which movie did Katharine Hepburn win her second Oscar?", "ground_truth": ["Guess Who's Coming To Dinner", "Guess Who's Coming to Dinner%3F", "Guess whose coming to dinner", "guess who s coming to dinner", "guess who s coming to dinner 3f"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Lion in Winter", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Lion in Winter", "The Lion in Winter", "The Lion in Winter", "The Lion in Winter", "The Lion in Winter", "The Lion in Winter", "The Lion in Winter", "The Lion in Winter", "The Lion in Winter", "The Lion in Winter"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:27:03.045424Z"}
{"question_id": "tqa_rc_validation_114", "question": "For which movie did Katharine Hepburn win her second Oscar?", "ground_truth": ["Guess Who's Coming To Dinner", "Guess Who's Coming to Dinner%3F", "Guess whose coming to dinner", "guess who s coming to dinner", "guess who s coming to dinner 3f"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Guess Who's Coming to Dinner", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:04.484018Z"}
{"question_id": "tqa_rc_validation_114", "question": "For which movie did Katharine Hepburn win her second Oscar?", "ground_truth": ["Guess Who's Coming To Dinner", "Guess Who's Coming to Dinner%3F", "Guess whose coming to dinner", "guess who s coming to dinner", "guess who s coming to dinner 3f"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Morning Glory (1933)", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Morning Glory (1933)", "The Philadelphia Story", "Morning Glory", "Morning Glory (1933)", "Morning Glory (1933)", "Morning Glory", "Morning Glory (1933)", "Guess Who's Coming to Dinner", "Morning Glory (1933)", "Morning Glory (1933)"], "equivalence_results": ["same", "different", "same", "same", "same", "same", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:27:22.407437Z"}
{"question_id": "tqa_rc_validation_115", "question": "Who had a 60s No 1 hit with This Diamond Ring?", "ground_truth": ["Gary Lewis and the Playboys", "Dave Gonzalez (Gary Lewis & the Playboys)", "Gary Lewis & the Playboys", "gary lewis and playboys", "dave gonzalez gary lewis playboys", "gary lewis playboys"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Gary Lewis & the Playboys", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:23.451392Z"}
{"question_id": "tqa_rc_validation_115", "question": "Who had a 60s No 1 hit with This Diamond Ring?", "ground_truth": ["Gary Lewis and the Playboys", "Dave Gonzalez (Gary Lewis & the Playboys)", "Gary Lewis & the Playboys", "gary lewis and playboys", "dave gonzalez gary lewis playboys", "gary lewis playboys"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Gary Lewis and the Playboys", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:25.397523Z"}
{"question_id": "tqa_rc_validation_115", "question": "Who had a 60s No 1 hit with This Diamond Ring?", "ground_truth": ["Gary Lewis and the Playboys", "Dave Gonzalez (Gary Lewis & the Playboys)", "Gary Lewis & the Playboys", "gary lewis and playboys", "dave gonzalez gary lewis playboys", "gary lewis playboys"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Gary Lewis & the Playboys", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:25.656846Z"}
{"question_id": "tqa_rc_validation_115", "question": "Who had a 60s No 1 hit with This Diamond Ring?", "ground_truth": ["Gary Lewis and the Playboys", "Dave Gonzalez (Gary Lewis & the Playboys)", "Gary Lewis & the Playboys", "gary lewis and playboys", "dave gonzalez gary lewis playboys", "gary lewis playboys"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Gary Lewis & The Playboys", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:27.100360Z"}
{"question_id": "tqa_rc_validation_115", "question": "Who had a 60s No 1 hit with This Diamond Ring?", "ground_truth": ["Gary Lewis and the Playboys", "Dave Gonzalez (Gary Lewis & the Playboys)", "Gary Lewis & the Playboys", "gary lewis and playboys", "dave gonzalez gary lewis playboys", "gary lewis playboys"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Gary Lewis and the Playboys", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:27.877154Z"}
{"question_id": "tqa_rc_validation_116", "question": "The world was first aware of the Chernobyl disaster after detectors were triggered at a nuclear plant in which country?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Sweden", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:28.553603Z"}
{"question_id": "tqa_rc_validation_116", "question": "The world was first aware of the Chernobyl disaster after detectors were triggered at a nuclear plant in which country?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Sweden", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:30.096100Z"}
{"question_id": "tqa_rc_validation_116", "question": "The world was first aware of the Chernobyl disaster after detectors were triggered at a nuclear plant in which country?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Sweden", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:30.465294Z"}
{"question_id": "tqa_rc_validation_116", "question": "The world was first aware of the Chernobyl disaster after detectors were triggered at a nuclear plant in which country?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Sweden", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:31.825921Z"}
{"question_id": "tqa_rc_validation_116", "question": "The world was first aware of the Chernobyl disaster after detectors were triggered at a nuclear plant in which country?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Sweden", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:32.595084Z"}
{"question_id": "tqa_rc_validation_117", "question": "In which country was the first permanent bungee jumping site situated?", "ground_truth": ["New Zealand", "N Z", "Nouvelle-Zelande", "Kiwiland", "New Zealand's", "New Zealand.", "Nz", "New Zealand,", "NEW Z", "N Zealand", "New Zealend", "Administrative divisions of new zealand", "New Zaeland", "Kiwistan", "Enzed", "NewZealand", "Name of New Zealand", "Staten Landt", "New+Zealand", "NZL", "Nu Tirani", "Neo Zealand", "ISO 3166-1:NZ", "New Zealnd", "AoTeAroa", "Sheepland", "Aotearoa / New Zealand", "Subdivisions of New Zealand", "Its got that new zeal", "New Zeland", "New-Zealand", "New Zeeland", "New Zealnad", "Staten Land", "N.Z.", "Staaten land", "New.Zealand", "Mew Zealand", "Maoriland", "N. Zealand", "Etymology of New Zealand", "New Xealand", "Māoria", "New zelanad", "Niu Tireni", "Nova Zeelandia", "new zealand s", "iso 3166 1 nz", "aotearoa new zealand", "nouvelle zelande"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "New Zealand", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:33.289004Z"}
{"question_id": "tqa_rc_validation_117", "question": "In which country was the first permanent bungee jumping site situated?", "ground_truth": ["New Zealand", "N Z", "Nouvelle-Zelande", "Kiwiland", "New Zealand's", "New Zealand.", "Nz", "New Zealand,", "NEW Z", "N Zealand", "New Zealend", "Administrative divisions of new zealand", "New Zaeland", "Kiwistan", "Enzed", "NewZealand", "Name of New Zealand", "Staten Landt", "New+Zealand", "NZL", "Nu Tirani", "Neo Zealand", "ISO 3166-1:NZ", "New Zealnd", "AoTeAroa", "Sheepland", "Aotearoa / New Zealand", "Subdivisions of New Zealand", "Its got that new zeal", "New Zeland", "New-Zealand", "New Zeeland", "New Zealnad", "Staten Land", "N.Z.", "Staaten land", "New.Zealand", "Mew Zealand", "Maoriland", "N. Zealand", "Etymology of New Zealand", "New Xealand", "Māoria", "New zelanad", "Niu Tireni", "Nova Zeelandia", "new zealand s", "iso 3166 1 nz", "aotearoa new zealand", "nouvelle zelande"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "New Zealand", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:34.921244Z"}
{"question_id": "tqa_rc_validation_117", "question": "In which country was the first permanent bungee jumping site situated?", "ground_truth": ["New Zealand", "N Z", "Nouvelle-Zelande", "Kiwiland", "New Zealand's", "New Zealand.", "Nz", "New Zealand,", "NEW Z", "N Zealand", "New Zealend", "Administrative divisions of new zealand", "New Zaeland", "Kiwistan", "Enzed", "NewZealand", "Name of New Zealand", "Staten Landt", "New+Zealand", "NZL", "Nu Tirani", "Neo Zealand", "ISO 3166-1:NZ", "New Zealnd", "AoTeAroa", "Sheepland", "Aotearoa / New Zealand", "Subdivisions of New Zealand", "Its got that new zeal", "New Zeland", "New-Zealand", "New Zeeland", "New Zealnad", "Staten Land", "N.Z.", "Staaten land", "New.Zealand", "Mew Zealand", "Maoriland", "N. Zealand", "Etymology of New Zealand", "New Xealand", "Māoria", "New zelanad", "Niu Tireni", "Nova Zeelandia", "new zealand s", "iso 3166 1 nz", "aotearoa new zealand", "nouvelle zelande"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "New Zealand", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:35.070535Z"}
{"question_id": "tqa_rc_validation_117", "question": "In which country was the first permanent bungee jumping site situated?", "ground_truth": ["New Zealand", "N Z", "Nouvelle-Zelande", "Kiwiland", "New Zealand's", "New Zealand.", "Nz", "New Zealand,", "NEW Z", "N Zealand", "New Zealend", "Administrative divisions of new zealand", "New Zaeland", "Kiwistan", "Enzed", "NewZealand", "Name of New Zealand", "Staten Landt", "New+Zealand", "NZL", "Nu Tirani", "Neo Zealand", "ISO 3166-1:NZ", "New Zealnd", "AoTeAroa", "Sheepland", "Aotearoa / New Zealand", "Subdivisions of New Zealand", "Its got that new zeal", "New Zeland", "New-Zealand", "New Zeeland", "New Zealnad", "Staten Land", "N.Z.", "Staaten land", "New.Zealand", "Mew Zealand", "Maoriland", "N. Zealand", "Etymology of New Zealand", "New Xealand", "Māoria", "New zelanad", "Niu Tireni", "Nova Zeelandia", "new zealand s", "iso 3166 1 nz", "aotearoa new zealand", "nouvelle zelande"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "New Zealand", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:36.249864Z"}
{"question_id": "tqa_rc_validation_117", "question": "In which country was the first permanent bungee jumping site situated?", "ground_truth": ["New Zealand", "N Z", "Nouvelle-Zelande", "Kiwiland", "New Zealand's", "New Zealand.", "Nz", "New Zealand,", "NEW Z", "N Zealand", "New Zealend", "Administrative divisions of new zealand", "New Zaeland", "Kiwistan", "Enzed", "NewZealand", "Name of New Zealand", "Staten Landt", "New+Zealand", "NZL", "Nu Tirani", "Neo Zealand", "ISO 3166-1:NZ", "New Zealnd", "AoTeAroa", "Sheepland", "Aotearoa / New Zealand", "Subdivisions of New Zealand", "Its got that new zeal", "New Zeland", "New-Zealand", "New Zeeland", "New Zealnad", "Staten Land", "N.Z.", "Staaten land", "New.Zealand", "Mew Zealand", "Maoriland", "N. Zealand", "Etymology of New Zealand", "New Xealand", "Māoria", "New zelanad", "Niu Tireni", "Nova Zeelandia", "new zealand s", "iso 3166 1 nz", "aotearoa new zealand", "nouvelle zelande"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "New Zealand", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:36.939266Z"}
{"question_id": "tqa_rc_validation_118", "question": "Who succeeded Brezhnev as Soviet premier?", "ground_truth": ["Andropov", "Yuri V. Andropov", "Yuri Andropov", "Yuriy Andropov", "Yuri Vladimirovich Andropov", "Andropou", "Jurij Vladimirovič Andropov", "Ю́рий Влади́мирович Андро́пов", "Juri Andropov", "Jurij Andropov", "Yury Andropov", "Yury Vladimirovich Andropov", "Jurij Vladimirovic Andropov", "yuri v andropov"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Nikolai Tikhonov", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Nikolai Tikhonov", "Nikolai Tikhonov", "Nikolai Tikhonov", "Nikolai Tikhonov", "Nikolai Tikhonov", "Nikolai Tikhonov", "Nikolai Tikhonov", "Nikolai Tikhonov", "Nikolai Tikhonov", "Nikolai Tikhonov"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:27:56.033492Z"}
{"question_id": "tqa_rc_validation_118", "question": "Who succeeded Brezhnev as Soviet premier?", "ground_truth": ["Andropov", "Yuri V. Andropov", "Yuri Andropov", "Yuriy Andropov", "Yuri Vladimirovich Andropov", "Andropou", "Jurij Vladimirovič Andropov", "Ю́рий Влади́мирович Андро́пов", "Juri Andropov", "Jurij Andropov", "Yury Andropov", "Yury Vladimirovich Andropov", "Jurij Vladimirovic Andropov", "yuri v andropov"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Yuri Andropov", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:57.796401Z"}
{"question_id": "tqa_rc_validation_118", "question": "Who succeeded Brezhnev as Soviet premier?", "ground_truth": ["Andropov", "Yuri V. Andropov", "Yuri Andropov", "Yuriy Andropov", "Yuri Vladimirovich Andropov", "Andropou", "Jurij Vladimirovič Andropov", "Ю́рий Влади́мирович Андро́пов", "Juri Andropov", "Jurij Andropov", "Yury Andropov", "Yury Vladimirovich Andropov", "Jurij Vladimirovic Andropov", "yuri v andropov"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Andropov", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:58.236340Z"}
{"question_id": "tqa_rc_validation_118", "question": "Who succeeded Brezhnev as Soviet premier?", "ground_truth": ["Andropov", "Yuri V. Andropov", "Yuri Andropov", "Yuriy Andropov", "Yuri Vladimirovich Andropov", "Andropou", "Jurij Vladimirovič Andropov", "Ю́рий Влади́мирович Андро́пов", "Juri Andropov", "Jurij Andropov", "Yury Andropov", "Yury Vladimirovich Andropov", "Jurij Vladimirovic Andropov", "yuri v andropov"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Yuri Andropov", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:27:59.437131Z"}
{"question_id": "tqa_rc_validation_118", "question": "Who succeeded Brezhnev as Soviet premier?", "ground_truth": ["Andropov", "Yuri V. Andropov", "Yuri Andropov", "Yuriy Andropov", "Yuri Vladimirovich Andropov", "Andropou", "Jurij Vladimirovič Andropov", "Ю́рий Влади́мирович Андро́пов", "Juri Andropov", "Jurij Andropov", "Yury Andropov", "Yury Vladimirovich Andropov", "Jurij Vladimirovic Andropov", "yuri v andropov"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Yuri Andropov", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:28:00.281351Z"}
{"question_id": "tqa_rc_validation_119", "question": "In the late 60s Owen Finlay MacLaren pioneered what useful item for parents of small chldren?", "ground_truth": ["Baby Buggy"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The umbrella-fold baby stroller (buggy)", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The folding umbrella stroller (buggy)", "The collapsible umbrella stroller", "The folding baby stroller (umbrella buggy)", "The umbrella-fold baby stroller (buggy)", "The folding umbrella stroller (buggy)", "The collapsible umbrella stroller", "The foldable baby stroller (umbrella buggy)", "The collapsible umbrella stroller (pushchair)", "The umbrella-fold baby stroller (buggy)", "The collapsible umbrella stroller (baby buggy)"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:28:18.513094Z"}
{"question_id": "tqa_rc_validation_119", "question": "In the late 60s Owen Finlay MacLaren pioneered what useful item for parents of small chldren?", "ground_truth": ["Baby Buggy"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Baby buggy (collapsible baby stroller)", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:28:20.254304Z"}
{"question_id": "tqa_rc_validation_119", "question": "In the late 60s Owen Finlay MacLaren pioneered what useful item for parents of small chldren?", "ground_truth": ["Baby Buggy"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Collapsible pushchair", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Collapsible pushchair", "Collapsible pushchair", "Collapsible pushchair", "Collapsible pushchair", "Collapsible pushchair", "Collapsible pushchair", "Collapsible pushchair", "Collapsible pushchair", "Collapsible pushchair", "Collapsible pushchair"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:28:30.617090Z"}
{"question_id": "tqa_rc_validation_119", "question": "In the late 60s Owen Finlay MacLaren pioneered what useful item for parents of small chldren?", "ground_truth": ["Baby Buggy"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The foldable umbrella stroller", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The lightweight foldable baby stroller", "The lightweight foldable baby stroller", "The lightweight foldable baby stroller", "The lightweight foldable baby stroller", "The foldable umbrella stroller", "The foldable umbrella stroller", "The foldable umbrella stroller", "The foldable umbrella stroller", "The foldable umbrella stroller", "The lightweight foldable baby stroller"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:28:53.871259Z"}
{"question_id": "tqa_rc_validation_119", "question": "In the late 60s Owen Finlay MacLaren pioneered what useful item for parents of small chldren?", "ground_truth": ["Baby Buggy"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The baby monitor", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The baby carrier or baby sling", "The Baby Flat Cot", "The car seat", "The playpen", "The baby carrier", "The safety gate", "Baby carriers", "The flat-pack baby bouncer", "The baby carrier", "The first plastic safety pin"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:29:10.342742Z"}
{"question_id": "tqa_rc_validation_120", "question": "In which city's shipyard was Solidarity set up?", "ground_truth": ["Gdansk, Poland", "Dànzica", "Baltic Sea/Gdanzk", "Danzig/Gdańsk", "Gdanzc", "Dantzick", "Gdunsk", "Gdanzk", "Gduńsk", "Gdańsk, Poland", "Gdanzisk", "Danzig (city)", "Gdañsk", "Gdaņska", "UN/LOCODE:PLGDN", "Gdank", "Gdanska", "Gdańska", "Gedanum", "Gdańk", "G'dansk", "Danzig", "Dantzic", "Nasz Stoleczny Gard Gduńsk", "Gdańsk", "Dantzik", "Gdansk", "Gdánsk", "Gdansk/Danzig", "Danzig, Poland", "Dantsic", "Duchy of Gdańsk", "gdansk poland", "un locode plgdn", "danzig city", "gdańsk poland", "g dansk", "baltic sea gdanzk", "danzig poland", "gdansk danzig", "danzig gdańsk"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Gdańsk", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:29:11.114646Z"}
{"question_id": "tqa_rc_validation_120", "question": "In which city's shipyard was Solidarity set up?", "ground_truth": ["Gdansk, Poland", "Dànzica", "Baltic Sea/Gdanzk", "Danzig/Gdańsk", "Gdanzc", "Dantzick", "Gdunsk", "Gdanzk", "Gduńsk", "Gdańsk, Poland", "Gdanzisk", "Danzig (city)", "Gdañsk", "Gdaņska", "UN/LOCODE:PLGDN", "Gdank", "Gdanska", "Gdańska", "Gedanum", "Gdańk", "G'dansk", "Danzig", "Dantzic", "Nasz Stoleczny Gard Gduńsk", "Gdańsk", "Dantzik", "Gdansk", "Gdánsk", "Gdansk/Danzig", "Danzig, Poland", "Dantsic", "Duchy of Gdańsk", "gdansk poland", "un locode plgdn", "danzig city", "gdańsk poland", "g dansk", "baltic sea gdanzk", "danzig poland", "gdansk danzig", "danzig gdańsk"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Gdańsk", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:29:12.991768Z"}
{"question_id": "tqa_rc_validation_120", "question": "In which city's shipyard was Solidarity set up?", "ground_truth": ["Gdansk, Poland", "Dànzica", "Baltic Sea/Gdanzk", "Danzig/Gdańsk", "Gdanzc", "Dantzick", "Gdunsk", "Gdanzk", "Gduńsk", "Gdańsk, Poland", "Gdanzisk", "Danzig (city)", "Gdañsk", "Gdaņska", "UN/LOCODE:PLGDN", "Gdank", "Gdanska", "Gdańska", "Gedanum", "Gdańk", "G'dansk", "Danzig", "Dantzic", "Nasz Stoleczny Gard Gduńsk", "Gdańsk", "Dantzik", "Gdansk", "Gdánsk", "Gdansk/Danzig", "Danzig, Poland", "Dantsic", "Duchy of Gdańsk", "gdansk poland", "un locode plgdn", "danzig city", "gdańsk poland", "g dansk", "baltic sea gdanzk", "danzig poland", "gdansk danzig", "danzig gdańsk"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Gdańsk", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:29:13.319593Z"}
{"question_id": "tqa_rc_validation_120", "question": "In which city's shipyard was Solidarity set up?", "ground_truth": ["Gdansk, Poland", "Dànzica", "Baltic Sea/Gdanzk", "Danzig/Gdańsk", "Gdanzc", "Dantzick", "Gdunsk", "Gdanzk", "Gduńsk", "Gdańsk, Poland", "Gdanzisk", "Danzig (city)", "Gdañsk", "Gdaņska", "UN/LOCODE:PLGDN", "Gdank", "Gdanska", "Gdańska", "Gedanum", "Gdańk", "G'dansk", "Danzig", "Dantzic", "Nasz Stoleczny Gard Gduńsk", "Gdańsk", "Dantzik", "Gdansk", "Gdánsk", "Gdansk/Danzig", "Danzig, Poland", "Dantsic", "Duchy of Gdańsk", "gdansk poland", "un locode plgdn", "danzig city", "gdańsk poland", "g dansk", "baltic sea gdanzk", "danzig poland", "gdansk danzig", "danzig gdańsk"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Gdańsk", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:29:14.447125Z"}
{"question_id": "tqa_rc_validation_120", "question": "In which city's shipyard was Solidarity set up?", "ground_truth": ["Gdansk, Poland", "Dànzica", "Baltic Sea/Gdanzk", "Danzig/Gdańsk", "Gdanzc", "Dantzick", "Gdunsk", "Gdanzk", "Gduńsk", "Gdańsk, Poland", "Gdanzisk", "Danzig (city)", "Gdañsk", "Gdaņska", "UN/LOCODE:PLGDN", "Gdank", "Gdanska", "Gdańska", "Gedanum", "Gdańk", "G'dansk", "Danzig", "Dantzic", "Nasz Stoleczny Gard Gduńsk", "Gdańsk", "Dantzik", "Gdansk", "Gdánsk", "Gdansk/Danzig", "Danzig, Poland", "Dantsic", "Duchy of Gdańsk", "gdansk poland", "un locode plgdn", "danzig city", "gdańsk poland", "g dansk", "baltic sea gdanzk", "danzig poland", "gdansk danzig", "danzig gdańsk"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Gdańsk", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:29:15.272692Z"}
{"question_id": "tqa_rc_validation_121", "question": "Which female singer was born on exactly the same day as impressionist Rich Little?", "ground_truth": ["Tina Turner", "Anna Bullock", "Tina Turner's", "Tina tuner", "Tinna turner", "Annie Mae Bullock", "Anna Mae Bullock", "tina turner s"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Dolly Parton", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Karen Carpenter", "Dusty Springfield", "Helen Reddy", "Cass Elliot", "Dusty Springfield", "Dusty Springfield", "Liza Minnelli", "Dusty Springfield", "Aretha Franklin", "Tina Turner"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:29:33.960857Z"}
{"question_id": "tqa_rc_validation_121", "question": "Which female singer was born on exactly the same day as impressionist Rich Little?", "ground_truth": ["Tina Turner", "Anna Bullock", "Tina Turner's", "Tina tuner", "Tinna turner", "Annie Mae Bullock", "Anna Mae Bullock", "tina turner s"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Brenda Lee", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Brenda Lee", "Brenda Lee", "Brenda Lee", "Brenda Lee", "Brenda Lee", "Brenda Lee", "Brenda Lee", "Brenda Lee", "Brenda Lee", "Brenda Lee"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:30:01.081665Z"}
{"question_id": "tqa_rc_validation_121", "question": "Which female singer was born on exactly the same day as impressionist Rich Little?", "ground_truth": ["Tina Turner", "Anna Bullock", "Tina Turner's", "Tina tuner", "Tinna turner", "Annie Mae Bullock", "Anna Mae Bullock", "tina turner s"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Dolly Parton", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Dolly Parton", "Barbra Streisand", "Dolly Parton", "Barbra Streisand", "Dolly Parton", "Dolly Parton", "Dolly Parton", "Barbra Streisand", "Dolly Parton", "Dolly Parton"], "equivalence_results": ["same", "different", "same", "different", "same", "same", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:30:13.645195Z"}
{"question_id": "tqa_rc_validation_121", "question": "Which female singer was born on exactly the same day as impressionist Rich Little?", "ground_truth": ["Tina Turner", "Anna Bullock", "Tina Turner's", "Tina tuner", "Tinna turner", "Annie Mae Bullock", "Anna Mae Bullock", "tina turner s"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Dolly Parton", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Dolly Parton", "Dolly Parton", "Dolly Parton", "Dolly Parton", "Dolly Parton", "Diana Ross", "Diana Ross", "Dolly Parton", "Barbra Streisand", "Diana Ross"], "equivalence_results": ["same", "same", "same", "same", "same", "different", "different", "same", "different", "different"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:30:38.757672Z"}
{"question_id": "tqa_rc_validation_121", "question": "Which female singer was born on exactly the same day as impressionist Rich Little?", "ground_truth": ["Tina Turner", "Anna Bullock", "Tina Turner's", "Tina tuner", "Tinna turner", "Annie Mae Bullock", "Anna Mae Bullock", "tina turner s"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "I couldn't find any information about a female singer born on the same day as Rich Little", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["I couldn't find any information about a female singer born on the same day as Rich Little", "I couldn't find any information on this specific question", "Gene Pitney's duet partner, but more famously known for her work as a solo artist,  Dusty Springfield was not the answer (she was born on April 16, 1939),  but rather the singer Gene Pitney sang", "I couldn't verify the information you are asking for", "I couldn't find a well-known answer to this question", "I couldn't find any information on a female singer born on the same day as impressionist Rich Little", "I couldn't find information about a female singer born on the same day as Rich Little", "I'm sorry, I am unable to verify the female singer born on the same day as impressionist Rich Little", "I could not verify the date of birth of Rich Little", "I couldn't find the information about the female singer and Rich Little being born on the same day"], "equivalence_results": ["same", "different", "different", "different", "different", "same", "same", "same", "different", "same"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:30:56.748796Z"}
{"question_id": "tqa_rc_validation_122", "question": "What is Harrison Ford's real name?", "ground_truth": ["Harrison Ford", "Harrison Ford (actor)", "Harison Ford", "Ford, Harrison", "ford harrison", "harrison ford actor"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Harrison Ford", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:30:57.604045Z"}
{"question_id": "tqa_rc_validation_122", "question": "What is Harrison Ford's real name?", "ground_truth": ["Harrison Ford", "Harrison Ford (actor)", "Harison Ford", "Ford, Harrison", "ford harrison", "harrison ford actor"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Harrison Ford", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:30:59.244167Z"}
{"question_id": "tqa_rc_validation_122", "question": "What is Harrison Ford's real name?", "ground_truth": ["Harrison Ford", "Harrison Ford (actor)", "Harison Ford", "Ford, Harrison", "ford harrison", "harrison ford actor"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Harrison Ford", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:30:59.464088Z"}
{"question_id": "tqa_rc_validation_122", "question": "What is Harrison Ford's real name?", "ground_truth": ["Harrison Ford", "Harrison Ford (actor)", "Harison Ford", "Ford, Harrison", "ford harrison", "harrison ford actor"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Harrison Ford", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:00.506024Z"}
{"question_id": "tqa_rc_validation_122", "question": "What is Harrison Ford's real name?", "ground_truth": ["Harrison Ford", "Harrison Ford (actor)", "Harison Ford", "Ford, Harrison", "ford harrison", "harrison ford actor"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "William Henry Harrison Ford", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:01.384812Z"}
{"question_id": "tqa_rc_validation_123", "question": "Who's home runs record did Mark McGwire break in the 1998 season?", "ground_truth": ["Roger Maris", "Roger Eugene Maras", "Roger marris", "Roger Eugene Maris", "Roger Maris Museum", "Roger Maras", "Roger Maris' 61 home run season", "roger maris 61 home run season"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Roger Maris", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:02.404618Z"}
{"question_id": "tqa_rc_validation_123", "question": "Who's home runs record did Mark McGwire break in the 1998 season?", "ground_truth": ["Roger Maris", "Roger Eugene Maras", "Roger marris", "Roger Eugene Maris", "Roger Maris Museum", "Roger Maras", "Roger Maris' 61 home run season", "roger maris 61 home run season"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Roger Maris", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:04.738569Z"}
{"question_id": "tqa_rc_validation_123", "question": "Who's home runs record did Mark McGwire break in the 1998 season?", "ground_truth": ["Roger Maris", "Roger Eugene Maras", "Roger marris", "Roger Eugene Maris", "Roger Maris Museum", "Roger Maras", "Roger Maris' 61 home run season", "roger maris 61 home run season"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Roger Maris", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:04.995872Z"}
{"question_id": "tqa_rc_validation_123", "question": "Who's home runs record did Mark McGwire break in the 1998 season?", "ground_truth": ["Roger Maris", "Roger Eugene Maras", "Roger marris", "Roger Eugene Maris", "Roger Maris Museum", "Roger Maras", "Roger Maris' 61 home run season", "roger maris 61 home run season"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Roger Maris", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:06.077111Z"}
{"question_id": "tqa_rc_validation_123", "question": "Who's home runs record did Mark McGwire break in the 1998 season?", "ground_truth": ["Roger Maris", "Roger Eugene Maras", "Roger marris", "Roger Eugene Maris", "Roger Maris Museum", "Roger Maras", "Roger Maris' 61 home run season", "roger maris 61 home run season"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Roger Maris' home run record", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:06.878188Z"}
{"question_id": "tqa_rc_validation_124", "question": "Who won baseball's first World Series of the 80s?", "ground_truth": ["Philadelphia Phillies", "The Phills", "Philadelphia Blue Jays", "Philadelphia Phyllis", "Philadelphia Phil", "Philadelphia Phillies (sports)", "Philadelphia Phillie", "Philadelphia Phillies roster", "List of Philadelphia Phillies captains", "Phillies", "Phightin' Phils", "Philadelphia Phillis", "The Phils", "The Phillies", "Phillies Roster", "Phils", "The Philadelphia Phillies", "Phillies Nation", "Filies", "Philadelphia Phillies/Quakers", "The Pillies", "Pillies", "philadelphia phillies sports", "phightin phils", "philadelphia phillies quakers", "phills"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Philadelphia Phillies won baseball’s first World Series of the 1980s (in 1980)", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Philadelphia Phillies won the first World Series of the 1980s (in 1980)", "The Philadelphia Phillies won the 1980 World Series", "The Philadelphia Phillies won the first World Series of the 1980s, in 1980", "The Philadelphia Phillies", "The Philadelphia Phillies won baseball’s first World Series of the 1980s (in 1980)", "The Philadelphia Phillies won the 1980 World Series", "The Philadelphia Phillies won baseball’s first World Series of the 1980s (in 1980)", "The Philadelphia Phillies won the 1980 World Series", "The Philadelphia Phillies won baseball’s first World Series of the 1980s (in 1980)", "The Philadelphia Phillies won the 1980 World Series"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:31:25.824449Z"}
{"question_id": "tqa_rc_validation_124", "question": "Who won baseball's first World Series of the 80s?", "ground_truth": ["Philadelphia Phillies", "The Phills", "Philadelphia Blue Jays", "Philadelphia Phyllis", "Philadelphia Phil", "Philadelphia Phillies (sports)", "Philadelphia Phillie", "Philadelphia Phillies roster", "List of Philadelphia Phillies captains", "Phillies", "Phightin' Phils", "Philadelphia Phillis", "The Phils", "The Phillies", "Phillies Roster", "Phils", "The Philadelphia Phillies", "Phillies Nation", "Filies", "Philadelphia Phillies/Quakers", "The Pillies", "Pillies", "philadelphia phillies sports", "phightin phils", "philadelphia phillies quakers", "phills"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The Philadelphia Phillies", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:27.570858Z"}
{"question_id": "tqa_rc_validation_124", "question": "Who won baseball's first World Series of the 80s?", "ground_truth": ["Philadelphia Phillies", "The Phills", "Philadelphia Blue Jays", "Philadelphia Phyllis", "Philadelphia Phil", "Philadelphia Phillies (sports)", "Philadelphia Phillie", "Philadelphia Phillies roster", "List of Philadelphia Phillies captains", "Phillies", "Phightin' Phils", "Philadelphia Phillis", "The Phils", "The Phillies", "Phillies Roster", "Phils", "The Philadelphia Phillies", "Phillies Nation", "Filies", "Philadelphia Phillies/Quakers", "The Pillies", "Pillies", "philadelphia phillies sports", "phightin phils", "philadelphia phillies quakers", "phills"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Philadelphia Phillies", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:27.784315Z"}
{"question_id": "tqa_rc_validation_124", "question": "Who won baseball's first World Series of the 80s?", "ground_truth": ["Philadelphia Phillies", "The Phills", "Philadelphia Blue Jays", "Philadelphia Phyllis", "Philadelphia Phil", "Philadelphia Phillies (sports)", "Philadelphia Phillie", "Philadelphia Phillies roster", "List of Philadelphia Phillies captains", "Phillies", "Phightin' Phils", "Philadelphia Phillis", "The Phils", "The Phillies", "Phillies Roster", "Phils", "The Philadelphia Phillies", "Phillies Nation", "Filies", "Philadelphia Phillies/Quakers", "The Pillies", "Pillies", "philadelphia phillies sports", "phightin phils", "philadelphia phillies quakers", "phills"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Philadelphia Phillies", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:28.973475Z"}
{"question_id": "tqa_rc_validation_124", "question": "Who won baseball's first World Series of the 80s?", "ground_truth": ["Philadelphia Phillies", "The Phills", "Philadelphia Blue Jays", "Philadelphia Phyllis", "Philadelphia Phil", "Philadelphia Phillies (sports)", "Philadelphia Phillie", "Philadelphia Phillies roster", "List of Philadelphia Phillies captains", "Phillies", "Phightin' Phils", "Philadelphia Phillis", "The Phils", "The Phillies", "Phillies Roster", "Phils", "The Philadelphia Phillies", "Phillies Nation", "Filies", "Philadelphia Phillies/Quakers", "The Pillies", "Pillies", "philadelphia phillies sports", "phightin phils", "philadelphia phillies quakers", "phills"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Philadelphia Phillies won baseball's first World Series of the 80s", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:31:30.001867Z"}
{"question_id": "tqa_rc_validation_125", "question": "What was Pete Sampras seeded when he won his first US Open?", "ground_truth": ["12", "twelve"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "12th seed", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:31:46.808947Z"}
{"question_id": "tqa_rc_validation_125", "question": "What was Pete Sampras seeded when he won his first US Open?", "ground_truth": ["12", "twelve"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "12th seed", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed", "12th seed"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:32:15.153528Z"}
{"question_id": "tqa_rc_validation_125", "question": "What was Pete Sampras seeded when he won his first US Open?", "ground_truth": ["12", "twelve"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "12th", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:32:15.473127Z"}
{"question_id": "tqa_rc_validation_125", "question": "What was Pete Sampras seeded when he won his first US Open?", "ground_truth": ["12", "twelve"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "12", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:32:16.717853Z"}
{"question_id": "tqa_rc_validation_125", "question": "What was Pete Sampras seeded when he won his first US Open?", "ground_truth": ["12", "twelve"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Unseeded", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Number 12", "Seeded 12th", "15", "15", "1st", "Unseeded", "13", "13", "16", "Third"], "equivalence_results": ["different", "different", "different", "different", "different", "same", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 1, "num_different": 9, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.1, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:32:33.745535Z"}
{"question_id": "tqa_rc_validation_126", "question": "\"Which boxer famously said,\"\" If I can't beat this bum take my name off the record books?\"\"\"", "ground_truth": ["Rocky Marciano", "Rocco Marchegiano", "The Brockton Blockbuster", "Brockton Bomber", "Marciano, Rocky", "Rocco francis marchegiano", "The Brockton Bomber", "Brockton Blockbuster", "marciano rocky"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Muhammad Ali", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:32:50.116708Z"}
{"question_id": "tqa_rc_validation_126", "question": "\"Which boxer famously said,\"\" If I can't beat this bum take my name off the record books?\"\"\"", "ground_truth": ["Rocky Marciano", "Rocco Marchegiano", "The Brockton Blockbuster", "Brockton Bomber", "Marciano, Rocky", "Rocco francis marchegiano", "The Brockton Bomber", "Brockton Blockbuster", "marciano rocky"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Joe Louis", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Joe Louis", "Joe Louis", "Joe Louis", "Joe Louis", "Joe Louis", "Joe Louis", "Joe Louis", "Joe Louis", "Joe Louis", "Joe Louis"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:33:16.186155Z"}
{"question_id": "tqa_rc_validation_126", "question": "\"Which boxer famously said,\"\" If I can't beat this bum take my name off the record books?\"\"\"", "ground_truth": ["Rocky Marciano", "Rocco Marchegiano", "The Brockton Blockbuster", "Brockton Bomber", "Marciano, Rocky", "Rocco francis marchegiano", "The Brockton Bomber", "Brockton Blockbuster", "marciano rocky"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Muhammad Ali", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:33:26.195234Z"}
{"question_id": "tqa_rc_validation_126", "question": "\"Which boxer famously said,\"\" If I can't beat this bum take my name off the record books?\"\"\"", "ground_truth": ["Rocky Marciano", "Rocco Marchegiano", "The Brockton Blockbuster", "Brockton Bomber", "Marciano, Rocky", "Rocco francis marchegiano", "The Brockton Bomber", "Brockton Blockbuster", "marciano rocky"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Muhammad Ali", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Joe Louis", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali", "Muhammad Ali"], "equivalence_results": ["same", "same", "same", "different", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:33:47.904361Z"}
{"question_id": "tqa_rc_validation_126", "question": "\"Which boxer famously said,\"\" If I can't beat this bum take my name off the record books?\"\"\"", "ground_truth": ["Rocky Marciano", "Rocco Marchegiano", "The Brockton Blockbuster", "Brockton Bomber", "Marciano, Rocky", "Rocco francis marchegiano", "The Brockton Bomber", "Brockton Blockbuster", "marciano rocky"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Rocky Marciano", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:33:48.685630Z"}
{"question_id": "tqa_rc_validation_127", "question": "Where did Jonathan Edwards set his 1995 triple jump world record?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Gothenburg, Sweden", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:33:49.659726Z"}
{"question_id": "tqa_rc_validation_127", "question": "Where did Jonathan Edwards set his 1995 triple jump world record?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Gothenburg, Sweden", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:33:50.750684Z"}
{"question_id": "tqa_rc_validation_127", "question": "Where did Jonathan Edwards set his 1995 triple jump world record?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Göteborg", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Göteborg", "Göteborg", "Göteborg", "Göteborg", "Göteborg", "Göteborg", "Göteborg", "Göteborg", "Göteborg", "Göteborg"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:34:03.428118Z"}
{"question_id": "tqa_rc_validation_127", "question": "Where did Jonathan Edwards set his 1995 triple jump world record?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Gothenburg", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Gothenburg", "Gothenburg", "Gothenburg", "Gothenburg", "Gothenburg", "Gothenburg", "Gothenburg", "Gothenburg", "Gothenburg", "Gothenburg"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:34:25.523914Z"}
{"question_id": "tqa_rc_validation_127", "question": "Where did Jonathan Edwards set his 1995 triple jump world record?", "ground_truth": ["Sweden", "Swedish sin", "Swea Region", "Sverige", "Swedish origin", "Schweden", "Kingdom of Sweden", "Etymology of Sweden", "Mainland Sweden", "Konungariket Sverige", "Ulf Bergman", "Swedish climate", "Climate of Sweden", "ISO 3166-1:SE", "Sveden", "Suecia", "Swedish realm", "Zweden", "iso 3166 1 se"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "I couldn't find any information on a Jonathan Edwards setting a 1995 triple jump world record", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["I'm not aware of any information about a person named Jonathan Edwards setting a triple jump world record in 1995", "I couldn't find any information about a Jonathan Edwards setting a 1995 triple jump world record", "I couldn't find any information about a person named Jonathan Edwards setting a triple jump world record in 1995", "I'm not aware of any information about a person named Jonathan Edwards setting a 1995 triple jump world record", "There is no record of a Jonathan Edwards setting a 1995 triple jump world record", "I'm not aware of the information regarding a Jonathan Edwards setting a 1995 triple jump world record", "I couldn't find any information on a Jonathan Edwards setting a 1995 triple jump world record", "I couldn't find any information on a person named Jonathan Edwards setting a triple jump world record in 1995", "I couldn't find any information on a Jonathan Edwards setting a 1995 triple jump world record", "I couldn't find any information on a Jonathan Edwards setting a 1995 world record"], "equivalence_results": ["same", "same", "same", "same", "different", "same", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:34:44.959667Z"}
{"question_id": "tqa_rc_validation_128", "question": "In baseball, where do the Orioles come from?", "ground_truth": ["Baltimore", "Ballermore, Murdaland", "Baltimore, Maryland, US", "B.More", "Bmore", "City of Baltimore, Maryland", "Baltimore (City)", "Baseball in Baltimore", "Ballamore, Murderland", "Mobtown", "Baltimore, US-MD", "Baltimore md", "Baltamore", "Baltimore (Md.)", "Ballermore, Murderland", "B-More", "Baltimore City", "Ballamore", "Baltimore, Md.", "Baltimore, Maryland", "Baltimore, Maryland, USA", "Baltimore, Maryland, United States", "Economy of Baltimore", "Baltimore, MD", "Charm City", "Balitmore", "Baltimore, United States", "Baltimore (MD)", "Ballermore", "Baltimore Department of Transportation", "Transportation in Baltimore", "B. More", "Baltimore City, MD", "Ballamore, Murdaland", "Baltimore, Maryland, United States of America", "Department of Transportation (Baltimore)", "Baltimore City, Maryland", "City of Baltimore", "Baltimore, USA", "Baltimore City Department of Transportation", "B More", "Baltimore DOT", "B'More", "Baltimore City Sheriff's Office", "UN/LOCODE:USBAL", "Baltimoreans", "Baltimore, MD, United States", "baltimore maryland usa", "baltimore maryland united states", "department of transportation baltimore", "city of baltimore maryland", "ballermore murderland", "baltimore city maryland", "baltimore united states", "baltimore maryland united states of america", "un locode usbal", "ballamore murderland", "baltimore city md", "baltimore maryland", "baltimore city sheriff s office", "baltimore usa", "baltimore maryland us", "baltimore md united states", "ballermore murdaland", "ballamore murdaland", "baltimore us md"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Baltimore, Maryland", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:45.851893Z"}
{"question_id": "tqa_rc_validation_128", "question": "In baseball, where do the Orioles come from?", "ground_truth": ["Baltimore", "Ballermore, Murdaland", "Baltimore, Maryland, US", "B.More", "Bmore", "City of Baltimore, Maryland", "Baltimore (City)", "Baseball in Baltimore", "Ballamore, Murderland", "Mobtown", "Baltimore, US-MD", "Baltimore md", "Baltamore", "Baltimore (Md.)", "Ballermore, Murderland", "B-More", "Baltimore City", "Ballamore", "Baltimore, Md.", "Baltimore, Maryland", "Baltimore, Maryland, USA", "Baltimore, Maryland, United States", "Economy of Baltimore", "Baltimore, MD", "Charm City", "Balitmore", "Baltimore, United States", "Baltimore (MD)", "Ballermore", "Baltimore Department of Transportation", "Transportation in Baltimore", "B. More", "Baltimore City, MD", "Ballamore, Murdaland", "Baltimore, Maryland, United States of America", "Department of Transportation (Baltimore)", "Baltimore City, Maryland", "City of Baltimore", "Baltimore, USA", "Baltimore City Department of Transportation", "B More", "Baltimore DOT", "B'More", "Baltimore City Sheriff's Office", "UN/LOCODE:USBAL", "Baltimoreans", "Baltimore, MD, United States", "baltimore maryland usa", "baltimore maryland united states", "department of transportation baltimore", "city of baltimore maryland", "ballermore murderland", "baltimore city maryland", "baltimore united states", "baltimore maryland united states of america", "un locode usbal", "ballamore murderland", "baltimore city md", "baltimore maryland", "baltimore city sheriff s office", "baltimore usa", "baltimore maryland us", "baltimore md united states", "ballermore murdaland", "ballamore murdaland", "baltimore us md"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Baltimore", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:47.904006Z"}
{"question_id": "tqa_rc_validation_128", "question": "In baseball, where do the Orioles come from?", "ground_truth": ["Baltimore", "Ballermore, Murdaland", "Baltimore, Maryland, US", "B.More", "Bmore", "City of Baltimore, Maryland", "Baltimore (City)", "Baseball in Baltimore", "Ballamore, Murderland", "Mobtown", "Baltimore, US-MD", "Baltimore md", "Baltamore", "Baltimore (Md.)", "Ballermore, Murderland", "B-More", "Baltimore City", "Ballamore", "Baltimore, Md.", "Baltimore, Maryland", "Baltimore, Maryland, USA", "Baltimore, Maryland, United States", "Economy of Baltimore", "Baltimore, MD", "Charm City", "Balitmore", "Baltimore, United States", "Baltimore (MD)", "Ballermore", "Baltimore Department of Transportation", "Transportation in Baltimore", "B. More", "Baltimore City, MD", "Ballamore, Murdaland", "Baltimore, Maryland, United States of America", "Department of Transportation (Baltimore)", "Baltimore City, Maryland", "City of Baltimore", "Baltimore, USA", "Baltimore City Department of Transportation", "B More", "Baltimore DOT", "B'More", "Baltimore City Sheriff's Office", "UN/LOCODE:USBAL", "Baltimoreans", "Baltimore, MD, United States", "baltimore maryland usa", "baltimore maryland united states", "department of transportation baltimore", "city of baltimore maryland", "ballermore murderland", "baltimore city maryland", "baltimore united states", "baltimore maryland united states of america", "un locode usbal", "ballamore murderland", "baltimore city md", "baltimore maryland", "baltimore city sheriff s office", "baltimore usa", "baltimore maryland us", "baltimore md united states", "ballermore murdaland", "ballamore murdaland", "baltimore us md"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Baltimore", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:48.108729Z"}
{"question_id": "tqa_rc_validation_128", "question": "In baseball, where do the Orioles come from?", "ground_truth": ["Baltimore", "Ballermore, Murdaland", "Baltimore, Maryland, US", "B.More", "Bmore", "City of Baltimore, Maryland", "Baltimore (City)", "Baseball in Baltimore", "Ballamore, Murderland", "Mobtown", "Baltimore, US-MD", "Baltimore md", "Baltamore", "Baltimore (Md.)", "Ballermore, Murderland", "B-More", "Baltimore City", "Ballamore", "Baltimore, Md.", "Baltimore, Maryland", "Baltimore, Maryland, USA", "Baltimore, Maryland, United States", "Economy of Baltimore", "Baltimore, MD", "Charm City", "Balitmore", "Baltimore, United States", "Baltimore (MD)", "Ballermore", "Baltimore Department of Transportation", "Transportation in Baltimore", "B. More", "Baltimore City, MD", "Ballamore, Murdaland", "Baltimore, Maryland, United States of America", "Department of Transportation (Baltimore)", "Baltimore City, Maryland", "City of Baltimore", "Baltimore, USA", "Baltimore City Department of Transportation", "B More", "Baltimore DOT", "B'More", "Baltimore City Sheriff's Office", "UN/LOCODE:USBAL", "Baltimoreans", "Baltimore, MD, United States", "baltimore maryland usa", "baltimore maryland united states", "department of transportation baltimore", "city of baltimore maryland", "ballermore murderland", "baltimore city maryland", "baltimore united states", "baltimore maryland united states of america", "un locode usbal", "ballamore murderland", "baltimore city md", "baltimore maryland", "baltimore city sheriff s office", "baltimore usa", "baltimore maryland us", "baltimore md united states", "ballermore murdaland", "ballamore murdaland", "baltimore us md"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Baltimore, Maryland", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:49.110524Z"}
{"question_id": "tqa_rc_validation_128", "question": "In baseball, where do the Orioles come from?", "ground_truth": ["Baltimore", "Ballermore, Murdaland", "Baltimore, Maryland, US", "B.More", "Bmore", "City of Baltimore, Maryland", "Baltimore (City)", "Baseball in Baltimore", "Ballamore, Murderland", "Mobtown", "Baltimore, US-MD", "Baltimore md", "Baltamore", "Baltimore (Md.)", "Ballermore, Murderland", "B-More", "Baltimore City", "Ballamore", "Baltimore, Md.", "Baltimore, Maryland", "Baltimore, Maryland, USA", "Baltimore, Maryland, United States", "Economy of Baltimore", "Baltimore, MD", "Charm City", "Balitmore", "Baltimore, United States", "Baltimore (MD)", "Ballermore", "Baltimore Department of Transportation", "Transportation in Baltimore", "B. More", "Baltimore City, MD", "Ballamore, Murdaland", "Baltimore, Maryland, United States of America", "Department of Transportation (Baltimore)", "Baltimore City, Maryland", "City of Baltimore", "Baltimore, USA", "Baltimore City Department of Transportation", "B More", "Baltimore DOT", "B'More", "Baltimore City Sheriff's Office", "UN/LOCODE:USBAL", "Baltimoreans", "Baltimore, MD, United States", "baltimore maryland usa", "baltimore maryland united states", "department of transportation baltimore", "city of baltimore maryland", "ballermore murderland", "baltimore city maryland", "baltimore united states", "baltimore maryland united states of america", "un locode usbal", "ballamore murderland", "baltimore city md", "baltimore maryland", "baltimore city sheriff s office", "baltimore usa", "baltimore maryland us", "baltimore md united states", "ballermore murdaland", "ballamore murdaland", "baltimore us md"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Baltimore, Maryland", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:50.029958Z"}
{"question_id": "tqa_rc_validation_129", "question": "The Naismith Award is presented in which sport?", "ground_truth": ["Basket ball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:50.757193Z"}
{"question_id": "tqa_rc_validation_129", "question": "The Naismith Award is presented in which sport?", "ground_truth": ["Basket ball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:52.254689Z"}
{"question_id": "tqa_rc_validation_129", "question": "The Naismith Award is presented in which sport?", "ground_truth": ["Basket ball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:52.405413Z"}
{"question_id": "tqa_rc_validation_129", "question": "The Naismith Award is presented in which sport?", "ground_truth": ["Basket ball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:53.530413Z"}
{"question_id": "tqa_rc_validation_129", "question": "The Naismith Award is presented in which sport?", "ground_truth": ["Basket ball", "Basketball", "Basketball gear", "Bball", "Boy's Basketball", "B Ball", "Shoot hoops", "Basketball parity worldwide", "Men's Basketball", "High school basketball", "Basketball Worldwide", "Basketball club", "B-ball", "Basket-ball", "Basketball team", "🏀", "Basketball rim", "Basketballer", "Rim (basketball)", "Basketball net", "Baksetball", "Basketball player", "Women's hoops", "Baketball", "Unicycle basketball", "men s basketball", "boy s basketball", "rim basketball", "women s hoops"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Basketball", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:34:54.295959Z"}
{"question_id": "tqa_rc_validation_130", "question": "Which cartoon and film character is the nickname of super athlete Michael Johnson?", "ground_truth": ["Superman", "Stalmannen", "Supaaman", "Jordan Elliot", "Superman (fictional character)", "Superman Secret Files", "Kal-El", "Super-Man", "Codename: Patriot", "The Metropolis Marvel", "Big blue boy scout", "Superman (Clark Kent)", "Action Ace", "Kal el", "Super man", "Superman Costume", "Able to leap tall buildings in a single bound", "The Superman", "Supertman", "Stålmannen", "Superman (comics)", "Supes", "Superman: Secret Files", "Metropolis Marvel", "Superman (DC Comics)", "The Action Ace", "Ubermensch!", "Big Blue Cheese", "Faster than a speeding bullet", "Übermensch!", "Superman (Kal-El)", "More powerful than a locomotive", "Man of tomorrow", "Supraman", "Superman/Clark Kent", "Kirk Brent", "Superman (character)", "Gojjum", "superman clark kent", "übermensch", "more powerful than locomotive", "codename patriot", "superman comics", "faster than speeding bullet", "superman fictional character", "superman dc comics", "ubermensch", "superman character", "superman kal el", "able to leap tall buildings in single bound"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Road Runner", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Road Runner", "Road Runner", "Road Runner", "The Road Runner", "Road Runner", "Road Runner", "Road Runner", "Road Runner", "Road Runner", "Road Runner"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:35:11.672913Z"}
{"question_id": "tqa_rc_validation_5", "question": "Rita Coolidge sang the title song for which Bond film?", "ground_truth": ["Octopussy", "Kamal kahn", "List of Bond girls in Octopussy", "Magda (James Bond)", "List of James Bond allies in Octopussy", "Vijay (James Bond)", "Bond 13", "Octopussy (character)", "Penelope Smallbone", "General Orlov", "Kamal Khan", "Octopussy (film)", "List of James Bond villains in Octopussy", "Jim Fanning (James Bond)", "magda james bond", "vijay james bond", "jim fanning james bond", "octopussy character", "octopussy film"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "You Only Live Twice", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["You Only Live Twice", "\"Falling in Love with You\" is not it, the correct answer is  \"You're No One Till Someone Loves You\" is not it", "You Only Live Twice", "You Only Live Twice", "You Only Live Twice", "You Only Live Twice", "You Only Live Twice", "You Only Live Twice", "You Only Live Twice", "\"You and I\" is not the title song, the correct title song sung by Rita Coolidge is for the Bond film \"You Only Live Twice\" no"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:35:27.593559Z"}
{"question_id": "tqa_rc_validation_5", "question": "Rita Coolidge sang the title song for which Bond film?", "ground_truth": ["Octopussy", "Kamal kahn", "List of Bond girls in Octopussy", "Magda (James Bond)", "List of James Bond allies in Octopussy", "Vijay (James Bond)", "Bond 13", "Octopussy (character)", "Penelope Smallbone", "General Orlov", "Kamal Khan", "Octopussy (film)", "List of James Bond villains in Octopussy", "Jim Fanning (James Bond)", "magda james bond", "vijay james bond", "jim fanning james bond", "octopussy character", "octopussy film"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Octopussy", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:35:29.225085Z"}
{"question_id": "tqa_rc_validation_130", "question": "Which cartoon and film character is the nickname of super athlete Michael Johnson?", "ground_truth": ["Superman", "Stalmannen", "Supaaman", "Jordan Elliot", "Superman (fictional character)", "Superman Secret Files", "Kal-El", "Super-Man", "Codename: Patriot", "The Metropolis Marvel", "Big blue boy scout", "Superman (Clark Kent)", "Action Ace", "Kal el", "Super man", "Superman Costume", "Able to leap tall buildings in a single bound", "The Superman", "Supertman", "Stålmannen", "Superman (comics)", "Supes", "Superman: Secret Files", "Metropolis Marvel", "Superman (DC Comics)", "The Action Ace", "Ubermensch!", "Big Blue Cheese", "Faster than a speeding bullet", "Übermensch!", "Superman (Kal-El)", "More powerful than a locomotive", "Man of tomorrow", "Supraman", "Superman/Clark Kent", "Kirk Brent", "Superman (character)", "Gojjum", "superman clark kent", "übermensch", "more powerful than locomotive", "codename patriot", "superman comics", "faster than speeding bullet", "superman fictional character", "superman dc comics", "ubermensch", "superman character", "superman kal el", "able to leap tall buildings in single bound"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Road Runner", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Road Runner", "Road Runner", "Road Runner", "Road Runner", "Road Runner", "Road Runner", "Road Runner", "Road Runner", "Road Runner", "Road Runner"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:35:36.675894Z"}
{"question_id": "tqa_rc_validation_130", "question": "Which cartoon and film character is the nickname of super athlete Michael Johnson?", "ground_truth": ["Superman", "Stalmannen", "Supaaman", "Jordan Elliot", "Superman (fictional character)", "Superman Secret Files", "Kal-El", "Super-Man", "Codename: Patriot", "The Metropolis Marvel", "Big blue boy scout", "Superman (Clark Kent)", "Action Ace", "Kal el", "Super man", "Superman Costume", "Able to leap tall buildings in a single bound", "The Superman", "Supertman", "Stålmannen", "Superman (comics)", "Supes", "Superman: Secret Files", "Metropolis Marvel", "Superman (DC Comics)", "The Action Ace", "Ubermensch!", "Big Blue Cheese", "Faster than a speeding bullet", "Übermensch!", "Superman (Kal-El)", "More powerful than a locomotive", "Man of tomorrow", "Supraman", "Superman/Clark Kent", "Kirk Brent", "Superman (character)", "Gojjum", "superman clark kent", "übermensch", "more powerful than locomotive", "codename patriot", "superman comics", "faster than speeding bullet", "superman fictional character", "superman dc comics", "ubermensch", "superman character", "superman kal el", "able to leap tall buildings in single bound"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Manster", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Manster", "The Manster", "The Manster", "The Man with the Golden Shoes, but more commonly known as  \"The Real Tarzan\" or simply \"Tarzan\"", "The Manster", "The Manster", "The Manster", "The Man with the Golden Shoes", "The Manster", "The Manster"], "equivalence_results": ["same", "same", "same", "different", "same", "same", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:35:47.250180Z"}
{"question_id": "tqa_rc_validation_130", "question": "Which cartoon and film character is the nickname of super athlete Michael Johnson?", "ground_truth": ["Superman", "Stalmannen", "Supaaman", "Jordan Elliot", "Superman (fictional character)", "Superman Secret Files", "Kal-El", "Super-Man", "Codename: Patriot", "The Metropolis Marvel", "Big blue boy scout", "Superman (Clark Kent)", "Action Ace", "Kal el", "Super man", "Superman Costume", "Able to leap tall buildings in a single bound", "The Superman", "Supertman", "Stålmannen", "Superman (comics)", "Supes", "Superman: Secret Files", "Metropolis Marvel", "Superman (DC Comics)", "The Action Ace", "Ubermensch!", "Big Blue Cheese", "Faster than a speeding bullet", "Übermensch!", "Superman (Kal-El)", "More powerful than a locomotive", "Man of tomorrow", "Supraman", "Superman/Clark Kent", "Kirk Brent", "Superman (character)", "Gojjum", "superman clark kent", "übermensch", "more powerful than locomotive", "codename patriot", "superman comics", "faster than speeding bullet", "superman fictional character", "superman dc comics", "ubermensch", "superman character", "superman kal el", "able to leap tall buildings in single bound"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The Duck", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Duck", "The Flash", "The Duck", "The Duck", "The Duck", "The Duck", "The Duck", "The Duck", "The Duck", "The Duck"], "equivalence_results": ["same", "different", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:36:08.181317Z"}
{"question_id": "tqa_rc_validation_130", "question": "Which cartoon and film character is the nickname of super athlete Michael Johnson?", "ground_truth": ["Superman", "Stalmannen", "Supaaman", "Jordan Elliot", "Superman (fictional character)", "Superman Secret Files", "Kal-El", "Super-Man", "Codename: Patriot", "The Metropolis Marvel", "Big blue boy scout", "Superman (Clark Kent)", "Action Ace", "Kal el", "Super man", "Superman Costume", "Able to leap tall buildings in a single bound", "The Superman", "Supertman", "Stålmannen", "Superman (comics)", "Supes", "Superman: Secret Files", "Metropolis Marvel", "Superman (DC Comics)", "The Action Ace", "Ubermensch!", "Big Blue Cheese", "Faster than a speeding bullet", "Übermensch!", "Superman (Kal-El)", "More powerful than a locomotive", "Man of tomorrow", "Supraman", "Superman/Clark Kent", "Kirk Brent", "Superman (character)", "Gojjum", "superman clark kent", "übermensch", "more powerful than locomotive", "codename patriot", "superman comics", "faster than speeding bullet", "superman fictional character", "superman dc comics", "ubermensch", "superman character", "superman kal el", "able to leap tall buildings in single bound"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Flash", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Flash", "Sprint", "The Flash", "The Flash", "Flash", "The Flash", "\"Gold\" was one nickname for Michael Johnson", "Sprint", "Flash", "The Flash"], "equivalence_results": ["same", "different", "same", "same", "same", "same", "different", "different", "same", "same"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:36:24.182645Z"}
{"question_id": "tqa_rc_validation_131", "question": "For which team did Babe Ruth blast his last Major League home run?", "ground_truth": ["Boston Braves", "Boston Braves (disambiguation)", "boston braves disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Boston Braves", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:25.106007Z"}
{"question_id": "tqa_rc_validation_131", "question": "For which team did Babe Ruth blast his last Major League home run?", "ground_truth": ["Boston Braves", "Boston Braves (disambiguation)", "boston braves disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Boston Braves", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:26.898441Z"}
{"question_id": "tqa_rc_validation_131", "question": "For which team did Babe Ruth blast his last Major League home run?", "ground_truth": ["Boston Braves", "Boston Braves (disambiguation)", "boston braves disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Boston Braves", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:27.305013Z"}
{"question_id": "tqa_rc_validation_131", "question": "For which team did Babe Ruth blast his last Major League home run?", "ground_truth": ["Boston Braves", "Boston Braves (disambiguation)", "boston braves disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Boston Braves", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:28.560980Z"}
{"question_id": "tqa_rc_validation_131", "question": "For which team did Babe Ruth blast his last Major League home run?", "ground_truth": ["Boston Braves", "Boston Braves (disambiguation)", "boston braves disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Boston Braves", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:29.510173Z"}
{"question_id": "tqa_rc_validation_132", "question": "What was Warren Beatty's first movie?", "ground_truth": ["Splendor in the Grass", "splendor in grass"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Splendor in the Grass", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:30.381459Z"}
{"question_id": "tqa_rc_validation_132", "question": "What was Warren Beatty's first movie?", "ground_truth": ["Splendor in the Grass", "splendor in grass"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Splendor in the Grass", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:32.109469Z"}
{"question_id": "tqa_rc_validation_132", "question": "What was Warren Beatty's first movie?", "ground_truth": ["Splendor in the Grass", "splendor in grass"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Splendor in the Grass", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:32.317571Z"}
{"question_id": "tqa_rc_validation_132", "question": "What was Warren Beatty's first movie?", "ground_truth": ["Splendor in the Grass", "splendor in grass"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Splendor in the Grass", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:33.638154Z"}
{"question_id": "tqa_rc_validation_132", "question": "What was Warren Beatty's first movie?", "ground_truth": ["Splendor in the Grass", "splendor in grass"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Splendor in the Grass", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:34.458610Z"}
{"question_id": "tqa_rc_validation_133", "question": "Which future Hollywood star got her break as Wonder Girl, Wonder Woman's sister Drusilla?", "ground_truth": ["Debra Winger", "Mary Debra Winger", "Deborah Winger"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Dawn Lyn", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Dawn Lyn", "Jayne Mansfield", "Ellen Burstyn", "Dawn Lyn", "Donna Mills", "Debra Winger", "Dawn Lyn", "Elliot Page", "Ellen Burstyn", "Dawn Lyn"], "equivalence_results": ["same", "different", "different", "same", "different", "different", "same", "different", "different", "same"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:36:52.379231Z"}
{"question_id": "tqa_rc_validation_133", "question": "Which future Hollywood star got her break as Wonder Girl, Wonder Woman's sister Drusilla?", "ground_truth": ["Debra Winger", "Mary Debra Winger", "Deborah Winger"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Debra Winger", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:54.077500Z"}
{"question_id": "tqa_rc_validation_133", "question": "Which future Hollywood star got her break as Wonder Girl, Wonder Woman's sister Drusilla?", "ground_truth": ["Debra Winger", "Mary Debra Winger", "Deborah Winger"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Debra Winger", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:36:54.342997Z"}
{"question_id": "tqa_rc_validation_133", "question": "Which future Hollywood star got her break as Wonder Girl, Wonder Woman's sister Drusilla?", "ground_truth": ["Debra Winger", "Mary Debra Winger", "Deborah Winger"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Lynda Carter", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Lynda Carter", "Lynda Carter", "Lynda Carter", "Lynda Carter", "Lynda Carter", "Lynda Carter", "Lynda Carter", "Lynda Carter", "Lynda Carter", "Lynda Carter"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:37:14.953866Z"}
{"question_id": "tqa_rc_validation_133", "question": "Which future Hollywood star got her break as Wonder Girl, Wonder Woman's sister Drusilla?", "ground_truth": ["Debra Winger", "Mary Debra Winger", "Deborah Winger"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Debra Messing", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Lynda Carter", "Debra Messing", "Lynda Carter", "Debra Messing", "Lynda Carter", "Debra Winger", "Debra Messing", "Debra Messing", "Debra Messing", "Lynda Carter"], "equivalence_results": ["different", "same", "different", "same", "different", "different", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:37:31.328046Z"}
{"question_id": "tqa_rc_validation_134", "question": "Mickey Braddock in the 50s series Circus Boy found fame with which surname in which pop band?", "ground_truth": ["Mickey Dolenz (The Monkees)", "mickey dolenz monkees"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Smith in The Tremeloes", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Smith in The Tremeloes", "Smith in The Tremeloes", "Braddock — The Vipers", "Carter — The Foundations", "Smith in The Smiths", "Dolenz — The Monkees", "Bobby Vee in The Crickets", "Smith in The Smiths", "Smith in The Tremeloes", "Smith in The Smiths"], "equivalence_results": ["same", "same", "different", "different", "different", "different", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:37:51.010455Z"}
{"question_id": "tqa_rc_validation_134", "question": "Mickey Braddock in the 50s series Circus Boy found fame with which surname in which pop band?", "ground_truth": ["Mickey Dolenz (The Monkees)", "mickey dolenz monkees"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Mickey Braddock was actually Micky Dolenz, who found fame as a member of **The Monkees**", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Mickey Braddock was actually Micky Dolenz, who found fame as a member of **The Monkees** with the surname **Dolenz**", "Mickey Braddock was actually Micky Dolenz, who found fame as a member of **The Monkees**", "Mickey Braddock was actually Micky Dolenz, who found fame as a member of **The Monkees**", "Mickey Braddock was actually Micky Dolenz, who found fame as a member of **The Monkees** with the surname **Dolenz**", "Mickey Braddock was actually Micky Dolenz, who found fame as a member of **The Monkees**", "Mickey Braddock was actually Micky Dolenz, who found fame as a member of **The Monkees** with the surname **Dolenz**", "Mickey Braddock was actually **Micky Dolenz**, who found fame as a member of **The Monkees**", "Mickey Braddock was actually Micky Dolenz, who found fame as a member of **The Monkees**", "Mickey Braddock, whose real name was Micky Dolenz, found fame as a member of **The Monkees** with the surname **Dolenz**", "Mickey Braddock was actually Micky Dolenz, who found fame as a member of **The Monkees**"], "equivalence_results": ["different", "same", "same", "different", "same", "different", "same", "same", "different", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:38:23.630376Z"}
{"question_id": "tqa_rc_validation_134", "question": "Mickey Braddock in the 50s series Circus Boy found fame with which surname in which pop band?", "ground_truth": ["Mickey Dolenz (The Monkees)", "mickey dolenz monkees"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Micky Dolenz in The Monkees", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Micky Dolenz in The Monkees", "Micky Dolenz in The Monkees", "Micky Dolenz in The Monkees", "Micky Dolenz in The Monkees", "Micky Dolenz in The Monkees", "Micky Dolenz in The Monkees", "Korne, in the pop band New Kids on the Block, later known as NKOTB", "Micky Dolenz in The Monkees", "Micky Dolenz in The Monkees", "Micky Dolenz in The Monkees"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "different", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:38:34.631227Z"}
{"question_id": "tqa_rc_validation_134", "question": "Mickey Braddock in the 50s series Circus Boy found fame with which surname in which pop band?", "ground_truth": ["Mickey Dolenz (The Monkees)", "mickey dolenz monkees"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Dolenz", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:38:35.844304Z"}
{"question_id": "tqa_rc_validation_134", "question": "Mickey Braddock in the 50s series Circus Boy found fame with which surname in which pop band?", "ground_truth": ["Mickey Dolenz (The Monkees)", "mickey dolenz monkees"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Animals", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Micky Braddock in the 50s series Circus Boy found fame with the surname Moon in the pop band Moody Blues", "Davies", "The Animals", "Herman", "The Shadows", "The Scaffold", "The Animals", "The Animals", "The Animals", "Harrison"], "equivalence_results": ["different", "different", "same", "different", "different", "different", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:38:55.528570Z"}
{"question_id": "tqa_rc_validation_135", "question": "Which war veteran was Director of News & Special Events for ABC before find fame as a TV cop?", "ground_truth": ["Tom Selleck", "Thomas William %22Tom%22 Selleck", "Thomas Selleck", "Thomas William Selleck", "thomas william 22tom 22 selleck"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Jack Webb", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Jack Webb", "Robert Taylor", "Efrem Zimbalist Jr", "Jack Webb", "Jack Webb", "Jack Webb", "Jack Webb", "Jack Webb", "Jack Webb", "Jack Webb"], "equivalence_results": ["same", "different", "different", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:39:13.261626Z"}
{"question_id": "tqa_rc_validation_135", "question": "Which war veteran was Director of News & Special Events for ABC before find fame as a TV cop?", "ground_truth": ["Tom Selleck", "Thomas William %22Tom%22 Selleck", "Thomas Selleck", "Thomas William Selleck", "thomas william 22tom 22 selleck"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Dennis Franz", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Dennis Franz", "Dennis Franz", "Dennis Franz", "Dennis Franz", "Dennis Franz", "Dennis Franz", "Dennis Franz", "Dennis Franz", "Dennis Franz", "Dennis Franz"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:39:52.679175Z"}
{"question_id": "tqa_rc_validation_135", "question": "Which war veteran was Director of News & Special Events for ABC before find fame as a TV cop?", "ground_truth": ["Tom Selleck", "Thomas William %22Tom%22 Selleck", "Thomas Selleck", "Thomas William Selleck", "thomas william 22tom 22 selleck"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Dennis Franz", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Roger Moore", "John Stalker is not correct, the answer is  Don Adams is not correct either, the correct answer is  Gene Reynolds is", "Dennis Hopper was not a war veteran who was Director of News & Special Events for ABC before finding fame as a TV cop, however,  The character \"S", "Dennis Franz", "Don 'Sonny' Croft, no", "John Stalker, but more likely the answer is: Roger Moore's predecessor in the role is not relevant, The answer is:", "Dennis Franz", "John Stamos is not correct, the correct answer is: John", "Dennis Franz", "John Klintworth doesn't fit, the correct answer is: Roger Moore doesn't fit"], "equivalence_results": ["different", "different", "different", "same", "different", "different", "same", "different", "same", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:40:03.831225Z"}
{"question_id": "tqa_rc_validation_135", "question": "Which war veteran was Director of News & Special Events for ABC before find fame as a TV cop?", "ground_truth": ["Tom Selleck", "Thomas William %22Tom%22 Selleck", "Thomas Selleck", "Thomas William Selleck", "thomas william 22tom 22 selleck"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Jack Lord", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Jack Lord", "Jack Lord", "Jack Lord", "Jack Lord", "Jack Lord", "Jack Lord", "Jack Lord", "Jack Lord", "Jack Lord", "Jack Lord"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:40:25.658970Z"}
{"question_id": "tqa_rc_validation_135", "question": "Which war veteran was Director of News & Special Events for ABC before find fame as a TV cop?", "ground_truth": ["Tom Selleck", "Thomas William %22Tom%22 Selleck", "Thomas Selleck", "Thomas William Selleck", "thomas william 22tom 22 selleck"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "O", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Richard Dawson", "Richard Crenna", "Jack Webb", "O", "Jack Webb", "O", "Lorne Greene", "O", "Lorne Greene", "O"], "equivalence_results": ["different", "different", "different", "same", "different", "same", "different", "same", "different", "same"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:40:42.378183Z"}
{"question_id": "tqa_rc_validation_136", "question": "What US sitcom was the first exported to Britain?", "ground_truth": ["Amos 'N' Andy", "Amos n Andy", "Amos And Andy", "Amos & Andy", "George %22Kingfish%22 Stevens", "Brazilian Brass Mines", "Amos ‘n’ Andy", "Amos 'n Andy", "Amos N' Andy", "The Amos 'n Andy Show", "Amos 'n Andy Show", "Amos 'n' Andy Show", "amos andy", "george 22kingfish 22 stevens", "amos n andy show"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "I Love Lucy", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:41:05.621209Z"}
{"question_id": "tqa_rc_validation_136", "question": "What US sitcom was the first exported to Britain?", "ground_truth": ["Amos 'N' Andy", "Amos n Andy", "Amos And Andy", "Amos & Andy", "George %22Kingfish%22 Stevens", "Brazilian Brass Mines", "Amos ‘n’ Andy", "Amos 'n Andy", "Amos N' Andy", "The Amos 'n Andy Show", "Amos 'n Andy Show", "Amos 'n' Andy Show", "amos andy", "george 22kingfish 22 stevens", "amos n andy show"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Fresh Prince of Bel-Air", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Fresh Prince of Bel-Air", "Fresh Prince of Bel-Air", "Fresh Prince of Bel-Air", "Fresh Prince of Bel-Air", "Fresh Prince of Bel-Air", "Fresh Prince of Bel-Air", "Fresh Prince of Bel-Air", "Fresh Prince of Bel-Air", "Fresh Prince of Bel-Air", "Fresh Prince of Bel-Air"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:41:40.231022Z"}
{"question_id": "tqa_rc_validation_136", "question": "What US sitcom was the first exported to Britain?", "ground_truth": ["Amos 'N' Andy", "Amos n Andy", "Amos And Andy", "Amos & Andy", "George %22Kingfish%22 Stevens", "Brazilian Brass Mines", "Amos ‘n’ Andy", "Amos 'n Andy", "Amos N' Andy", "The Amos 'n Andy Show", "Amos 'n Andy Show", "Amos 'n' Andy Show", "amos andy", "george 22kingfish 22 stevens", "amos n andy show"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "I Love Lucy", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:41:50.697199Z"}
{"question_id": "tqa_rc_validation_136", "question": "What US sitcom was the first exported to Britain?", "ground_truth": ["Amos 'N' Andy", "Amos n Andy", "Amos And Andy", "Amos & Andy", "George %22Kingfish%22 Stevens", "Brazilian Brass Mines", "Amos ‘n’ Andy", "Amos 'n Andy", "Amos N' Andy", "The Amos 'n Andy Show", "Amos 'n Andy Show", "Amos 'n' Andy Show", "amos andy", "george 22kingfish 22 stevens", "amos n andy show"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "I Love Lucy", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:42:12.552960Z"}
{"question_id": "tqa_rc_validation_136", "question": "What US sitcom was the first exported to Britain?", "ground_truth": ["Amos 'N' Andy", "Amos n Andy", "Amos And Andy", "Amos & Andy", "George %22Kingfish%22 Stevens", "Brazilian Brass Mines", "Amos ‘n’ Andy", "Amos 'n Andy", "Amos N' Andy", "The Amos 'n Andy Show", "Amos 'n Andy Show", "Amos 'n' Andy Show", "amos andy", "george 22kingfish 22 stevens", "amos n andy show"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "I Love Lucy", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["I Love Lucy", "The Mary Tyler Moore Show", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "I Love Lucy", "'Topper' is incorrect too"], "equivalence_results": ["same", "different", "same", "same", "same", "same", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:42:28.971935Z"}
{"question_id": "tqa_rc_validation_137", "question": "In Hanna and Barbera's TV cartoons base on The Addams Family who was the voice of Gomez?", "ground_truth": ["John Astin"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "J", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["J", "J", "J", "J", "J", "J", "Jules Munshin", "Julián Díaz", "J", "J"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "unclear", "unclear", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 0, "num_unclear": 2, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:42:47.136330Z"}
{"question_id": "tqa_rc_validation_137", "question": "In Hanna and Barbera's TV cartoons base on The Addams Family who was the voice of Gomez?", "ground_truth": ["John Astin"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "John Astin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:42:48.757138Z"}
{"question_id": "tqa_rc_validation_137", "question": "In Hanna and Barbera's TV cartoons base on The Addams Family who was the voice of Gomez?", "ground_truth": ["John Astin"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Lennie Weinrib", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Lennie Weinrib", "Lennie Weinrib", "Lennie Weinrib", "Lennie Weinrib", "Lennie Weinrib", "Lennie Weinrib", "Lennie Weinrib", "Lennie Weinrib", "Lennie Weinrib", "Lennie Weinrib"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:42:58.965632Z"}
{"question_id": "tqa_rc_validation_137", "question": "In Hanna and Barbera's TV cartoons base on The Addams Family who was the voice of Gomez?", "ground_truth": ["John Astin"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "John Astin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:43:00.214526Z"}
{"question_id": "tqa_rc_validation_137", "question": "In Hanna and Barbera's TV cartoons base on The Addams Family who was the voice of Gomez?", "ground_truth": ["John Astin"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "John Astin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:43:01.074979Z"}
{"question_id": "tqa_rc_validation_138", "question": "Who was the only female victim to be killed off in the opening credit sequence in Police Squad?", "ground_truth": ["Florence Henderson", "Florence Agnes Henderson", "Florence Hendersen", "Flo Henderson"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Florence Henderson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:43:01.908671Z"}
{"question_id": "tqa_rc_validation_138", "question": "Who was the only female victim to be killed off in the opening credit sequence in Police Squad?", "ground_truth": ["Florence Henderson", "Florence Agnes Henderson", "Florence Hendersen", "Flo Henderson"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Lana Turner", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Lorna Patterson", "Lorna Patterson", "Lana Turner", "Lorna Patterson", "Lorna Patterson", "Lorna Patterson", "Lana Turner", "Lorna Patterson", "Lorna Patterson", "Lorna Patterson"], "equivalence_results": ["different", "different", "same", "different", "different", "different", "same", "different", "different", "different"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:43:28.105744Z"}
{"question_id": "tqa_rc_validation_138", "question": "Who was the only female victim to be killed off in the opening credit sequence in Police Squad?", "ground_truth": ["Florence Henderson", "Florence Agnes Henderson", "Florence Hendersen", "Flo Henderson"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Jane Spencer", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Granny Smith", "Jane Spencer", "Norah", "Norah Guinness", "Jane Spencer", "Jane Spencer", "Jane Spencer", "Jane Spencer", "Norah Montague", "Norberg"], "equivalence_results": ["different", "same", "different", "different", "same", "same", "same", "same", "different", "different"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:43:38.783784Z"}
{"question_id": "tqa_rc_validation_138", "question": "Who was the only female victim to be killed off in the opening credit sequence in Police Squad?", "ground_truth": ["Florence Henderson", "Florence Agnes Henderson", "Florence Hendersen", "Flo Henderson"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Lorna Gray", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Lorna Zubitch", "Lorna Patterson", "Lorna Patterson", "Lorna Gray", "Lorna Gray", "Lorna Doone", "Lorna Gray", "Lorna Patterson", "Lorna Gray", "Lorna Gray"], "equivalence_results": ["different", "different", "different", "same", "same", "different", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:44:01.095680Z"}
{"question_id": "tqa_rc_validation_138", "question": "Who was the only female victim to be killed off in the opening credit sequence in Police Squad?", "ground_truth": ["Florence Henderson", "Florence Agnes Henderson", "Florence Hendersen", "Flo Henderson"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Sylvia Castillo", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Anita Morris", "Carol Anne Keane", "Suzanne", "Marion Middleton", "Amy O'Neill", "Carol Anne Frazier", "Carol Anne Keaton", "Peggy Lipton", "Carol Kaye", "Peggy Knudsen"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:44:19.350779Z"}
{"question_id": "tqa_rc_validation_139", "question": "Which US president won the Nobel Peace Prize in 1920?", "ground_truth": ["Woodrow Wilson", "Thomas W. Wilson", "President wilson", "Wilson, Woodrow", "Thomas Woodrow Wilson", "Presidency of Woodrow Wilson", "President Woodrow Wilson", "President Wilson's", "T Woodrow Wilson", "W. Wilson", "Woodrow Wilson's", "Wildrow Woodson", "28th President of the United States", "T. Woodrow Wilson", "28th president of united states", "president wilson s", "w wilson", "thomas w wilson", "wilson woodrow", "woodrow wilson s"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Woodrow Wilson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:20.068428Z"}
{"question_id": "tqa_rc_validation_139", "question": "Which US president won the Nobel Peace Prize in 1920?", "ground_truth": ["Woodrow Wilson", "Thomas W. Wilson", "President wilson", "Wilson, Woodrow", "Thomas Woodrow Wilson", "Presidency of Woodrow Wilson", "President Woodrow Wilson", "President Wilson's", "T Woodrow Wilson", "W. Wilson", "Woodrow Wilson's", "Wildrow Woodson", "28th President of the United States", "T. Woodrow Wilson", "28th president of united states", "president wilson s", "w wilson", "thomas w wilson", "wilson woodrow", "woodrow wilson s"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Woodrow Wilson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:21.937697Z"}
{"question_id": "tqa_rc_validation_139", "question": "Which US president won the Nobel Peace Prize in 1920?", "ground_truth": ["Woodrow Wilson", "Thomas W. Wilson", "President wilson", "Wilson, Woodrow", "Thomas Woodrow Wilson", "Presidency of Woodrow Wilson", "President Woodrow Wilson", "President Wilson's", "T Woodrow Wilson", "W. Wilson", "Woodrow Wilson's", "Wildrow Woodson", "28th President of the United States", "T. Woodrow Wilson", "28th president of united states", "president wilson s", "w wilson", "thomas w wilson", "wilson woodrow", "woodrow wilson s"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Woodrow Wilson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:22.257175Z"}
{"question_id": "tqa_rc_validation_139", "question": "Which US president won the Nobel Peace Prize in 1920?", "ground_truth": ["Woodrow Wilson", "Thomas W. Wilson", "President wilson", "Wilson, Woodrow", "Thomas Woodrow Wilson", "Presidency of Woodrow Wilson", "President Woodrow Wilson", "President Wilson's", "T Woodrow Wilson", "W. Wilson", "Woodrow Wilson's", "Wildrow Woodson", "28th President of the United States", "T. Woodrow Wilson", "28th president of united states", "president wilson s", "w wilson", "thomas w wilson", "wilson woodrow", "woodrow wilson s"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Woodrow Wilson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:23.444065Z"}
{"question_id": "tqa_rc_validation_139", "question": "Which US president won the Nobel Peace Prize in 1920?", "ground_truth": ["Woodrow Wilson", "Thomas W. Wilson", "President wilson", "Wilson, Woodrow", "Thomas Woodrow Wilson", "Presidency of Woodrow Wilson", "President Woodrow Wilson", "President Wilson's", "T Woodrow Wilson", "W. Wilson", "Woodrow Wilson's", "Wildrow Woodson", "28th President of the United States", "T. Woodrow Wilson", "28th president of united states", "president wilson s", "w wilson", "thomas w wilson", "wilson woodrow", "woodrow wilson s"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Woodrow Wilson", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:24.268515Z"}
{"question_id": "tqa_rc_validation_140", "question": "Who beat Tim Henman in his first Wimbledon singles semifinal?", "ground_truth": ["Pete Sampras", "Sampras", "Sampras, Pete", "Peter Sampras", "Petros %22Pete%22 Sampras", "sampras pete", "petros 22pete 22 sampras"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Goran Ivanišević", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Goran Ivanišević", "Goran Ivanišević", "Goran Ivanišević", "Goran Ivanišević", "Goran Ivanišević", "Goran Ivanišević", "Goran Ivanišević", "Goran Ivanišević", "Goran Ivanišević", "Goran Ivanišević"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:44:43.225158Z"}
{"question_id": "tqa_rc_validation_140", "question": "Who beat Tim Henman in his first Wimbledon singles semifinal?", "ground_truth": ["Pete Sampras", "Sampras", "Sampras, Pete", "Peter Sampras", "Petros %22Pete%22 Sampras", "sampras pete", "petros 22pete 22 sampras"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Pete Sampras", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:45.532354Z"}
{"question_id": "tqa_rc_validation_140", "question": "Who beat Tim Henman in his first Wimbledon singles semifinal?", "ground_truth": ["Pete Sampras", "Sampras", "Sampras, Pete", "Peter Sampras", "Petros %22Pete%22 Sampras", "sampras pete", "petros 22pete 22 sampras"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Pete Sampras", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:45.770575Z"}
{"question_id": "tqa_rc_validation_140", "question": "Who beat Tim Henman in his first Wimbledon singles semifinal?", "ground_truth": ["Pete Sampras", "Sampras", "Sampras, Pete", "Peter Sampras", "Petros %22Pete%22 Sampras", "sampras pete", "petros 22pete 22 sampras"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Pete Sampras", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:47.186277Z"}
{"question_id": "tqa_rc_validation_140", "question": "Who beat Tim Henman in his first Wimbledon singles semifinal?", "ground_truth": ["Pete Sampras", "Sampras", "Sampras, Pete", "Peter Sampras", "Petros %22Pete%22 Sampras", "sampras pete", "petros 22pete 22 sampras"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Pete Sampras", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:47.932867Z"}
{"question_id": "tqa_rc_validation_141", "question": "What relation was Flo Jo to Jackie Joyner Kersee?", "ground_truth": ["Sister-in-law", "Brother in law", "Wife's sister", "Bro-law", "Sisters-in-law", "Sibling-in-law", "Siblings-in-law", "Brothers-in-law", "Brother-in-law", "Sister in law", "wife s sister", "brothers in law", "sibling in law", "siblings in law", "bro law", "sisters in law"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Sister-in-law", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:48.954698Z"}
{"question_id": "tqa_rc_validation_141", "question": "What relation was Flo Jo to Jackie Joyner Kersee?", "ground_truth": ["Sister-in-law", "Brother in law", "Wife's sister", "Bro-law", "Sisters-in-law", "Sibling-in-law", "Siblings-in-law", "Brothers-in-law", "Brother-in-law", "Sister in law", "wife s sister", "brothers in law", "sibling in law", "siblings in law", "bro law", "sisters in law"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Sister-in-law", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:49.819700Z"}
{"question_id": "tqa_rc_validation_141", "question": "What relation was Flo Jo to Jackie Joyner Kersee?", "ground_truth": ["Sister-in-law", "Brother in law", "Wife's sister", "Bro-law", "Sisters-in-law", "Sibling-in-law", "Siblings-in-law", "Brothers-in-law", "Brother-in-law", "Sister in law", "wife s sister", "brothers in law", "sibling in law", "siblings in law", "bro law", "sisters in law"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Sisters-in-law", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:50.193471Z"}
{"question_id": "tqa_rc_validation_141", "question": "What relation was Flo Jo to Jackie Joyner Kersee?", "ground_truth": ["Sister-in-law", "Brother in law", "Wife's sister", "Bro-law", "Sisters-in-law", "Sibling-in-law", "Siblings-in-law", "Brothers-in-law", "Brother-in-law", "Sister in law", "wife s sister", "brothers in law", "sibling in law", "siblings in law", "bro law", "sisters in law"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Sister-in-law", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:44:51.756256Z"}
{"question_id": "tqa_rc_validation_141", "question": "What relation was Flo Jo to Jackie Joyner Kersee?", "ground_truth": ["Sister-in-law", "Brother in law", "Wife's sister", "Bro-law", "Sisters-in-law", "Sibling-in-law", "Siblings-in-law", "Brothers-in-law", "Brother-in-law", "Sister in law", "wife s sister", "brothers in law", "sibling in law", "siblings in law", "bro law", "sisters in law"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Florence Griffith Joyner was married to Al Joyner, who was the brother of Jackie Joyner-Kersee", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Florence Griffith Joyner was married to Al Joyner, who was the brother of Jackie Joyner Kersee", "Florence Griffith Joyner (also known as \"Flo-Jo\") was married to Al Joyner, who was the brother of Jackie Joyner Kersee", "Florence Griffith Joyner, also known as Flo Jo, was married to Al Joyner, who was Jackie Joyner Kersee's brother", "Florence Griffith Joyner, also known as 'Flo Jo,' was married to Al Joyner, the brother of Jackie Joyner-Kersee", "Florence Griffith Joyner was married to Al Joyner, who was the brother of Jackie Joyner Kersee", "Florence Griffith-Joyner, also known as Flo Jo, was married to Al Joyner, the brother of Jackie Joyner-Kersee", "Florence Griffith Joyner (also known as \"Flo-Jo\") was married to Al Joyner, who was the brother of Jackie Joyner-Kersee", "Florence Griffith-Joyner was married to Al Joyner, the brother of Jackie Joyner-Kersee", "Florence Griffith Joyner was married to Jackie Joyner Kersee's husband's friend, but more closely known to be a close friend of Jackie Joyner Kersee", "Friend"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "different", "different"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:45:11.616233Z"}
{"question_id": "tqa_rc_validation_142", "question": "How long was swimmer Michelle Smith-de Bruin banned for attempting to manipulate a drugs test?", "ground_truth": ["4 years", "four  time", "4 time", "four time"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Four years", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Four years", "Four years", "Four years", "Four years", "Four years", "Four years", "Four years", "Four years", "Four years", "Four years"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:45:28.461423Z"}
{"question_id": "tqa_rc_validation_142", "question": "How long was swimmer Michelle Smith-de Bruin banned for attempting to manipulate a drugs test?", "ground_truth": ["4 years", "four  time", "4 time", "four time"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "4 years", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:45:30.668867Z"}
{"question_id": "tqa_rc_validation_142", "question": "How long was swimmer Michelle Smith-de Bruin banned for attempting to manipulate a drugs test?", "ground_truth": ["4 years", "four  time", "4 time", "four time"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "4 years", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:45:31.064549Z"}
{"question_id": "tqa_rc_validation_142", "question": "How long was swimmer Michelle Smith-de Bruin banned for attempting to manipulate a drugs test?", "ground_truth": ["4 years", "four  time", "4 time", "four time"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Four years", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Four years", "Four years", "Four years", "Four years", "Four years", "Four years", "Four years", "Four years", "Four years", "Four years"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:45:52.366620Z"}
{"question_id": "tqa_rc_validation_142", "question": "How long was swimmer Michelle Smith-de Bruin banned for attempting to manipulate a drugs test?", "ground_truth": ["4 years", "four  time", "4 time", "four time"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "2 years", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["4 years", "2 years", "3 years and 3 months", "4 years", "10 years", "3 years", "4 years", "12 months", "6 years", "2 years"], "equivalence_results": ["different", "same", "different", "different", "different", "different", "different", "different", "different", "same"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:46:07.613148Z"}
{"question_id": "tqa_rc_validation_5", "question": "Rita Coolidge sang the title song for which Bond film?", "ground_truth": ["Octopussy", "Kamal kahn", "List of Bond girls in Octopussy", "Magda (James Bond)", "List of James Bond allies in Octopussy", "Vijay (James Bond)", "Bond 13", "Octopussy (character)", "Penelope Smallbone", "General Orlov", "Kamal Khan", "Octopussy (film)", "List of James Bond villains in Octopussy", "Jim Fanning (James Bond)", "magda james bond", "vijay james bond", "jim fanning james bond", "octopussy character", "octopussy film"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "All Time High", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["All Time High", "All Time High", "All Time High", "All Time High", "Boys Town", "All Time High", "All Time High", "All Time High", "All Time High", "All Time High"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:46:08.867367Z"}
{"question_id": "tqa_rc_validation_143", "question": "Yuan Yuan was caught carrying drugs for which Chinese team?", "ground_truth": ["Swimming", "Swam", "Swimming (disambiguation)", "To-suijutsu", "to suijutsu", "swimming disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "China’s women’s volleyball team", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["China’s national women’s volleyball team", "Shanghai Sharks", "China women’s national curling team", "China", "China’s women’s volleyball team", "China national football team", "China’s national women’s hockey team", "Chinese Taipei", "China’s national gymnastics team", "Chinese Taipei"], "equivalence_results": ["same", "different", "different", "different", "same", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:46:26.069216Z"}
{"question_id": "tqa_rc_validation_143", "question": "Yuan Yuan was caught carrying drugs for which Chinese team?", "ground_truth": ["Swimming", "Swam", "Swimming (disambiguation)", "To-suijutsu", "to suijutsu", "swimming disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Liaoning", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Liaoning", "Liaoning", "Liaoning", "Liaoning", "Liaoning", "Liaoning", "Liaoning", "Liaoning", "Liaoning", "Liaoning"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:46:52.402755Z"}
{"question_id": "tqa_rc_validation_143", "question": "Yuan Yuan was caught carrying drugs for which Chinese team?", "ground_truth": ["Swimming", "Swam", "Swimming (disambiguation)", "To-suijutsu", "to suijutsu", "swimming disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Chinese Badminton Team", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Chinese badminton team", "Chinese women's softball team", "Chinese women's national badminton team", "Chinese Badminton Team", "Chinese Badminton Team", "Chinese women's national badminton team", "Chinese Badminton Team", "Chinese badminton team", "Chinese badminton team", "Chinese badminton team"], "equivalence_results": ["same", "different", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:47:02.626074Z"}
{"question_id": "tqa_rc_validation_143", "question": "Yuan Yuan was caught carrying drugs for which Chinese team?", "ground_truth": ["Swimming", "Swam", "Swimming (disambiguation)", "To-suijutsu", "to suijutsu", "swimming disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Chinese swimming team", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:47:03.945271Z"}
{"question_id": "tqa_rc_validation_143", "question": "Yuan Yuan was caught carrying drugs for which Chinese team?", "ground_truth": ["Swimming", "Swam", "Swimming (disambiguation)", "To-suijutsu", "to suijutsu", "swimming disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Chinese national basketball team", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["China national football team", "China national women's basketball team", "Chinese national football team", "Chinese national football team", "China's national basketball team", "The Chinese national football team", "Yuan Yuan was caught carrying heroin for the Chinese national basketball team", "The Chinese national basketball team", "The Chinese national basketball team", "The Chinese national bobsleigh team"], "equivalence_results": ["different", "different", "different", "different", "same", "different", "different", "same", "same", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:47:20.433123Z"}
{"question_id": "tqa_rc_validation_144", "question": "Which grand slam did Pete Sampras not win in the 20th century?", "ground_truth": ["French", "Français", "Francaise", "The French", "Frenchness", "Francais", "French (disambiguation)", "Frrench", "french disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The French Open", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:47:21.315675Z"}
{"question_id": "tqa_rc_validation_144", "question": "Which grand slam did Pete Sampras not win in the 20th century?", "ground_truth": ["French", "Français", "Francaise", "The French", "Frenchness", "Francais", "French (disambiguation)", "Frrench", "french disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "French Open", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:47:22.955883Z"}
{"question_id": "tqa_rc_validation_144", "question": "Which grand slam did Pete Sampras not win in the 20th century?", "ground_truth": ["French", "Français", "Francaise", "The French", "Frenchness", "Francais", "French (disambiguation)", "Frrench", "french disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "French Open", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:47:23.197979Z"}
{"question_id": "tqa_rc_validation_144", "question": "Which grand slam did Pete Sampras not win in the 20th century?", "ground_truth": ["French", "Français", "Francaise", "The French", "Frenchness", "Francais", "French (disambiguation)", "Frrench", "french disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "French Open", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:47:24.641267Z"}
{"question_id": "tqa_rc_validation_144", "question": "Which grand slam did Pete Sampras not win in the 20th century?", "ground_truth": ["French", "Français", "Francaise", "The French", "Frenchness", "Francais", "French (disambiguation)", "Frrench", "french disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The French Open", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:47:25.427643Z"}
{"question_id": "tqa_rc_validation_145", "question": "In which events did Gert Fredriksson win six Olympic gold medals?", "ground_truth": ["Canoeing", "Flatwater", "Canoeist", "Canoers", "Canoe flatwater racing", "Canoing", "Paddler", "Canoer", "Flatwater canoeing", "Competitive canoeing"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "K-1 1000 m and K-2 1000 m kayaking events", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Kayak (K-1 and K-2) sprint events: 1000 m and 10,000 m", "K-1 1000 m and K-2 1000 m kayaking (canoe sprint) events", "", "Kayak (K-1 and K-2) sprint events: 1000 m and 10,000 m", "K-1 1000 m and K-2 1000 m kayaking events", "Kayak sprint — K-1 1000 m (1948, 1952, 1956) and K-2 1000 m (1952, 1956, 1960)", "", "Kayak (K-1 and K-2) sprint events (1000 m and 10,000 m) at the 1948, 1952, and 1956 Summer Olympics", "Kayak sprint events in the K-1 and K-2 classes at the Summer Olympics", "K-1 1000 m (1948, 1952, 1956), K-1 10,000 m (1948), K-2 1000 m (1952, 1960)"], "equivalence_results": ["different", "same", "different", "different", "same", "same", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:47:48.038638Z"}
{"question_id": "tqa_rc_validation_145", "question": "In which events did Gert Fredriksson win six Olympic gold medals?", "ground_truth": ["Canoeing", "Flatwater", "Canoeist", "Canoers", "Canoe flatwater racing", "Canoing", "Paddler", "Canoer", "Flatwater canoeing", "Competitive canoeing"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000m (1948, 1952, 1956), K-1 10000m (", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000m (1948, 1952, 1956), K-1 10000m (", "Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000m (1948, 1952, 1956), K-1 10000m (", "Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000 m (1948, 1952, 1956), K-1 10000", "Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000m (1948, 1952, 1956), K-1 10000m (", "Gert Fredriksson won his six Olympic gold medals in flatwater canoeing (kayak) events: K-1 1000 m (1948, 1952, 1956), K-1 10", "Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000 m (1948, 1952, 1956), K-1 10000", "Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000m (1948, 1952, 1956), K-1 10000m (", "Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000m (1948, 1952, 1956), K-1 10000m (", "Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000m (1948, 1952, 1956), K-1 10000m (", "Gert Fredriksson won six Olympic gold medals in flatwater canoeing (kayak events): K-1 1000 m (1948, 1952, 1956), K-1 10000"], "equivalence_results": ["same", "same", "unclear", "same", "unclear", "unclear", "same", "same", "same", "unclear"], "equivalence_stats": {"num_same": 6, "num_different": 0, "num_unclear": 4, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:48:22.082610Z"}
{"question_id": "tqa_rc_validation_145", "question": "In which events did Gert Fredriksson win six Olympic gold medals?", "ground_truth": ["Canoeing", "Flatwater", "Canoeist", "Canoers", "Canoe flatwater racing", "Canoing", "Paddler", "Canoer", "Flatwater canoeing", "Competitive canoeing"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "K-1 1000m and K-2 1000m", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["K-1 1000m and K-1 10000m", "K-1 1000m and K-1 10000m", "K-1 1000m and K-1 10000m", "K-1 1000m and K-2 1000m", "K-1 1000 m and K-2 1000 m", "K-1 1000m and K-2 1000m", "K-1 1000m and K-2 1000m", "K-1 1000m and K-2 1000m", "K-1 1000m and K-2 1000m", "K-1 1000m and K-1 10000m"], "equivalence_results": ["different", "different", "different", "same", "same", "same", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:48:32.740652Z"}
{"question_id": "tqa_rc_validation_145", "question": "In which events did Gert Fredriksson win six Olympic gold medals?", "ground_truth": ["Canoeing", "Flatwater", "Canoeist", "Canoers", "Canoe flatwater racing", "Canoing", "Paddler", "Canoer", "Flatwater canoeing", "Competitive canoeing"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Canoeing", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:48:34.016706Z"}
{"question_id": "tqa_rc_validation_145", "question": "In which events did Gert Fredriksson win six Olympic gold medals?", "ground_truth": ["Canoeing", "Flatwater", "Canoeist", "Canoers", "Canoe flatwater racing", "Canoing", "Paddler", "Canoer", "Flatwater canoeing", "Competitive canoeing"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "K-1 1000m, K-1 10000m, K-1 4x1000m", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["K-1 1000m, K-1 10000m", "K-1 1000m, K-1 10000m", "K-1 1000m, K-1 4x1000m", "K-1 1000 meters, K-1 10000 meters, K-1, K-2, and K-1 team events", "K-1 1000m and K-1 4×500m relay", "K-1 and K-2 1000m and K-1 and K-4 10000m", "K-1 1000m, K-1 4x1000m", "Canoing", "K-1 1000 meters, K-1 10000 meters", "K-1 1000m, K-1 10,000m, K-1 4×500m relay, K-1 10,000m, K-1 1000m, K-1 10,"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:48:53.781920Z"}
{"question_id": "tqa_rc_validation_146", "question": "How many of his 45 races did Mike Hawthorn, a former Formula One motor racing world champion, win?", "ground_truth": ["Three", "3"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "3", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:48:54.459259Z"}
{"question_id": "tqa_rc_validation_146", "question": "How many of his 45 races did Mike Hawthorn, a former Formula One motor racing world champion, win?", "ground_truth": ["Three", "3"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "3", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:48:56.419468Z"}
{"question_id": "tqa_rc_validation_146", "question": "How many of his 45 races did Mike Hawthorn, a former Formula One motor racing world champion, win?", "ground_truth": ["Three", "3"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "3", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:48:56.815868Z"}
{"question_id": "tqa_rc_validation_146", "question": "How many of his 45 races did Mike Hawthorn, a former Formula One motor racing world champion, win?", "ground_truth": ["Three", "3"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "3", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:48:58.344435Z"}
{"question_id": "tqa_rc_validation_146", "question": "How many of his 45 races did Mike Hawthorn, a former Formula One motor racing world champion, win?", "ground_truth": ["Three", "3"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "3", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:48:59.067604Z"}
{"question_id": "tqa_rc_validation_147", "question": "On the Internet what is Spam?", "ground_truth": ["Junk mail", "Junk mail (disambiguation)", "Junkmail", "Junkmailing", "junk mail disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Unsolicited bulk messages, typically sent by email, often for advertising or scams", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Unsolicited bulk messages, typically sent via email or other online platforms, often for advertising or malicious purposes", "Unsolicited, usually bulk, unwanted messages sent online, often for advertising or scams", "Unsolicited bulk messages, typically sent via email or other online platforms, often for advertising or malicious purposes", "Unsolicited, usually bulk, messages sent online, typically for advertising, scams, or malicious purposes", "Unsolicited bulk messages, typically sent via email or other online platforms, often for advertising or malicious purposes", "Unsolicited bulk messages, typically sent by email or other online platforms, often for advertising or malicious purposes", "Unsolicited, usually bulk, unwanted messages sent online, often for advertising or scams", "Unsolicited, usually bulk, unwanted messages sent online, often for advertising or scams", "Unsolicited bulk messages, typically advertising, sent online (e", "Unsolicited bulk messages, typically sent by email or other online platforms, often for advertising or malicious purposes"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "unclear", "same"], "equivalence_stats": {"num_same": 9, "num_different": 0, "num_unclear": 1, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:49:20.914273Z"}
{"question_id": "tqa_rc_validation_147", "question": "On the Internet what is Spam?", "ground_truth": ["Junk mail", "Junk mail (disambiguation)", "Junkmail", "Junkmailing", "junk mail disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Unsolicited bulk messages, typically advertisements, sent indiscriminately to large numbers of recipients via email or other digital platforms", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Unsolicited bulk messages, typically advertisements, sent indiscriminately to large numbers of recipients via email or other digital platforms", "Unsolicited bulk messages, typically advertisements, sent indiscriminately to a large number of recipients via email or other digital platforms", "Unsolicited bulk messages, typically advertisements, sent indiscriminately to a large number of recipients via email or other digital platforms", "Unsolicited bulk messages, typically advertisements, sent indiscriminately to large numbers of recipients via email or other digital platforms", "Unsolicited bulk messages, typically advertisements, sent indiscriminately to large numbers of recipients via email or other digital platforms", "Unsolicited bulk messages, typically advertisements, sent indiscriminately to a large number of recipients via email or other digital platforms", "Unsolicited bulk messages, typically advertisements, sent indiscriminately to large numbers of recipients via email or other digital platforms", "Unsolicited bulk messages, typically advertisements, sent indiscriminately to large numbers of recipients via email or other digital platforms", "Unsolicited bulk messages, typically advertisements, sent indiscriminately to large numbers of recipients via email or other digital platforms", "Unsolicited bulk messages, typically advertisements, sent indiscriminately to large numbers of recipients via email or other digital platforms"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:49:51.178904Z"}
{"question_id": "tqa_rc_validation_147", "question": "On the Internet what is Spam?", "ground_truth": ["Junk mail", "Junk mail (disambiguation)", "Junkmail", "Junkmailing", "junk mail disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Unsolicited commercial email", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Unsolicited commercial email", "Unsolicited commercial email", "Unsolicited commercial email", "Unsolicited commercial email", "Unsolicited commercial email", "Unsolicited commercial email", "Unsolicited commercial email", "Unsolicited commercial email", "Unsolicited commercial email", "Unsolicited commercial email"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:50:01.229465Z"}
{"question_id": "tqa_rc_validation_147", "question": "On the Internet what is Spam?", "ground_truth": ["Junk mail", "Junk mail (disambiguation)", "Junkmail", "Junkmailing", "junk mail disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Unwanted or unsolicited bulk messages", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Unwanted or unsolicited bulk messages", "Unwanted or unsolicited bulk messages", "Unwanted or unsolicited bulk messages, typically sent via email", "Unsolicited bulk messages, typically for advertising or phishing", "Unsolicited bulk messages, typically sent via email", "Unsolicited bulk messages, typically sent for advertising, phishing, or malware distribution", "Unsolicited bulk messages, typically sent for advertising or malicious purposes", "Unsolicited bulk messages, typically sent via email", "Unwanted or unsolicited bulk messages, typically sent via email", "Unsolicited bulk messages, typically sent via email"], "equivalence_results": ["same", "same", "different", "different", "same", "same", "different", "same", "different", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:50:25.799814Z"}
{"question_id": "tqa_rc_validation_147", "question": "On the Internet what is Spam?", "ground_truth": ["Junk mail", "Junk mail (disambiguation)", "Junkmail", "Junkmailing", "junk mail disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Unsolicited commercial email or messages", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Unsolicited commercial messages or emails", "Unsolicited commercial email or messages", "Unsolicited commercial email or messages, especially those with unwanted or insignificant content", "Unwanted or unsolicited messages or content, usually commercial in nature, sent to a large number of recipients", "Unsolicited commercial electronic messages, usually advertisements or scams", "Unwanted or unsolicited messages, especially advertisements, sent to a large number of recipients", "Unwanted or unsolicited messages, emails, or advertisements", "Unsolicited commercial email or messages sent to large numbers of recipients", "Unsolicited commercial email", "Unsolicited commercial email"], "equivalence_results": ["same", "same", "different", "same", "same", "different", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:50:43.165940Z"}
{"question_id": "tqa_rc_validation_148", "question": "In which country did the Internet start?", "ground_truth": ["USA", "The United States of America", "United States Of Amerca", "Us of a", "U.–S.–A.", "Americaland", "United States (U.S.A.)", "Amurika", "Unite states of america", "United States of America (redirect)", "The U S A", "Unietd States", "EE UU", "The U.S.A.", "U.-S.-A.", "United Staets of America", "Unites States", "États-Unis d'Amérique", "Verenigde State", "U.–S.", "The United States of America.", "The U-S-A", "EEUU", "U. S. A.", "Nagkaisang mga Estado", "The U. S. of America", "The USA", "America (United States)", "The U. S. A.", "U S of America", "UNITED STATES", "Estados Unidos", "The U–S", "American United States", "US and A", "Unitd states", "The US of A", "EE.UU.", "U-S", "The U-S", "Etymology of the United States", "U.S.A.)", "EE. UU.", "United states of america", "US of america", "Verenigde State van Amerika", "Nited States", "United-States", "Unite States", "Estados Unidos de América", "UnitedStates", "Estaos Unios", "Untied States of America", "The U S of America", "THE AMERICAN UNITED STATES", "The United-States", "U S A", "AmericA", "Estados Unidos de America", "The U.S. of America", "Amerka", "United–States", "U.s.a.", "United State of America", "United States (US)", "The U.S. of A", "Amercia", "Stati Uniti d'America", "Los Estados Unidos de America", "United Stated", "U.S.", "United States (of America)", "States of America", "America-class", "Los Estados Unidos", "U,S,", "United States (country)", "Federal United States", "ISO 3166-1:US", "Untied States", "The U.–S.–A.", "VS America", "Amurica", "Etats-Unis d'Amerique", "US", "U.S. OF A", "USofA", "Etats-Unis", "United States of America (U.S.A.)", "Amarica", "The United States", "U-S-A", "United States/Introduction", "The Us", "Unitesd states", "The U S of A", "America class", "America magazine", "الولايات المتحدة الأمريكية", "The U. S. of A", "U S", "(USA)", "The United–States", "United States (U.S.)", "U.-S.", "United States of America (USA)", "'merica", "United States of America.", "The U.S.", "United States of America/OldPage", "United+States", "The U S", "United Sates", "U–S–A", "U.S. of America", "U–S", "Los Estados Unidos de América", "The U.-S.", "America (country)", "United States of American", "The U.–S.", "Amurka", "U. S. of A", "The U. S.", "United States America", "États-Unis", "USoA", "Estaos Uníos", "America, United States of", "U. S. of America", "U.S.American", "(US)", "The U–S–A", "U. S.", "U.S. America", "U.S. A", "Yankee land", "America (US)", "U.S", "America (United States of)", "US (country)", "U.S.A", "Americia", "The US of america", "Vereinigte Staaten", "US America", "These United States of America", "VS Amerika", "Name of the United States", "Estatos Unitos", "America (USA)", "The U.-S.-A.", "United States of America/Introduction", "Americophile", "V.S. America", "U S of A", "V.S. Amerika", "United+States+of+America", "The Unites States of America", "u–s–", "america united states of", "v s amerika", "united states of america oldpage", "america us", "etats unis d amerique", "america united states", "merica", "v s america", "états unis d amérique", "united states of america u s", "etymology of united states", "u s american", "united states of america usa", "united states u s", "us and", "etats unis", "united states introduction", "america usa", "u s of", "iso 3166 1 us", "united states country", "america country", "united states us", "united states of america redirect", "stati uniti d america", "us country", "états unis", "us of", "unites states of america", "name of united states", "u s america", "u –s –", "united states of america introduction", "u –s"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The United States", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:50:43.967298Z"}
{"question_id": "tqa_rc_validation_148", "question": "In which country did the Internet start?", "ground_truth": ["USA", "The United States of America", "United States Of Amerca", "Us of a", "U.–S.–A.", "Americaland", "United States (U.S.A.)", "Amurika", "Unite states of america", "United States of America (redirect)", "The U S A", "Unietd States", "EE UU", "The U.S.A.", "U.-S.-A.", "United Staets of America", "Unites States", "États-Unis d'Amérique", "Verenigde State", "U.–S.", "The United States of America.", "The U-S-A", "EEUU", "U. S. A.", "Nagkaisang mga Estado", "The U. S. of America", "The USA", "America (United States)", "The U. S. A.", "U S of America", "UNITED STATES", "Estados Unidos", "The U–S", "American United States", "US and A", "Unitd states", "The US of A", "EE.UU.", "U-S", "The U-S", "Etymology of the United States", "U.S.A.)", "EE. UU.", "United states of america", "US of america", "Verenigde State van Amerika", "Nited States", "United-States", "Unite States", "Estados Unidos de América", "UnitedStates", "Estaos Unios", "Untied States of America", "The U S of America", "THE AMERICAN UNITED STATES", "The United-States", "U S A", "AmericA", "Estados Unidos de America", "The U.S. of America", "Amerka", "United–States", "U.s.a.", "United State of America", "United States (US)", "The U.S. of A", "Amercia", "Stati Uniti d'America", "Los Estados Unidos de America", "United Stated", "U.S.", "United States (of America)", "States of America", "America-class", "Los Estados Unidos", "U,S,", "United States (country)", "Federal United States", "ISO 3166-1:US", "Untied States", "The U.–S.–A.", "VS America", "Amurica", "Etats-Unis d'Amerique", "US", "U.S. OF A", "USofA", "Etats-Unis", "United States of America (U.S.A.)", "Amarica", "The United States", "U-S-A", "United States/Introduction", "The Us", "Unitesd states", "The U S of A", "America class", "America magazine", "الولايات المتحدة الأمريكية", "The U. S. of A", "U S", "(USA)", "The United–States", "United States (U.S.)", "U.-S.", "United States of America (USA)", "'merica", "United States of America.", "The U.S.", "United States of America/OldPage", "United+States", "The U S", "United Sates", "U–S–A", "U.S. of America", "U–S", "Los Estados Unidos de América", "The U.-S.", "America (country)", "United States of American", "The U.–S.", "Amurka", "U. S. of A", "The U. S.", "United States America", "États-Unis", "USoA", "Estaos Uníos", "America, United States of", "U. S. of America", "U.S.American", "(US)", "The U–S–A", "U. S.", "U.S. America", "U.S. A", "Yankee land", "America (US)", "U.S", "America (United States of)", "US (country)", "U.S.A", "Americia", "The US of america", "Vereinigte Staaten", "US America", "These United States of America", "VS Amerika", "Name of the United States", "Estatos Unitos", "America (USA)", "The U.-S.-A.", "United States of America/Introduction", "Americophile", "V.S. America", "U S of A", "V.S. Amerika", "United+States+of+America", "The Unites States of America", "u–s–", "america united states of", "v s amerika", "united states of america oldpage", "america us", "etats unis d amerique", "america united states", "merica", "v s america", "états unis d amérique", "united states of america u s", "etymology of united states", "u s american", "united states of america usa", "united states u s", "us and", "etats unis", "united states introduction", "america usa", "u s of", "iso 3166 1 us", "united states country", "america country", "united states us", "united states of america redirect", "stati uniti d america", "us country", "états unis", "us of", "unites states of america", "name of united states", "u s america", "u –s –", "united states of america introduction", "u –s"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "United States", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:50:44.758351Z"}
{"question_id": "tqa_rc_validation_148", "question": "In which country did the Internet start?", "ground_truth": ["USA", "The United States of America", "United States Of Amerca", "Us of a", "U.–S.–A.", "Americaland", "United States (U.S.A.)", "Amurika", "Unite states of america", "United States of America (redirect)", "The U S A", "Unietd States", "EE UU", "The U.S.A.", "U.-S.-A.", "United Staets of America", "Unites States", "États-Unis d'Amérique", "Verenigde State", "U.–S.", "The United States of America.", "The U-S-A", "EEUU", "U. S. A.", "Nagkaisang mga Estado", "The U. S. of America", "The USA", "America (United States)", "The U. S. A.", "U S of America", "UNITED STATES", "Estados Unidos", "The U–S", "American United States", "US and A", "Unitd states", "The US of A", "EE.UU.", "U-S", "The U-S", "Etymology of the United States", "U.S.A.)", "EE. UU.", "United states of america", "US of america", "Verenigde State van Amerika", "Nited States", "United-States", "Unite States", "Estados Unidos de América", "UnitedStates", "Estaos Unios", "Untied States of America", "The U S of America", "THE AMERICAN UNITED STATES", "The United-States", "U S A", "AmericA", "Estados Unidos de America", "The U.S. of America", "Amerka", "United–States", "U.s.a.", "United State of America", "United States (US)", "The U.S. of A", "Amercia", "Stati Uniti d'America", "Los Estados Unidos de America", "United Stated", "U.S.", "United States (of America)", "States of America", "America-class", "Los Estados Unidos", "U,S,", "United States (country)", "Federal United States", "ISO 3166-1:US", "Untied States", "The U.–S.–A.", "VS America", "Amurica", "Etats-Unis d'Amerique", "US", "U.S. OF A", "USofA", "Etats-Unis", "United States of America (U.S.A.)", "Amarica", "The United States", "U-S-A", "United States/Introduction", "The Us", "Unitesd states", "The U S of A", "America class", "America magazine", "الولايات المتحدة الأمريكية", "The U. S. of A", "U S", "(USA)", "The United–States", "United States (U.S.)", "U.-S.", "United States of America (USA)", "'merica", "United States of America.", "The U.S.", "United States of America/OldPage", "United+States", "The U S", "United Sates", "U–S–A", "U.S. of America", "U–S", "Los Estados Unidos de América", "The U.-S.", "America (country)", "United States of American", "The U.–S.", "Amurka", "U. S. of A", "The U. S.", "United States America", "États-Unis", "USoA", "Estaos Uníos", "America, United States of", "U. S. of America", "U.S.American", "(US)", "The U–S–A", "U. S.", "U.S. America", "U.S. A", "Yankee land", "America (US)", "U.S", "America (United States of)", "US (country)", "U.S.A", "Americia", "The US of america", "Vereinigte Staaten", "US America", "These United States of America", "VS Amerika", "Name of the United States", "Estatos Unitos", "America (USA)", "The U.-S.-A.", "United States of America/Introduction", "Americophile", "V.S. America", "U S of A", "V.S. Amerika", "United+States+of+America", "The Unites States of America", "u–s–", "america united states of", "v s amerika", "united states of america oldpage", "america us", "etats unis d amerique", "america united states", "merica", "v s america", "états unis d amérique", "united states of america u s", "etymology of united states", "u s american", "united states of america usa", "united states u s", "us and", "etats unis", "united states introduction", "america usa", "u s of", "iso 3166 1 us", "united states country", "america country", "united states us", "united states of america redirect", "stati uniti d america", "us country", "états unis", "us of", "unites states of america", "name of united states", "u s america", "u –s –", "united states of america introduction", "u –s"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "United States", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:50:45.014934Z"}
{"question_id": "tqa_rc_validation_148", "question": "In which country did the Internet start?", "ground_truth": ["USA", "The United States of America", "United States Of Amerca", "Us of a", "U.–S.–A.", "Americaland", "United States (U.S.A.)", "Amurika", "Unite states of america", "United States of America (redirect)", "The U S A", "Unietd States", "EE UU", "The U.S.A.", "U.-S.-A.", "United Staets of America", "Unites States", "États-Unis d'Amérique", "Verenigde State", "U.–S.", "The United States of America.", "The U-S-A", "EEUU", "U. S. A.", "Nagkaisang mga Estado", "The U. S. of America", "The USA", "America (United States)", "The U. S. A.", "U S of America", "UNITED STATES", "Estados Unidos", "The U–S", "American United States", "US and A", "Unitd states", "The US of A", "EE.UU.", "U-S", "The U-S", "Etymology of the United States", "U.S.A.)", "EE. UU.", "United states of america", "US of america", "Verenigde State van Amerika", "Nited States", "United-States", "Unite States", "Estados Unidos de América", "UnitedStates", "Estaos Unios", "Untied States of America", "The U S of America", "THE AMERICAN UNITED STATES", "The United-States", "U S A", "AmericA", "Estados Unidos de America", "The U.S. of America", "Amerka", "United–States", "U.s.a.", "United State of America", "United States (US)", "The U.S. of A", "Amercia", "Stati Uniti d'America", "Los Estados Unidos de America", "United Stated", "U.S.", "United States (of America)", "States of America", "America-class", "Los Estados Unidos", "U,S,", "United States (country)", "Federal United States", "ISO 3166-1:US", "Untied States", "The U.–S.–A.", "VS America", "Amurica", "Etats-Unis d'Amerique", "US", "U.S. OF A", "USofA", "Etats-Unis", "United States of America (U.S.A.)", "Amarica", "The United States", "U-S-A", "United States/Introduction", "The Us", "Unitesd states", "The U S of A", "America class", "America magazine", "الولايات المتحدة الأمريكية", "The U. S. of A", "U S", "(USA)", "The United–States", "United States (U.S.)", "U.-S.", "United States of America (USA)", "'merica", "United States of America.", "The U.S.", "United States of America/OldPage", "United+States", "The U S", "United Sates", "U–S–A", "U.S. of America", "U–S", "Los Estados Unidos de América", "The U.-S.", "America (country)", "United States of American", "The U.–S.", "Amurka", "U. S. of A", "The U. S.", "United States America", "États-Unis", "USoA", "Estaos Uníos", "America, United States of", "U. S. of America", "U.S.American", "(US)", "The U–S–A", "U. S.", "U.S. America", "U.S. A", "Yankee land", "America (US)", "U.S", "America (United States of)", "US (country)", "U.S.A", "Americia", "The US of america", "Vereinigte Staaten", "US America", "These United States of America", "VS Amerika", "Name of the United States", "Estatos Unitos", "America (USA)", "The U.-S.-A.", "United States of America/Introduction", "Americophile", "V.S. America", "U S of A", "V.S. Amerika", "United+States+of+America", "The Unites States of America", "u–s–", "america united states of", "v s amerika", "united states of america oldpage", "america us", "etats unis d amerique", "america united states", "merica", "v s america", "états unis d amérique", "united states of america u s", "etymology of united states", "u s american", "united states of america usa", "united states u s", "us and", "etats unis", "united states introduction", "america usa", "u s of", "iso 3166 1 us", "united states country", "america country", "united states us", "united states of america redirect", "stati uniti d america", "us country", "états unis", "us of", "unites states of america", "name of united states", "u s america", "u –s –", "united states of america introduction", "u –s"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "United States", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:50:46.171810Z"}
{"question_id": "tqa_rc_validation_148", "question": "In which country did the Internet start?", "ground_truth": ["USA", "The United States of America", "United States Of Amerca", "Us of a", "U.–S.–A.", "Americaland", "United States (U.S.A.)", "Amurika", "Unite states of america", "United States of America (redirect)", "The U S A", "Unietd States", "EE UU", "The U.S.A.", "U.-S.-A.", "United Staets of America", "Unites States", "États-Unis d'Amérique", "Verenigde State", "U.–S.", "The United States of America.", "The U-S-A", "EEUU", "U. S. A.", "Nagkaisang mga Estado", "The U. S. of America", "The USA", "America (United States)", "The U. S. A.", "U S of America", "UNITED STATES", "Estados Unidos", "The U–S", "American United States", "US and A", "Unitd states", "The US of A", "EE.UU.", "U-S", "The U-S", "Etymology of the United States", "U.S.A.)", "EE. UU.", "United states of america", "US of america", "Verenigde State van Amerika", "Nited States", "United-States", "Unite States", "Estados Unidos de América", "UnitedStates", "Estaos Unios", "Untied States of America", "The U S of America", "THE AMERICAN UNITED STATES", "The United-States", "U S A", "AmericA", "Estados Unidos de America", "The U.S. of America", "Amerka", "United–States", "U.s.a.", "United State of America", "United States (US)", "The U.S. of A", "Amercia", "Stati Uniti d'America", "Los Estados Unidos de America", "United Stated", "U.S.", "United States (of America)", "States of America", "America-class", "Los Estados Unidos", "U,S,", "United States (country)", "Federal United States", "ISO 3166-1:US", "Untied States", "The U.–S.–A.", "VS America", "Amurica", "Etats-Unis d'Amerique", "US", "U.S. OF A", "USofA", "Etats-Unis", "United States of America (U.S.A.)", "Amarica", "The United States", "U-S-A", "United States/Introduction", "The Us", "Unitesd states", "The U S of A", "America class", "America magazine", "الولايات المتحدة الأمريكية", "The U. S. of A", "U S", "(USA)", "The United–States", "United States (U.S.)", "U.-S.", "United States of America (USA)", "'merica", "United States of America.", "The U.S.", "United States of America/OldPage", "United+States", "The U S", "United Sates", "U–S–A", "U.S. of America", "U–S", "Los Estados Unidos de América", "The U.-S.", "America (country)", "United States of American", "The U.–S.", "Amurka", "U. S. of A", "The U. S.", "United States America", "États-Unis", "USoA", "Estaos Uníos", "America, United States of", "U. S. of America", "U.S.American", "(US)", "The U–S–A", "U. S.", "U.S. America", "U.S. A", "Yankee land", "America (US)", "U.S", "America (United States of)", "US (country)", "U.S.A", "Americia", "The US of america", "Vereinigte Staaten", "US America", "These United States of America", "VS Amerika", "Name of the United States", "Estatos Unitos", "America (USA)", "The U.-S.-A.", "United States of America/Introduction", "Americophile", "V.S. America", "U S of A", "V.S. Amerika", "United+States+of+America", "The Unites States of America", "u–s–", "america united states of", "v s amerika", "united states of america oldpage", "america us", "etats unis d amerique", "america united states", "merica", "v s america", "états unis d amérique", "united states of america u s", "etymology of united states", "u s american", "united states of america usa", "united states u s", "us and", "etats unis", "united states introduction", "america usa", "u s of", "iso 3166 1 us", "united states country", "america country", "united states us", "united states of america redirect", "stati uniti d america", "us country", "états unis", "us of", "unites states of america", "name of united states", "u s america", "u –s –", "united states of america introduction", "u –s"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The United States", "greedy_correct": true, "correctness_match_type": "gold_contains_prediction", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:50:47.031624Z"}
{"question_id": "tqa_rc_validation_149", "question": "In which year was the Juilliard School founded in New York?", "ground_truth": ["1905", "one thousand, nine hundred and five", "one thousand nine hundred and five"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "1905", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:50:47.902921Z"}
{"question_id": "tqa_rc_validation_149", "question": "In which year was the Juilliard School founded in New York?", "ground_truth": ["1905", "one thousand, nine hundred and five", "one thousand nine hundred and five"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "1905", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:50:49.398517Z"}
{"question_id": "tqa_rc_validation_149", "question": "In which year was the Juilliard School founded in New York?", "ground_truth": ["1905", "one thousand, nine hundred and five", "one thousand nine hundred and five"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "1924", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1924", "1924", "1905", "1924", "1924", "1924", "1924", "1924", "1924", "1924"], "equivalence_results": ["same", "same", "different", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:51:02.434582Z"}
{"question_id": "tqa_rc_validation_149", "question": "In which year was the Juilliard School founded in New York?", "ground_truth": ["1905", "one thousand, nine hundred and five", "one thousand nine hundred and five"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "1905", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:51:03.529327Z"}
{"question_id": "tqa_rc_validation_149", "question": "In which year was the Juilliard School founded in New York?", "ground_truth": ["1905", "one thousand, nine hundred and five", "one thousand nine hundred and five"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "1905", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:51:04.259884Z"}
{"question_id": "tqa_rc_validation_150", "question": "Who wrote My Life and Loves in 1926, originally banned in the US?", "ground_truth": ["Frank Harris"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Frank Harris", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:51:05.138568Z"}
{"question_id": "tqa_rc_validation_150", "question": "Who wrote My Life and Loves in 1926, originally banned in the US?", "ground_truth": ["Frank Harris"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Frank Harris", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:51:06.775991Z"}
{"question_id": "tqa_rc_validation_150", "question": "Who wrote My Life and Loves in 1926, originally banned in the US?", "ground_truth": ["Frank Harris"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Frank Harris", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:51:07.200548Z"}
{"question_id": "tqa_rc_validation_150", "question": "Who wrote My Life and Loves in 1926, originally banned in the US?", "ground_truth": ["Frank Harris"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Frank Harris", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:51:08.391749Z"}
{"question_id": "tqa_rc_validation_150", "question": "Who wrote My Life and Loves in 1926, originally banned in the US?", "ground_truth": ["Frank Harris"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Frank Harris", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:51:09.047460Z"}
{"question_id": "tqa_rc_validation_151", "question": "What was Blondie's last UK No 1 of the 80s?", "ground_truth": ["Rapture", "Midtribulation rapture", "Midtribulationism", "Pre-tribulation", "Pre-tribulation rapture", "Pretribulation rapture", "Mid-tribulation rapture", "Rapture (Protestant belief)", "The Teaching of the rapture", "Pretribulationistism", "Pre Tribulation", "Pre-tribulational", "Pre-trib", "teaching of rapture", "pre tribulation rapture", "rapture protestant belief", "pre tribulational", "mid tribulation rapture", "pre trib"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Tide Is High", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Tide Is High", "The Tide Is High", "The Tide Is High", "“The Tide Is High”", "The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:51:27.183448Z"}
{"question_id": "tqa_rc_validation_151", "question": "What was Blondie's last UK No 1 of the 80s?", "ground_truth": ["Rapture", "Midtribulation rapture", "Midtribulationism", "Pre-tribulation", "Pre-tribulation rapture", "Pretribulation rapture", "Mid-tribulation rapture", "Rapture (Protestant belief)", "The Teaching of the rapture", "Pretribulationistism", "Pre Tribulation", "Pre-tribulational", "Pre-trib", "teaching of rapture", "pre tribulation rapture", "rapture protestant belief", "pre tribulational", "mid tribulation rapture", "pre trib"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Atomic", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Atomic", "The Tide Is High", "Atomic", "Atomic", "The Tide Is High", "Atomic", "Atomic", "Atomic", "Atomic", "Atomic"], "equivalence_results": ["same", "different", "same", "same", "different", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:51:53.021470Z"}
{"question_id": "tqa_rc_validation_151", "question": "What was Blondie's last UK No 1 of the 80s?", "ground_truth": ["Rapture", "Midtribulation rapture", "Midtribulationism", "Pre-tribulation", "Pre-tribulation rapture", "Pretribulation rapture", "Mid-tribulation rapture", "Rapture (Protestant belief)", "The Teaching of the rapture", "Pretribulationistism", "Pre Tribulation", "Pre-tribulational", "Pre-trib", "teaching of rapture", "pre tribulation rapture", "rapture protestant belief", "pre tribulational", "mid tribulation rapture", "pre trib"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Heart of Glass was not their last UK No 1 of the 80s, it was actually Atomic in 1980 and then Harden My Heart (with Pat Benatar, not solo) wasn't, but their cover of \"Call Me\"", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Atomic", "Heart of Glass was not their last UK No 1 of the 80s, it was actually Atomic", "Heart of Glass was not their last UK No 1 of the 80s, it was actually Atomic in 1980 and then Heartbreak Beat wasn't a UK No 1, but Call Me was not their last either", "Atomic", "Heart of Glass was not their last UK No 1 of the 80s, it was actually \"Against All Odds\" by Phil Collins that was stopped from No 1 by", "Heart of Glass was not their last UK No 1 of the 80s, it was actually Atomic", "Heart of Glass was not their last UK No 1 of the 80s, it was actually Atomic in 1980 and then The Tide is High in 1981, but their last UK No 1 of the decade was actually Harden", "Heart of Glass was not their last UK No 1 of the 80s, it was actually Atomic", "Heart of Glass was not their last UK No 1 of the 80s, it was actually Atomic", "Heart of Glass was not their last UK No 1 of the 80s, it was actually Atomic"], "equivalence_results": ["different", "different", "different", "same", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 1, "num_different": 9, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.1, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:52:04.663081Z"}
{"question_id": "tqa_rc_validation_151", "question": "What was Blondie's last UK No 1 of the 80s?", "ground_truth": ["Rapture", "Midtribulation rapture", "Midtribulationism", "Pre-tribulation", "Pre-tribulation rapture", "Pretribulation rapture", "Mid-tribulation rapture", "Rapture (Protestant belief)", "The Teaching of the rapture", "Pretribulationistism", "Pre Tribulation", "Pre-tribulational", "Pre-trib", "teaching of rapture", "pre tribulation rapture", "rapture protestant belief", "pre tribulational", "mid tribulation rapture", "pre trib"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "The Tide Is High", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High", "The Tide Is High"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:52:26.720862Z"}
{"question_id": "tqa_rc_validation_151", "question": "What was Blondie's last UK No 1 of the 80s?", "ground_truth": ["Rapture", "Midtribulation rapture", "Midtribulationism", "Pre-tribulation", "Pre-tribulation rapture", "Pretribulation rapture", "Mid-tribulation rapture", "Rapture (Protestant belief)", "The Teaching of the rapture", "Pretribulationistism", "Pre Tribulation", "Pre-tribulational", "Pre-trib", "teaching of rapture", "pre tribulation rapture", "rapture protestant belief", "pre tribulational", "mid tribulation rapture", "pre trib"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "\"Married\"", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["\"Isle of No Doubt\"", "\"No Exit\"", "\"Married for the First Time\"", "\"Maria\"", "\"Maria\"", "\"Married for the Last Time\"", "\"Isle of No Doubt\"", "It's Over", "\"Married\"", "\"Marbles\""], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 1, "num_different": 9, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.1, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:52:43.287683Z"}
{"question_id": "tqa_rc_validation_152", "question": "In baseball, where do the Royals come from?", "ground_truth": ["Kansas city", "Kansas City Metro", "Kansas City Metropolitan Area", "Metropolitan Kansas City", "Kansas City metro area", "Greater Kansas City", "KC Metropolitan Area", "Kansas City, Missouri metropolitan area", "Kansas City-Overland Park-Kansas City, MO-KS CSA", "Kansas City-Overland Park-Kansas City, MO-KS Combined Statistical Area", "K.C. Metropolitan Area", "Kansas City, MO-KS MSA", "Kansas City, MO-KS Metropolitan Statistical Area", "Kansas City, USA", "kansas city overland park kansas city mo ks combined statistical area", "kansas city overland park kansas city mo ks csa", "kansas city mo ks msa", "kansas city missouri metropolitan area", "kansas city usa", "kansas city mo ks metropolitan statistical area", "k c metropolitan area"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Kansas City", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:52:44.070889Z"}
{"question_id": "tqa_rc_validation_152", "question": "In baseball, where do the Royals come from?", "ground_truth": ["Kansas city", "Kansas City Metro", "Kansas City Metropolitan Area", "Metropolitan Kansas City", "Kansas City metro area", "Greater Kansas City", "KC Metropolitan Area", "Kansas City, Missouri metropolitan area", "Kansas City-Overland Park-Kansas City, MO-KS CSA", "Kansas City-Overland Park-Kansas City, MO-KS Combined Statistical Area", "K.C. Metropolitan Area", "Kansas City, MO-KS MSA", "Kansas City, MO-KS Metropolitan Statistical Area", "Kansas City, USA", "kansas city overland park kansas city mo ks combined statistical area", "kansas city overland park kansas city mo ks csa", "kansas city mo ks msa", "kansas city missouri metropolitan area", "kansas city usa", "kansas city mo ks metropolitan statistical area", "k c metropolitan area"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Kansas City", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:52:45.050551Z"}
{"question_id": "tqa_rc_validation_152", "question": "In baseball, where do the Royals come from?", "ground_truth": ["Kansas city", "Kansas City Metro", "Kansas City Metropolitan Area", "Metropolitan Kansas City", "Kansas City metro area", "Greater Kansas City", "KC Metropolitan Area", "Kansas City, Missouri metropolitan area", "Kansas City-Overland Park-Kansas City, MO-KS CSA", "Kansas City-Overland Park-Kansas City, MO-KS Combined Statistical Area", "K.C. Metropolitan Area", "Kansas City, MO-KS MSA", "Kansas City, MO-KS Metropolitan Statistical Area", "Kansas City, USA", "kansas city overland park kansas city mo ks combined statistical area", "kansas city overland park kansas city mo ks csa", "kansas city mo ks msa", "kansas city missouri metropolitan area", "kansas city usa", "kansas city mo ks metropolitan statistical area", "k c metropolitan area"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Kansas City", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:52:45.412063Z"}
{"question_id": "tqa_rc_validation_152", "question": "In baseball, where do the Royals come from?", "ground_truth": ["Kansas city", "Kansas City Metro", "Kansas City Metropolitan Area", "Metropolitan Kansas City", "Kansas City metro area", "Greater Kansas City", "KC Metropolitan Area", "Kansas City, Missouri metropolitan area", "Kansas City-Overland Park-Kansas City, MO-KS CSA", "Kansas City-Overland Park-Kansas City, MO-KS Combined Statistical Area", "K.C. Metropolitan Area", "Kansas City, MO-KS MSA", "Kansas City, MO-KS Metropolitan Statistical Area", "Kansas City, USA", "kansas city overland park kansas city mo ks combined statistical area", "kansas city overland park kansas city mo ks csa", "kansas city mo ks msa", "kansas city missouri metropolitan area", "kansas city usa", "kansas city mo ks metropolitan statistical area", "k c metropolitan area"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Kansas City, Missouri", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:52:46.761577Z"}
{"question_id": "tqa_rc_validation_152", "question": "In baseball, where do the Royals come from?", "ground_truth": ["Kansas city", "Kansas City Metro", "Kansas City Metropolitan Area", "Metropolitan Kansas City", "Kansas City metro area", "Greater Kansas City", "KC Metropolitan Area", "Kansas City, Missouri metropolitan area", "Kansas City-Overland Park-Kansas City, MO-KS CSA", "Kansas City-Overland Park-Kansas City, MO-KS Combined Statistical Area", "K.C. Metropolitan Area", "Kansas City, MO-KS MSA", "Kansas City, MO-KS Metropolitan Statistical Area", "Kansas City, USA", "kansas city overland park kansas city mo ks combined statistical area", "kansas city overland park kansas city mo ks csa", "kansas city mo ks msa", "kansas city missouri metropolitan area", "kansas city usa", "kansas city mo ks metropolitan statistical area", "k c metropolitan area"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Kansas City", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:52:47.639294Z"}
{"question_id": "tqa_rc_validation_153", "question": "What is the largest city in Ohio?", "ground_truth": ["Cleveland", "The Rock 'n' Roll Capital of the World", "Cleveland, Cuyahoga, Ohio", "Cleveland, Ohio", "Clevelnad", "The Cleve", "Government of Cleveland, Ohio", "Cleveland, Ohio, US", "Cleaveland", "Urban community school", "Ohio Cleveland", "Cleveland, Ohio, USA", "Cleveland, Ohio, U.S.A.", "Cleveland, OH.", "Sixth City", "Cleveland, oh", "UN/LOCODE:USCLE", "Cleveland,ohio", "The Rock and Roll Capital of the World", "Cleveland, USA", "Poznan, Ohio", "Cleveland Ohio", "Cleveland (OH)", "Sister Cities of Cleveland, Ohio", "Cleveland, Ohio, U.S.", "Cleveland (Ohio)", "Government of Cleveland", "rock and roll capital of world", "cleveland ohio us", "sister cities of cleveland ohio", "cleve", "cleveland cuyahoga ohio", "government of cleveland ohio", "cleveland ohio u s", "un locode uscle", "rock n roll capital of world", "cleveland oh", "cleveland usa", "poznan ohio", "cleveland ohio usa"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Columbus", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:53:06.497616Z"}
{"question_id": "tqa_rc_validation_153", "question": "What is the largest city in Ohio?", "ground_truth": ["Cleveland", "The Rock 'n' Roll Capital of the World", "Cleveland, Cuyahoga, Ohio", "Cleveland, Ohio", "Clevelnad", "The Cleve", "Government of Cleveland, Ohio", "Cleveland, Ohio, US", "Cleaveland", "Urban community school", "Ohio Cleveland", "Cleveland, Ohio, USA", "Cleveland, Ohio, U.S.A.", "Cleveland, OH.", "Sixth City", "Cleveland, oh", "UN/LOCODE:USCLE", "Cleveland,ohio", "The Rock and Roll Capital of the World", "Cleveland, USA", "Poznan, Ohio", "Cleveland Ohio", "Cleveland (OH)", "Sister Cities of Cleveland, Ohio", "Cleveland, Ohio, U.S.", "Cleveland (Ohio)", "Government of Cleveland", "rock and roll capital of world", "cleveland ohio us", "sister cities of cleveland ohio", "cleve", "cleveland cuyahoga ohio", "government of cleveland ohio", "cleveland ohio u s", "un locode uscle", "rock n roll capital of world", "cleveland oh", "cleveland usa", "poznan ohio", "cleveland ohio usa"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Columbus", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:53:31.099286Z"}
{"question_id": "tqa_rc_validation_153", "question": "What is the largest city in Ohio?", "ground_truth": ["Cleveland", "The Rock 'n' Roll Capital of the World", "Cleveland, Cuyahoga, Ohio", "Cleveland, Ohio", "Clevelnad", "The Cleve", "Government of Cleveland, Ohio", "Cleveland, Ohio, US", "Cleaveland", "Urban community school", "Ohio Cleveland", "Cleveland, Ohio, USA", "Cleveland, Ohio, U.S.A.", "Cleveland, OH.", "Sixth City", "Cleveland, oh", "UN/LOCODE:USCLE", "Cleveland,ohio", "The Rock and Roll Capital of the World", "Cleveland, USA", "Poznan, Ohio", "Cleveland Ohio", "Cleveland (OH)", "Sister Cities of Cleveland, Ohio", "Cleveland, Ohio, U.S.", "Cleveland (Ohio)", "Government of Cleveland", "rock and roll capital of world", "cleveland ohio us", "sister cities of cleveland ohio", "cleve", "cleveland cuyahoga ohio", "government of cleveland ohio", "cleveland ohio u s", "un locode uscle", "rock n roll capital of world", "cleveland oh", "cleveland usa", "poznan ohio", "cleveland ohio usa"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Columbus", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:53:41.108760Z"}
{"question_id": "tqa_rc_validation_153", "question": "What is the largest city in Ohio?", "ground_truth": ["Cleveland", "The Rock 'n' Roll Capital of the World", "Cleveland, Cuyahoga, Ohio", "Cleveland, Ohio", "Clevelnad", "The Cleve", "Government of Cleveland, Ohio", "Cleveland, Ohio, US", "Cleaveland", "Urban community school", "Ohio Cleveland", "Cleveland, Ohio, USA", "Cleveland, Ohio, U.S.A.", "Cleveland, OH.", "Sixth City", "Cleveland, oh", "UN/LOCODE:USCLE", "Cleveland,ohio", "The Rock and Roll Capital of the World", "Cleveland, USA", "Poznan, Ohio", "Cleveland Ohio", "Cleveland (OH)", "Sister Cities of Cleveland, Ohio", "Cleveland, Ohio, U.S.", "Cleveland (Ohio)", "Government of Cleveland", "rock and roll capital of world", "cleveland ohio us", "sister cities of cleveland ohio", "cleve", "cleveland cuyahoga ohio", "government of cleveland ohio", "cleveland ohio u s", "un locode uscle", "rock n roll capital of world", "cleveland oh", "cleveland usa", "poznan ohio", "cleveland ohio usa"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Columbus", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:54:02.290525Z"}
{"question_id": "tqa_rc_validation_153", "question": "What is the largest city in Ohio?", "ground_truth": ["Cleveland", "The Rock 'n' Roll Capital of the World", "Cleveland, Cuyahoga, Ohio", "Cleveland, Ohio", "Clevelnad", "The Cleve", "Government of Cleveland, Ohio", "Cleveland, Ohio, US", "Cleaveland", "Urban community school", "Ohio Cleveland", "Cleveland, Ohio, USA", "Cleveland, Ohio, U.S.A.", "Cleveland, OH.", "Sixth City", "Cleveland, oh", "UN/LOCODE:USCLE", "Cleveland,ohio", "The Rock and Roll Capital of the World", "Cleveland, USA", "Poznan, Ohio", "Cleveland Ohio", "Cleveland (OH)", "Sister Cities of Cleveland, Ohio", "Cleveland, Ohio, U.S.", "Cleveland (Ohio)", "Government of Cleveland", "rock and roll capital of world", "cleveland ohio us", "sister cities of cleveland ohio", "cleve", "cleveland cuyahoga ohio", "government of cleveland ohio", "cleveland ohio u s", "un locode uscle", "rock n roll capital of world", "cleveland oh", "cleveland usa", "poznan ohio", "cleveland ohio usa"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Columbus", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus", "Columbus"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:54:18.740509Z"}
{"question_id": "tqa_rc_validation_154", "question": "In which decade of the 20th century was Anne Bancroft born?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "1930s", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:20.074669Z"}
{"question_id": "tqa_rc_validation_154", "question": "In which decade of the 20th century was Anne Bancroft born?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "1930s", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:21.946924Z"}
{"question_id": "tqa_rc_validation_154", "question": "In which decade of the 20th century was Anne Bancroft born?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "1930s", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:22.213863Z"}
{"question_id": "tqa_rc_validation_154", "question": "In which decade of the 20th century was Anne Bancroft born?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "1930s", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:23.452064Z"}
{"question_id": "tqa_rc_validation_154", "question": "In which decade of the 20th century was Anne Bancroft born?", "ground_truth": ["1930s", "1930’s", "Thirties", "1930s literature", "Nineteen-thirties", "1930–1939", "1930-1939", "'30s", "1930's", "%6030s", "1930s (decade)", "The Thirties", "30s", "nineteen thirties", "1930 1939", "1930s decade", "1930 s", "6030s"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The 1930s", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:24.346149Z"}
{"question_id": "tqa_rc_validation_155", "question": "The Suez Canal connects the Mediterranean Sea to which other Sea?", "ground_truth": ["Red sea", "Arabicus Sinus", "Sinus Arabicus", "The red sea", "ቀይሕ ባሕሪ", "Red Sea Basin", "Al Baḩr al Aḩmar", "Sea of Mecca"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Red Sea", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:25.101670Z"}
{"question_id": "tqa_rc_validation_155", "question": "The Suez Canal connects the Mediterranean Sea to which other Sea?", "ground_truth": ["Red sea", "Arabicus Sinus", "Sinus Arabicus", "The red sea", "ቀይሕ ባሕሪ", "Red Sea Basin", "Al Baḩr al Aḩmar", "Sea of Mecca"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Red Sea", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:26.288850Z"}
{"question_id": "tqa_rc_validation_155", "question": "The Suez Canal connects the Mediterranean Sea to which other Sea?", "ground_truth": ["Red sea", "Arabicus Sinus", "Sinus Arabicus", "The red sea", "ቀይሕ ባሕሪ", "Red Sea Basin", "Al Baḩr al Aḩmar", "Sea of Mecca"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Red Sea", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:26.699440Z"}
{"question_id": "tqa_rc_validation_155", "question": "The Suez Canal connects the Mediterranean Sea to which other Sea?", "ground_truth": ["Red sea", "Arabicus Sinus", "Sinus Arabicus", "The red sea", "ቀይሕ ባሕሪ", "Red Sea Basin", "Al Baḩr al Aḩmar", "Sea of Mecca"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Red Sea", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:27.940915Z"}
{"question_id": "tqa_rc_validation_155", "question": "The Suez Canal connects the Mediterranean Sea to which other Sea?", "ground_truth": ["Red sea", "Arabicus Sinus", "Sinus Arabicus", "The red sea", "ቀይሕ ባሕሪ", "Red Sea Basin", "Al Baḩr al Aḩmar", "Sea of Mecca"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Red Sea", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:54:28.621267Z"}
{"question_id": "tqa_rc_validation_156", "question": "Which rock star did Cindy Crawford name her first son after?", "ground_truth": ["Presley", "Pressley", "Pressly"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Rande Gerber", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Elvis Presley", "Rande Gerber", "Rande Gerber", "Elvis Presley", "Elvis Presley", "Elvis Presley", "Rande Gerber", "Elvis Presley", "Elvis Presley", "Rande Gerber"], "equivalence_results": ["different", "same", "same", "different", "different", "different", "same", "different", "different", "same"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:54:45.989765Z"}
{"question_id": "tqa_rc_validation_156", "question": "Which rock star did Cindy Crawford name her first son after?", "ground_truth": ["Presley", "Pressley", "Pressly"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Presley, named after Elvis Presley", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Presley, after Elvis Presley", "Presley, named after Elvis Presley", "Presley, named after Elvis Presley", "Presley, named after Elvis Presley", "Presley, named after Elvis Presley", "Presley, named after Elvis Presley", "Presley, after Elvis Presley", "Presley, named after Elvis Presley", "Presley, named after Elvis Presley", "Presley, after Elvis Presley"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:55:13.064150Z"}
{"question_id": "tqa_rc_validation_156", "question": "Which rock star did Cindy Crawford name her first son after?", "ground_truth": ["Presley", "Pressley", "Pressly"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Presley", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:13.289877Z"}
{"question_id": "tqa_rc_validation_156", "question": "Which rock star did Cindy Crawford name her first son after?", "ground_truth": ["Presley", "Pressley", "Pressly"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Presley", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:14.763200Z"}
{"question_id": "tqa_rc_validation_156", "question": "Which rock star did Cindy Crawford name her first son after?", "ground_truth": ["Presley", "Pressley", "Pressly"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Presley", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:15.636306Z"}
{"question_id": "tqa_rc_validation_157", "question": "Sun Yat Sen overthrew the emperor in which country establishing a republic after 2000 years of imperial rule?", "ground_truth": ["China", "Chinese People's Republic", "China (Peking)", "The prc", "Socialist China", "Chinese PR", "PRoC", "PRC", "China's", "P. R. of China", "People's Republic Of China", "The People's Republic of China", "Territorial disputes of China", "China PRC", "People's repuublic of china", "China (PRC)", "China (People's Republic)", "People's Republic of China (Mainland China)", "Zhonghua Renmin Gonghe Guo", "People' Republic of China", "People' s Republic of China", "P.R. of China", "China, People's Republic of", "Chung-Kuo", "P.R.C.", "Zhong Guo", "Peoples republic of China", "Red China (modern)", "Zhonghuarenmingongheguo", "State of China", "Zhonghuá rénmín gònghéguó", "中国", "P.R.China", "People's Republic or China", "Zhonghua Renmin Gongheguo", "China, the People's Republic of", "Nation of China", "People’s Republic of China", "China, PRC", "Zhōnghuá Rénmín Gònghéguó", "Modern day China", "中华", "Chaina", "Zhongguo", "Homes in china", "Zhōngguó", "Sinic", "China PR", "PRC (China)", "中國", "Jhongguó", "Red Chinese", "(The People's Republic of) China", "The People’s Republic of China", "China (Republic : 1949- )", "China People's Republic", "Pr china", "Chungkuo", "ISO 3166-1:CN", "Land of China", "P.R. China", "Zhongguó", "中华人民共和国", "PRChina", "中華", "PR of China", "中華人民共和國", "Pr of c", "Cihna", "Communist China (modern)", "P. R. China", "People's Republic of China (PRC)", "Peoples' Republic of China", "The Peoples Republic of China", "chinese people s republic", "people s republic of china", "china peking", "red china modern", "people s republic of china mainland china", "iso 3166 1 cn", "communist china modern", "p r of china", "prc china", "china republic 1949", "people s republic of china prc", "people s republic or china", "china people s republic of", "china s", "chung kuo", "p r china", "p r c", "people s repuublic of china", "china people s republic", "people republic of china"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "China", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:16.282390Z"}
{"question_id": "tqa_rc_validation_157", "question": "Sun Yat Sen overthrew the emperor in which country establishing a republic after 2000 years of imperial rule?", "ground_truth": ["China", "Chinese People's Republic", "China (Peking)", "The prc", "Socialist China", "Chinese PR", "PRoC", "PRC", "China's", "P. R. of China", "People's Republic Of China", "The People's Republic of China", "Territorial disputes of China", "China PRC", "People's repuublic of china", "China (PRC)", "China (People's Republic)", "People's Republic of China (Mainland China)", "Zhonghua Renmin Gonghe Guo", "People' Republic of China", "People' s Republic of China", "P.R. of China", "China, People's Republic of", "Chung-Kuo", "P.R.C.", "Zhong Guo", "Peoples republic of China", "Red China (modern)", "Zhonghuarenmingongheguo", "State of China", "Zhonghuá rénmín gònghéguó", "中国", "P.R.China", "People's Republic or China", "Zhonghua Renmin Gongheguo", "China, the People's Republic of", "Nation of China", "People’s Republic of China", "China, PRC", "Zhōnghuá Rénmín Gònghéguó", "Modern day China", "中华", "Chaina", "Zhongguo", "Homes in china", "Zhōngguó", "Sinic", "China PR", "PRC (China)", "中國", "Jhongguó", "Red Chinese", "(The People's Republic of) China", "The People’s Republic of China", "China (Republic : 1949- )", "China People's Republic", "Pr china", "Chungkuo", "ISO 3166-1:CN", "Land of China", "P.R. China", "Zhongguó", "中华人民共和国", "PRChina", "中華", "PR of China", "中華人民共和國", "Pr of c", "Cihna", "Communist China (modern)", "P. R. China", "People's Republic of China (PRC)", "Peoples' Republic of China", "The Peoples Republic of China", "chinese people s republic", "people s republic of china", "china peking", "red china modern", "people s republic of china mainland china", "iso 3166 1 cn", "communist china modern", "p r of china", "prc china", "china republic 1949", "people s republic of china prc", "people s republic or china", "china people s republic of", "china s", "chung kuo", "p r china", "p r c", "people s repuublic of china", "china people s republic", "people republic of china"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "China", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:18.418472Z"}
{"question_id": "tqa_rc_validation_157", "question": "Sun Yat Sen overthrew the emperor in which country establishing a republic after 2000 years of imperial rule?", "ground_truth": ["China", "Chinese People's Republic", "China (Peking)", "The prc", "Socialist China", "Chinese PR", "PRoC", "PRC", "China's", "P. R. of China", "People's Republic Of China", "The People's Republic of China", "Territorial disputes of China", "China PRC", "People's repuublic of china", "China (PRC)", "China (People's Republic)", "People's Republic of China (Mainland China)", "Zhonghua Renmin Gonghe Guo", "People' Republic of China", "People' s Republic of China", "P.R. of China", "China, People's Republic of", "Chung-Kuo", "P.R.C.", "Zhong Guo", "Peoples republic of China", "Red China (modern)", "Zhonghuarenmingongheguo", "State of China", "Zhonghuá rénmín gònghéguó", "中国", "P.R.China", "People's Republic or China", "Zhonghua Renmin Gongheguo", "China, the People's Republic of", "Nation of China", "People’s Republic of China", "China, PRC", "Zhōnghuá Rénmín Gònghéguó", "Modern day China", "中华", "Chaina", "Zhongguo", "Homes in china", "Zhōngguó", "Sinic", "China PR", "PRC (China)", "中國", "Jhongguó", "Red Chinese", "(The People's Republic of) China", "The People’s Republic of China", "China (Republic : 1949- )", "China People's Republic", "Pr china", "Chungkuo", "ISO 3166-1:CN", "Land of China", "P.R. China", "Zhongguó", "中华人民共和国", "PRChina", "中華", "PR of China", "中華人民共和國", "Pr of c", "Cihna", "Communist China (modern)", "P. R. China", "People's Republic of China (PRC)", "Peoples' Republic of China", "The Peoples Republic of China", "chinese people s republic", "people s republic of china", "china peking", "red china modern", "people s republic of china mainland china", "iso 3166 1 cn", "communist china modern", "p r of china", "prc china", "china republic 1949", "people s republic of china prc", "people s republic or china", "china people s republic of", "china s", "chung kuo", "p r china", "p r c", "people s repuublic of china", "china people s republic", "people republic of china"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "China", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:18.713754Z"}
{"question_id": "tqa_rc_validation_157", "question": "Sun Yat Sen overthrew the emperor in which country establishing a republic after 2000 years of imperial rule?", "ground_truth": ["China", "Chinese People's Republic", "China (Peking)", "The prc", "Socialist China", "Chinese PR", "PRoC", "PRC", "China's", "P. R. of China", "People's Republic Of China", "The People's Republic of China", "Territorial disputes of China", "China PRC", "People's repuublic of china", "China (PRC)", "China (People's Republic)", "People's Republic of China (Mainland China)", "Zhonghua Renmin Gonghe Guo", "People' Republic of China", "People' s Republic of China", "P.R. of China", "China, People's Republic of", "Chung-Kuo", "P.R.C.", "Zhong Guo", "Peoples republic of China", "Red China (modern)", "Zhonghuarenmingongheguo", "State of China", "Zhonghuá rénmín gònghéguó", "中国", "P.R.China", "People's Republic or China", "Zhonghua Renmin Gongheguo", "China, the People's Republic of", "Nation of China", "People’s Republic of China", "China, PRC", "Zhōnghuá Rénmín Gònghéguó", "Modern day China", "中华", "Chaina", "Zhongguo", "Homes in china", "Zhōngguó", "Sinic", "China PR", "PRC (China)", "中國", "Jhongguó", "Red Chinese", "(The People's Republic of) China", "The People’s Republic of China", "China (Republic : 1949- )", "China People's Republic", "Pr china", "Chungkuo", "ISO 3166-1:CN", "Land of China", "P.R. China", "Zhongguó", "中华人民共和国", "PRChina", "中華", "PR of China", "中華人民共和國", "Pr of c", "Cihna", "Communist China (modern)", "P. R. China", "People's Republic of China (PRC)", "Peoples' Republic of China", "The Peoples Republic of China", "chinese people s republic", "people s republic of china", "china peking", "red china modern", "people s republic of china mainland china", "iso 3166 1 cn", "communist china modern", "p r of china", "prc china", "china republic 1949", "people s republic of china prc", "people s republic or china", "china people s republic of", "china s", "chung kuo", "p r china", "p r c", "people s repuublic of china", "china people s republic", "people republic of china"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "China", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:19.813079Z"}
{"question_id": "tqa_rc_validation_157", "question": "Sun Yat Sen overthrew the emperor in which country establishing a republic after 2000 years of imperial rule?", "ground_truth": ["China", "Chinese People's Republic", "China (Peking)", "The prc", "Socialist China", "Chinese PR", "PRoC", "PRC", "China's", "P. R. of China", "People's Republic Of China", "The People's Republic of China", "Territorial disputes of China", "China PRC", "People's repuublic of china", "China (PRC)", "China (People's Republic)", "People's Republic of China (Mainland China)", "Zhonghua Renmin Gonghe Guo", "People' Republic of China", "People' s Republic of China", "P.R. of China", "China, People's Republic of", "Chung-Kuo", "P.R.C.", "Zhong Guo", "Peoples republic of China", "Red China (modern)", "Zhonghuarenmingongheguo", "State of China", "Zhonghuá rénmín gònghéguó", "中国", "P.R.China", "People's Republic or China", "Zhonghua Renmin Gongheguo", "China, the People's Republic of", "Nation of China", "People’s Republic of China", "China, PRC", "Zhōnghuá Rénmín Gònghéguó", "Modern day China", "中华", "Chaina", "Zhongguo", "Homes in china", "Zhōngguó", "Sinic", "China PR", "PRC (China)", "中國", "Jhongguó", "Red Chinese", "(The People's Republic of) China", "The People’s Republic of China", "China (Republic : 1949- )", "China People's Republic", "Pr china", "Chungkuo", "ISO 3166-1:CN", "Land of China", "P.R. China", "Zhongguó", "中华人民共和国", "PRChina", "中華", "PR of China", "中華人民共和國", "Pr of c", "Cihna", "Communist China (modern)", "P. R. China", "People's Republic of China (PRC)", "Peoples' Republic of China", "The Peoples Republic of China", "chinese people s republic", "people s republic of china", "china peking", "red china modern", "people s republic of china mainland china", "iso 3166 1 cn", "communist china modern", "p r of china", "prc china", "china republic 1949", "people s republic of china prc", "people s republic or china", "china people s republic of", "china s", "chung kuo", "p r china", "p r c", "people s repuublic of china", "china people s republic", "people republic of china"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "China", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:20.594177Z"}
{"question_id": "tqa_rc_validation_158", "question": "Who designed the dress which made the most at Diana's dress auction?", "ground_truth": ["Victor Edelstein"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Victor Edelstein", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:21.502565Z"}
{"question_id": "tqa_rc_validation_158", "question": "Who designed the dress which made the most at Diana's dress auction?", "ground_truth": ["Victor Edelstein"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Victor Edelstein", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:22.412430Z"}
{"question_id": "tqa_rc_validation_158", "question": "Who designed the dress which made the most at Diana's dress auction?", "ground_truth": ["Victor Edelstein"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "John Galliano", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Christina Stambolian", "Catherine Walker", "Catherine Walker", "John Galliano", "Catherine Walker", "Catherine Walker", "Catherine Walker", "Catherine Walker", "Catherine Walker", "Catherine Walker"], "equivalence_results": ["different", "different", "different", "same", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 1, "num_different": 9, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.1, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:55:33.559802Z"}
{"question_id": "tqa_rc_validation_158", "question": "Who designed the dress which made the most at Diana's dress auction?", "ground_truth": ["Victor Edelstein"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Catherine Walker", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Victor Edelstein", "Catherine Walker", "Catherine Walker", "Catherine Walker", "Catherine Walker", "Catherine Walker", "Catherine Walker", "Catherine Walker", "Catherine Walker", "Catherine Walker"], "equivalence_results": ["different", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:55:55.199756Z"}
{"question_id": "tqa_rc_validation_158", "question": "Who designed the dress which made the most at Diana's dress auction?", "ground_truth": ["Victor Edelstein"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Victor Edelstein", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:56.093301Z"}
{"question_id": "tqa_rc_validation_159", "question": "Which Palestinian co-founded al Fatah in 1957?", "ground_truth": ["Yasser Arafat", "Yasir Arafat", "Yasir 'Arafat", "Jassir Arafat", "Abu Ammar", "Yasser 'Arafat", "محمد عبد الرحمن عبد الرؤوف عرفات القدوة الحسيني", "Abū %60ammār", "Mohammed Abdel Rahman Abdel Raouf Arafat Al Qudua Al Husseini", "Yaser Arafat", "Mohammed Abdel Rahman Abdel Raouf Arafat al-Qudwa al-Husseini", "Ashraf al-Kurdi", "Muhammad Abd ar-Rauf al-Qudwah al-Husayni", "Abu Amar", "Mohammed Abdel-Raouf Arafat As Qudwa al-Hussaeini", "Death of yasser arafat", "Yasser Arafet", "Yassir Arafat", "Death of Arafat", "Muhammed al-Qudwa al-Husseini", "Yasir Arafat (Disambiguation)", "Illness of Yasser Arafat", "Yassar Arafat", "yasir arafat disambiguation", "abū 60ammār", "muhammed al qudwa al husseini", "ashraf al kurdi", "muhammad abd ar rauf al qudwah al husayni", "mohammed abdel raouf arafat as qudwa al hussaeini", "mohammed abdel rahman abdel raouf arafat al qudwa al husseini"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Yasser Arafat", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:56.929406Z"}
{"question_id": "tqa_rc_validation_159", "question": "Which Palestinian co-founded al Fatah in 1957?", "ground_truth": ["Yasser Arafat", "Yasir Arafat", "Yasir 'Arafat", "Jassir Arafat", "Abu Ammar", "Yasser 'Arafat", "محمد عبد الرحمن عبد الرؤوف عرفات القدوة الحسيني", "Abū %60ammār", "Mohammed Abdel Rahman Abdel Raouf Arafat Al Qudua Al Husseini", "Yaser Arafat", "Mohammed Abdel Rahman Abdel Raouf Arafat al-Qudwa al-Husseini", "Ashraf al-Kurdi", "Muhammad Abd ar-Rauf al-Qudwah al-Husayni", "Abu Amar", "Mohammed Abdel-Raouf Arafat As Qudwa al-Hussaeini", "Death of yasser arafat", "Yasser Arafet", "Yassir Arafat", "Death of Arafat", "Muhammed al-Qudwa al-Husseini", "Yasir Arafat (Disambiguation)", "Illness of Yasser Arafat", "Yassar Arafat", "yasir arafat disambiguation", "abū 60ammār", "muhammed al qudwa al husseini", "ashraf al kurdi", "muhammad abd ar rauf al qudwah al husayni", "mohammed abdel raouf arafat as qudwa al hussaeini", "mohammed abdel rahman abdel raouf arafat al qudwa al husseini"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Yasser Arafat", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:58.665545Z"}
{"question_id": "tqa_rc_validation_159", "question": "Which Palestinian co-founded al Fatah in 1957?", "ground_truth": ["Yasser Arafat", "Yasir Arafat", "Yasir 'Arafat", "Jassir Arafat", "Abu Ammar", "Yasser 'Arafat", "محمد عبد الرحمن عبد الرؤوف عرفات القدوة الحسيني", "Abū %60ammār", "Mohammed Abdel Rahman Abdel Raouf Arafat Al Qudua Al Husseini", "Yaser Arafat", "Mohammed Abdel Rahman Abdel Raouf Arafat al-Qudwa al-Husseini", "Ashraf al-Kurdi", "Muhammad Abd ar-Rauf al-Qudwah al-Husayni", "Abu Amar", "Mohammed Abdel-Raouf Arafat As Qudwa al-Hussaeini", "Death of yasser arafat", "Yasser Arafet", "Yassir Arafat", "Death of Arafat", "Muhammed al-Qudwa al-Husseini", "Yasir Arafat (Disambiguation)", "Illness of Yasser Arafat", "Yassar Arafat", "yasir arafat disambiguation", "abū 60ammār", "muhammed al qudwa al husseini", "ashraf al kurdi", "muhammad abd ar rauf al qudwah al husayni", "mohammed abdel raouf arafat as qudwa al hussaeini", "mohammed abdel rahman abdel raouf arafat al qudwa al husseini"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Yasser Arafat", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:55:58.949067Z"}
{"question_id": "tqa_rc_validation_159", "question": "Which Palestinian co-founded al Fatah in 1957?", "ground_truth": ["Yasser Arafat", "Yasir Arafat", "Yasir 'Arafat", "Jassir Arafat", "Abu Ammar", "Yasser 'Arafat", "محمد عبد الرحمن عبد الرؤوف عرفات القدوة الحسيني", "Abū %60ammār", "Mohammed Abdel Rahman Abdel Raouf Arafat Al Qudua Al Husseini", "Yaser Arafat", "Mohammed Abdel Rahman Abdel Raouf Arafat al-Qudwa al-Husseini", "Ashraf al-Kurdi", "Muhammad Abd ar-Rauf al-Qudwah al-Husayni", "Abu Amar", "Mohammed Abdel-Raouf Arafat As Qudwa al-Hussaeini", "Death of yasser arafat", "Yasser Arafet", "Yassir Arafat", "Death of Arafat", "Muhammed al-Qudwa al-Husseini", "Yasir Arafat (Disambiguation)", "Illness of Yasser Arafat", "Yassar Arafat", "yasir arafat disambiguation", "abū 60ammār", "muhammed al qudwa al husseini", "ashraf al kurdi", "muhammad abd ar rauf al qudwah al husayni", "mohammed abdel raouf arafat as qudwa al hussaeini", "mohammed abdel rahman abdel raouf arafat al qudwa al husseini"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Yasser Arafat", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:56:00.230256Z"}
{"question_id": "tqa_rc_validation_159", "question": "Which Palestinian co-founded al Fatah in 1957?", "ground_truth": ["Yasser Arafat", "Yasir Arafat", "Yasir 'Arafat", "Jassir Arafat", "Abu Ammar", "Yasser 'Arafat", "محمد عبد الرحمن عبد الرؤوف عرفات القدوة الحسيني", "Abū %60ammār", "Mohammed Abdel Rahman Abdel Raouf Arafat Al Qudua Al Husseini", "Yaser Arafat", "Mohammed Abdel Rahman Abdel Raouf Arafat al-Qudwa al-Husseini", "Ashraf al-Kurdi", "Muhammad Abd ar-Rauf al-Qudwah al-Husayni", "Abu Amar", "Mohammed Abdel-Raouf Arafat As Qudwa al-Hussaeini", "Death of yasser arafat", "Yasser Arafet", "Yassir Arafat", "Death of Arafat", "Muhammed al-Qudwa al-Husseini", "Yasir Arafat (Disambiguation)", "Illness of Yasser Arafat", "Yassar Arafat", "yasir arafat disambiguation", "abū 60ammār", "muhammed al qudwa al husseini", "ashraf al kurdi", "muhammad abd ar rauf al qudwah al husayni", "mohammed abdel raouf arafat as qudwa al hussaeini", "mohammed abdel rahman abdel raouf arafat al qudwa al husseini"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Yasser Arafat", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:56:00.945914Z"}
{"question_id": "tqa_rc_validation_160", "question": "In which country was Earl Spencer's acrimonious divorce settlement heard?", "ground_truth": ["South Africa", "South Africa's", "Southafrica", "Third Republic (South Africa)", "Republiek van Suid-Afrika", "Sou'frica", "Zuid Afrika", "Zuid-Afrika", "ISO 3166-1:ZA", "South-African", "S Africa", "Zuid Africa", "Mzansi", "Afrique du sud", "Zuidafrika", "Ningizimu Afrika", "Capital of South Africa", "Suid-Afrika", "South-Africa", "Rep. of SOUTH AFRICA", "The Republic of South Africa", "Suid Africa", "Azania/South Africa", "S Afr", "Saffa", "South African", "Seth efrika", "Soufrica", "Republic of south africa", "South Africaà", "The Beloved Country", "S. Africa", "South Africans", "azania south africa", "south africa s", "third republic south africa", "sou frica", "iso 3166 1 za", "suid afrika", "rep of south africa", "beloved country", "republiek van suid afrika"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "France", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["France", "France", "France", "France", "France", "France", "France", "France", "Scotland", "France"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "different", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:56:18.561748Z"}
{"question_id": "tqa_rc_validation_160", "question": "In which country was Earl Spencer's acrimonious divorce settlement heard?", "ground_truth": ["South Africa", "South Africa's", "Southafrica", "Third Republic (South Africa)", "Republiek van Suid-Afrika", "Sou'frica", "Zuid Afrika", "Zuid-Afrika", "ISO 3166-1:ZA", "South-African", "S Africa", "Zuid Africa", "Mzansi", "Afrique du sud", "Zuidafrika", "Ningizimu Afrika", "Capital of South Africa", "Suid-Afrika", "South-Africa", "Rep. of SOUTH AFRICA", "The Republic of South Africa", "Suid Africa", "Azania/South Africa", "S Afr", "Saffa", "South African", "Seth efrika", "Soufrica", "Republic of south africa", "South Africaà", "The Beloved Country", "S. Africa", "South Africans", "azania south africa", "south africa s", "third republic south africa", "sou frica", "iso 3166 1 za", "suid afrika", "rep of south africa", "beloved country", "republiek van suid afrika"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "South Africa", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:56:20.271363Z"}
{"question_id": "tqa_rc_validation_160", "question": "In which country was Earl Spencer's acrimonious divorce settlement heard?", "ground_truth": ["South Africa", "South Africa's", "Southafrica", "Third Republic (South Africa)", "Republiek van Suid-Afrika", "Sou'frica", "Zuid Afrika", "Zuid-Afrika", "ISO 3166-1:ZA", "South-African", "S Africa", "Zuid Africa", "Mzansi", "Afrique du sud", "Zuidafrika", "Ningizimu Afrika", "Capital of South Africa", "Suid-Afrika", "South-Africa", "Rep. of SOUTH AFRICA", "The Republic of South Africa", "Suid Africa", "Azania/South Africa", "S Afr", "Saffa", "South African", "Seth efrika", "Soufrica", "Republic of south africa", "South Africaà", "The Beloved Country", "S. Africa", "South Africans", "azania south africa", "south africa s", "third republic south africa", "sou frica", "iso 3166 1 za", "suid afrika", "rep of south africa", "beloved country", "republiek van suid afrika"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "South Africa", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:56:20.495085Z"}
{"question_id": "tqa_rc_validation_160", "question": "In which country was Earl Spencer's acrimonious divorce settlement heard?", "ground_truth": ["South Africa", "South Africa's", "Southafrica", "Third Republic (South Africa)", "Republiek van Suid-Afrika", "Sou'frica", "Zuid Afrika", "Zuid-Afrika", "ISO 3166-1:ZA", "South-African", "S Africa", "Zuid Africa", "Mzansi", "Afrique du sud", "Zuidafrika", "Ningizimu Afrika", "Capital of South Africa", "Suid-Afrika", "South-Africa", "Rep. of SOUTH AFRICA", "The Republic of South Africa", "Suid Africa", "Azania/South Africa", "S Afr", "Saffa", "South African", "Seth efrika", "Soufrica", "Republic of south africa", "South Africaà", "The Beloved Country", "S. Africa", "South Africans", "azania south africa", "south africa s", "third republic south africa", "sou frica", "iso 3166 1 za", "suid afrika", "rep of south africa", "beloved country", "republiek van suid afrika"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "England", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["England", "England", "England", "England", "England", "England", "England", "England", "England", "England"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:56:42.410332Z"}
{"question_id": "tqa_rc_validation_160", "question": "In which country was Earl Spencer's acrimonious divorce settlement heard?", "ground_truth": ["South Africa", "South Africa's", "Southafrica", "Third Republic (South Africa)", "Republiek van Suid-Afrika", "Sou'frica", "Zuid Afrika", "Zuid-Afrika", "ISO 3166-1:ZA", "South-African", "S Africa", "Zuid Africa", "Mzansi", "Afrique du sud", "Zuidafrika", "Ningizimu Afrika", "Capital of South Africa", "Suid-Afrika", "South-Africa", "Rep. of SOUTH AFRICA", "The Republic of South Africa", "Suid Africa", "Azania/South Africa", "S Afr", "Saffa", "South African", "Seth efrika", "Soufrica", "Republic of south africa", "South Africaà", "The Beloved Country", "S. Africa", "South Africans", "azania south africa", "south africa s", "third republic south africa", "sou frica", "iso 3166 1 za", "suid afrika", "rep of south africa", "beloved country", "republiek van suid afrika"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "England", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["United Kingdom", "Ireland", "England", "United Kingdom", "England", "United Kingdom", "United Kingdom", "England", "The United Kingdom", "Ireland"], "equivalence_results": ["different", "different", "same", "different", "same", "different", "different", "same", "different", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:56:58.697207Z"}
{"question_id": "tqa_rc_validation_161", "question": "In which North African country was Mohammed Al-Fayed, owner of Harrods department store in London, born?", "ground_truth": ["Egypt", "EGY", "Arab Republic of Egypt", "A .R . EGYPT", "The Arab Republic of Egypt", "Eygpt", "Etymology of Egypt", "مصر", "Kemmet", "Gift of the Nile", "Names of Egypt", "Miṣr", "Eytp", "National identity of Egyptians", "Jumhuriyat Misr al'Arabiyah", "Eypt", "Egyptian Republic", "Ejipt", "Name of Egypt", "Egipto", "Kimet", "جمهوريّة مصرالعربيّة", "Egypte", "Egypt (name)", "جمهورية مصرالعربية", "A.R. Egypt", "Republic of Eygpt", "Égypte", "Second Egyptian Republic", "Egipt", "ISO 3166-1:EG", "Egypt info", "jumhuriyat misr al arabiyah", "iso 3166 1 eg", "r egypt", "egypt name", "gift of nile"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Egypt", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:56:59.603335Z"}
{"question_id": "tqa_rc_validation_161", "question": "In which North African country was Mohammed Al-Fayed, owner of Harrods department store in London, born?", "ground_truth": ["Egypt", "EGY", "Arab Republic of Egypt", "A .R . EGYPT", "The Arab Republic of Egypt", "Eygpt", "Etymology of Egypt", "مصر", "Kemmet", "Gift of the Nile", "Names of Egypt", "Miṣr", "Eytp", "National identity of Egyptians", "Jumhuriyat Misr al'Arabiyah", "Eypt", "Egyptian Republic", "Ejipt", "Name of Egypt", "Egipto", "Kimet", "جمهوريّة مصرالعربيّة", "Egypte", "Egypt (name)", "جمهورية مصرالعربية", "A.R. Egypt", "Republic of Eygpt", "Égypte", "Second Egyptian Republic", "Egipt", "ISO 3166-1:EG", "Egypt info", "jumhuriyat misr al arabiyah", "iso 3166 1 eg", "r egypt", "egypt name", "gift of nile"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Egypt", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:01.090689Z"}
{"question_id": "tqa_rc_validation_161", "question": "In which North African country was Mohammed Al-Fayed, owner of Harrods department store in London, born?", "ground_truth": ["Egypt", "EGY", "Arab Republic of Egypt", "A .R . EGYPT", "The Arab Republic of Egypt", "Eygpt", "Etymology of Egypt", "مصر", "Kemmet", "Gift of the Nile", "Names of Egypt", "Miṣr", "Eytp", "National identity of Egyptians", "Jumhuriyat Misr al'Arabiyah", "Eypt", "Egyptian Republic", "Ejipt", "Name of Egypt", "Egipto", "Kimet", "جمهوريّة مصرالعربيّة", "Egypte", "Egypt (name)", "جمهورية مصرالعربية", "A.R. Egypt", "Republic of Eygpt", "Égypte", "Second Egyptian Republic", "Egipt", "ISO 3166-1:EG", "Egypt info", "jumhuriyat misr al arabiyah", "iso 3166 1 eg", "r egypt", "egypt name", "gift of nile"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Egypt", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:01.375146Z"}
{"question_id": "tqa_rc_validation_161", "question": "In which North African country was Mohammed Al-Fayed, owner of Harrods department store in London, born?", "ground_truth": ["Egypt", "EGY", "Arab Republic of Egypt", "A .R . EGYPT", "The Arab Republic of Egypt", "Eygpt", "Etymology of Egypt", "مصر", "Kemmet", "Gift of the Nile", "Names of Egypt", "Miṣr", "Eytp", "National identity of Egyptians", "Jumhuriyat Misr al'Arabiyah", "Eypt", "Egyptian Republic", "Ejipt", "Name of Egypt", "Egipto", "Kimet", "جمهوريّة مصرالعربيّة", "Egypte", "Egypt (name)", "جمهورية مصرالعربية", "A.R. Egypt", "Republic of Eygpt", "Égypte", "Second Egyptian Republic", "Egipt", "ISO 3166-1:EG", "Egypt info", "jumhuriyat misr al arabiyah", "iso 3166 1 eg", "r egypt", "egypt name", "gift of nile"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Egypt", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:02.682915Z"}
{"question_id": "tqa_rc_validation_161", "question": "In which North African country was Mohammed Al-Fayed, owner of Harrods department store in London, born?", "ground_truth": ["Egypt", "EGY", "Arab Republic of Egypt", "A .R . EGYPT", "The Arab Republic of Egypt", "Eygpt", "Etymology of Egypt", "مصر", "Kemmet", "Gift of the Nile", "Names of Egypt", "Miṣr", "Eytp", "National identity of Egyptians", "Jumhuriyat Misr al'Arabiyah", "Eypt", "Egyptian Republic", "Ejipt", "Name of Egypt", "Egipto", "Kimet", "جمهوريّة مصرالعربيّة", "Egypte", "Egypt (name)", "جمهورية مصرالعربية", "A.R. Egypt", "Republic of Eygpt", "Égypte", "Second Egyptian Republic", "Egipt", "ISO 3166-1:EG", "Egypt info", "jumhuriyat misr al arabiyah", "iso 3166 1 eg", "r egypt", "egypt name", "gift of nile"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Egypt", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:03.388614Z"}
{"question_id": "tqa_rc_validation_162", "question": "Aung San Suu Kyi is a controversial leader in which country?", "ground_truth": ["Myanmar", "Economic sanctions against Myanmar", "Economic sanctions against Burma", "ISO 3166-1:MM", "Birman Empire", "Etymology of Burma", "Republic of The Union of Myanmar", "Pyidaunzu Thanmăda Myăma Nainngandaw", "Mianmar", "Borders of Burma", "Myanmar (Burma)", "Mayanmar", "မြန်မာပြည်", "Pyi-daung-zu Myan-ma Naing-ngan-daw", "Myammar", "Burma/Myanmar", "Burmese Republic", "Burma-Myanmar", "Burma (Myanmar)", "Union of Myanmar", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော်", "Sanctions against Burma", "Myanmar (formerly Burma)", "Birma", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော", "Birmanie", "Myanmar/(Burma)", "Burma", "Myanmar/Burma", "Myanmer", "Socialist Republic of the Union of Burma", "Eastern Burma", "Union of burma", "Myanma", "Birmania", "myanmar formerly burma", "republic of union of myanmar", "myanmar burma", "socialist republic of union of burma", "iso 3166 1 mm", "pyi daung zu myan ma naing ngan daw", "burma myanmar"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Myanmar", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:04.730864Z"}
{"question_id": "tqa_rc_validation_162", "question": "Aung San Suu Kyi is a controversial leader in which country?", "ground_truth": ["Myanmar", "Economic sanctions against Myanmar", "Economic sanctions against Burma", "ISO 3166-1:MM", "Birman Empire", "Etymology of Burma", "Republic of The Union of Myanmar", "Pyidaunzu Thanmăda Myăma Nainngandaw", "Mianmar", "Borders of Burma", "Myanmar (Burma)", "Mayanmar", "မြန်မာပြည်", "Pyi-daung-zu Myan-ma Naing-ngan-daw", "Myammar", "Burma/Myanmar", "Burmese Republic", "Burma-Myanmar", "Burma (Myanmar)", "Union of Myanmar", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော်", "Sanctions against Burma", "Myanmar (formerly Burma)", "Birma", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော", "Birmanie", "Myanmar/(Burma)", "Burma", "Myanmar/Burma", "Myanmer", "Socialist Republic of the Union of Burma", "Eastern Burma", "Union of burma", "Myanma", "Birmania", "myanmar formerly burma", "republic of union of myanmar", "myanmar burma", "socialist republic of union of burma", "iso 3166 1 mm", "pyi daung zu myan ma naing ngan daw", "burma myanmar"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Myanmar", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:06.320554Z"}
{"question_id": "tqa_rc_validation_162", "question": "Aung San Suu Kyi is a controversial leader in which country?", "ground_truth": ["Myanmar", "Economic sanctions against Myanmar", "Economic sanctions against Burma", "ISO 3166-1:MM", "Birman Empire", "Etymology of Burma", "Republic of The Union of Myanmar", "Pyidaunzu Thanmăda Myăma Nainngandaw", "Mianmar", "Borders of Burma", "Myanmar (Burma)", "Mayanmar", "မြန်မာပြည်", "Pyi-daung-zu Myan-ma Naing-ngan-daw", "Myammar", "Burma/Myanmar", "Burmese Republic", "Burma-Myanmar", "Burma (Myanmar)", "Union of Myanmar", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော်", "Sanctions against Burma", "Myanmar (formerly Burma)", "Birma", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော", "Birmanie", "Myanmar/(Burma)", "Burma", "Myanmar/Burma", "Myanmer", "Socialist Republic of the Union of Burma", "Eastern Burma", "Union of burma", "Myanma", "Birmania", "myanmar formerly burma", "republic of union of myanmar", "myanmar burma", "socialist republic of union of burma", "iso 3166 1 mm", "pyi daung zu myan ma naing ngan daw", "burma myanmar"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Myanmar", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:06.559737Z"}
{"question_id": "tqa_rc_validation_162", "question": "Aung San Suu Kyi is a controversial leader in which country?", "ground_truth": ["Myanmar", "Economic sanctions against Myanmar", "Economic sanctions against Burma", "ISO 3166-1:MM", "Birman Empire", "Etymology of Burma", "Republic of The Union of Myanmar", "Pyidaunzu Thanmăda Myăma Nainngandaw", "Mianmar", "Borders of Burma", "Myanmar (Burma)", "Mayanmar", "မြန်မာပြည်", "Pyi-daung-zu Myan-ma Naing-ngan-daw", "Myammar", "Burma/Myanmar", "Burmese Republic", "Burma-Myanmar", "Burma (Myanmar)", "Union of Myanmar", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော်", "Sanctions against Burma", "Myanmar (formerly Burma)", "Birma", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော", "Birmanie", "Myanmar/(Burma)", "Burma", "Myanmar/Burma", "Myanmer", "Socialist Republic of the Union of Burma", "Eastern Burma", "Union of burma", "Myanma", "Birmania", "myanmar formerly burma", "republic of union of myanmar", "myanmar burma", "socialist republic of union of burma", "iso 3166 1 mm", "pyi daung zu myan ma naing ngan daw", "burma myanmar"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Myanmar", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:07.642820Z"}
{"question_id": "tqa_rc_validation_162", "question": "Aung San Suu Kyi is a controversial leader in which country?", "ground_truth": ["Myanmar", "Economic sanctions against Myanmar", "Economic sanctions against Burma", "ISO 3166-1:MM", "Birman Empire", "Etymology of Burma", "Republic of The Union of Myanmar", "Pyidaunzu Thanmăda Myăma Nainngandaw", "Mianmar", "Borders of Burma", "Myanmar (Burma)", "Mayanmar", "မြန်မာပြည်", "Pyi-daung-zu Myan-ma Naing-ngan-daw", "Myammar", "Burma/Myanmar", "Burmese Republic", "Burma-Myanmar", "Burma (Myanmar)", "Union of Myanmar", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော်", "Sanctions against Burma", "Myanmar (formerly Burma)", "Birma", "ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော", "Birmanie", "Myanmar/(Burma)", "Burma", "Myanmar/Burma", "Myanmer", "Socialist Republic of the Union of Burma", "Eastern Burma", "Union of burma", "Myanma", "Birmania", "myanmar formerly burma", "republic of union of myanmar", "myanmar burma", "socialist republic of union of burma", "iso 3166 1 mm", "pyi daung zu myan ma naing ngan daw", "burma myanmar"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Myanmar (Burma)", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:08.336810Z"}
{"question_id": "tqa_rc_validation_163", "question": "Which of the founders of United Artists had the last name nearest the beginning of the alphabet?", "ground_truth": ["Chaplin", "Chaplin (disambiguation)", "Chaplin (musical)", "chaplin disambiguation", "chaplin musical"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Charlie Chaplin", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:09.165680Z"}
{"question_id": "tqa_rc_validation_163", "question": "Which of the founders of United Artists had the last name nearest the beginning of the alphabet?", "ground_truth": ["Chaplin", "Chaplin (disambiguation)", "Chaplin (musical)", "chaplin disambiguation", "chaplin musical"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Chaplin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:10.712684Z"}
{"question_id": "tqa_rc_validation_163", "question": "Which of the founders of United Artists had the last name nearest the beginning of the alphabet?", "ground_truth": ["Chaplin", "Chaplin (disambiguation)", "Chaplin (musical)", "chaplin disambiguation", "chaplin musical"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Chaplin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:10.892712Z"}
{"question_id": "tqa_rc_validation_163", "question": "Which of the founders of United Artists had the last name nearest the beginning of the alphabet?", "ground_truth": ["Chaplin", "Chaplin (disambiguation)", "Chaplin (musical)", "chaplin disambiguation", "chaplin musical"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Chaplin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:11.883614Z"}
{"question_id": "tqa_rc_validation_163", "question": "Which of the founders of United Artists had the last name nearest the beginning of the alphabet?", "ground_truth": ["Chaplin", "Chaplin (disambiguation)", "Chaplin (musical)", "chaplin disambiguation", "chaplin musical"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "D", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Charles Chaplin", "D", "Dwan", "Charlie Chaplin", "D", "Chaplin", "Charles Chaplin", "D", "D", "D"], "equivalence_results": ["different", "same", "different", "different", "same", "different", "different", "same", "same", "same"], "equivalence_stats": {"num_same": 5, "num_different": 5, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.5, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:57:27.878106Z"}
{"question_id": "tqa_rc_validation_164", "question": "In La Cage Aux Folles, what was La Cage Aux Folles?", "ground_truth": ["Nightclub", "Discotheque", "Night clubs", "Diskotek", "Dance club", "Clubbers", "Night club", "Discothèque", "Nightclubs", "Clubber", "Theque", "Discoteck", "Discotech", "Discothèques", "Clubgoer", "Nightclub culture", "List of nightclubs", "Discoteque", "Discotheques", "Discothek", "History of discotheques", "Disco Bar", "Dance clubs", "Disco pub", "Discotek", "Discotheke", "Club scene", "Night-club", "Club night", "History of nightclubs"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "A Saint-Tropez nightclub featuring drag performances", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["A Saint-Tropez drag nightclub run by Georges and Albin", "A Saint-Tropez nightclub featuring a drag floor show", "A nightclub featuring drag performances", "A Saint-Tropez nightclub featuring drag performances", "A Saint-Tropez nightclub featuring drag performances", "A Saint-Tropez nightclub featuring a drag cabaret act", "A Saint-Tropez nightclub featuring drag performances", "A Saint-Tropez nightclub featuring drag performances", "A Saint-Tropez nightclub featuring drag performances", "A nightclub in Saint-Tropez featuring drag performers"], "equivalence_results": ["different", "same", "different", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:57:46.606399Z"}
{"question_id": "tqa_rc_validation_164", "question": "In La Cage Aux Folles, what was La Cage Aux Folles?", "ground_truth": ["Nightclub", "Discotheque", "Night clubs", "Diskotek", "Dance club", "Clubbers", "Night club", "Discothèque", "Nightclubs", "Clubber", "Theque", "Discoteck", "Discotech", "Discothèques", "Clubgoer", "Nightclub culture", "List of nightclubs", "Discoteque", "Discotheques", "Discothek", "History of discotheques", "Disco Bar", "Dance clubs", "Disco pub", "Discotek", "Discotheke", "Club scene", "Night-club", "Club night", "History of nightclubs"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "A nightclub", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:47.580036Z"}
{"question_id": "tqa_rc_validation_164", "question": "In La Cage Aux Folles, what was La Cage Aux Folles?", "ground_truth": ["Nightclub", "Discotheque", "Night clubs", "Diskotek", "Dance club", "Clubbers", "Night club", "Discothèque", "Nightclubs", "Clubber", "Theque", "Discoteck", "Discotech", "Discothèques", "Clubgoer", "Nightclub culture", "List of nightclubs", "Discoteque", "Discotheques", "Discothek", "History of discotheques", "Disco Bar", "Dance clubs", "Disco pub", "Discotek", "Discotheke", "Club scene", "Night-club", "Club night", "History of nightclubs"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "A drag nightclub", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:47.915540Z"}
{"question_id": "tqa_rc_validation_164", "question": "In La Cage Aux Folles, what was La Cage Aux Folles?", "ground_truth": ["Nightclub", "Discotheque", "Night clubs", "Diskotek", "Dance club", "Clubbers", "Night club", "Discothèque", "Nightclubs", "Clubber", "Theque", "Discoteck", "Discotech", "Discothèques", "Clubgoer", "Nightclub culture", "List of nightclubs", "Discoteque", "Discotheques", "Discothek", "History of discotheques", "Disco Bar", "Dance clubs", "Disco pub", "Discotek", "Discotheke", "Club scene", "Night-club", "Club night", "History of nightclubs"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "A nightclub", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:49.092016Z"}
{"question_id": "tqa_rc_validation_164", "question": "In La Cage Aux Folles, what was La Cage Aux Folles?", "ground_truth": ["Nightclub", "Discotheque", "Night clubs", "Diskotek", "Dance club", "Clubbers", "Night club", "Discothèque", "Nightclubs", "Clubber", "Theque", "Discoteck", "Discotech", "Discothèques", "Clubgoer", "Nightclub culture", "List of nightclubs", "Discoteque", "Discotheques", "Discothek", "History of discotheques", "Disco Bar", "Dance clubs", "Disco pub", "Discotek", "Discotheke", "Club scene", "Night-club", "Club night", "History of nightclubs"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "A nightclub", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:49.936363Z"}
{"question_id": "tqa_rc_validation_165", "question": "Where was the Fiddler in the musical's title?", "ground_truth": ["On the Roof", "Sur les toits (cambrioleurs et gendarmes)", "Sur les toits", "On the Roofs", "on roof", "sur les toits cambrioleurs et gendarmes", "on roofs"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "On the roof", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:50.827442Z"}
{"question_id": "tqa_rc_validation_165", "question": "Where was the Fiddler in the musical's title?", "ground_truth": ["On the Roof", "Sur les toits (cambrioleurs et gendarmes)", "Sur les toits", "On the Roofs", "on roof", "sur les toits cambrioleurs et gendarmes", "on roofs"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "On the Roof", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:52.577522Z"}
{"question_id": "tqa_rc_validation_165", "question": "Where was the Fiddler in the musical's title?", "ground_truth": ["On the Roof", "Sur les toits (cambrioleurs et gendarmes)", "Sur les toits", "On the Roofs", "on roof", "sur les toits cambrioleurs et gendarmes", "on roofs"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "On the roof", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:52.799833Z"}
{"question_id": "tqa_rc_validation_165", "question": "Where was the Fiddler in the musical's title?", "ground_truth": ["On the Roof", "Sur les toits (cambrioleurs et gendarmes)", "Sur les toits", "On the Roofs", "on roof", "sur les toits cambrioleurs et gendarmes", "on roofs"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "On the roof", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:57:54.078939Z"}
{"question_id": "tqa_rc_validation_6", "question": "What was the last US state to reintroduce alcohol after prohibition?", "ground_truth": ["Utah", "Utah (State)", "Forty-Fifth State", "Sports in Utah", "Climate of Utah", "Education in Utah", "UT (state)", "Utahn", "Yutas", "Geography of Utah", "Utah, United States", "Utah state nickname", "History of mining in Utah", "State of Utah", "Religion in Utah", "Utah (U.S. state)", "Transportation in Utah", "Beehive State", "US-UT", "Utahan", "Politics of Utah", "Salt Lake Seagulls", "45th State", "History of Utah (to 1847)", "The Beehive State", "Youtah", "Transport in Utah", "utah united states", "us ut", "utah state", "forty fifth state", "ut state", "history of utah to 1847", "utah u s state"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Mississippi (in 1966)", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)", "Mississippi (in 1966)"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:58:04.869854Z"}
{"question_id": "tqa_rc_validation_165", "question": "Where was the Fiddler in the musical's title?", "ground_truth": ["On the Roof", "Sur les toits (cambrioleurs et gendarmes)", "Sur les toits", "On the Roofs", "on roof", "sur les toits cambrioleurs et gendarmes", "on roofs"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "In the violinist's seat", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["On the Roof", "On the Roof", "In the violin section of the orchestra at the opera house", "The title \"Fiddler on the Roof\" refers to the violinist in the classic Russian Jewish folktale, \"If I Were a Fiddler on the Roof\", whose character would stand on the roof and play a fiddle", "On the Roof", "In the violinist's seat", "In the violinist's seat on the stage", "A fiddle player on the roof of the village in Anatevka", "In the violinist's orchestra pit", "In the violinist's seat"], "equivalence_results": ["different", "different", "different", "different", "different", "same", "different", "different", "different", "same"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:58:11.165730Z"}
{"question_id": "tqa_rc_validation_166", "question": "South Pacific was set during which war?", "ground_truth": ["WWII", "The Second world war", "WorldWar2", "WW2", "Second World war", "War World Two", "World War II", "Second Great War", "The 2nd World War", "WW-II", "2nd world war", "World War two", "The second great war", "World war 2", "The Origins and Commencement of World War II", "World War ll", "WW II", "World-War II", "W.W.2", "WarII", "War World II", "War World 2", "World War II countries and Leaders", "Countries in the Second World War", "Second World War: The History and the Events", "Ww2'", "Nazi occupation", "World War, 1939-1945", "Second World Wars", "WWTWO", "II World War", "W.W. II", "World War Ⅱ", "WW-2", "2w2", "IIWW", "W.W.II", "World War II/Infobox", "Segunda Guerra Mundial", "WW 2", "WW@", "Word war II", "Guerre mondiale II", "World War II/Edited Text", "world war ii infobox", "world war 1939 1945", "second world war history and events", "countries in second world war", "origins and commencement of world war ii", "ww", "w w 2", "w w ii", "world war ii edited text"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "World War II", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:58:12.012812Z"}
{"question_id": "tqa_rc_validation_166", "question": "South Pacific was set during which war?", "ground_truth": ["WWII", "The Second world war", "WorldWar2", "WW2", "Second World war", "War World Two", "World War II", "Second Great War", "The 2nd World War", "WW-II", "2nd world war", "World War two", "The second great war", "World war 2", "The Origins and Commencement of World War II", "World War ll", "WW II", "World-War II", "W.W.2", "WarII", "War World II", "War World 2", "World War II countries and Leaders", "Countries in the Second World War", "Second World War: The History and the Events", "Ww2'", "Nazi occupation", "World War, 1939-1945", "Second World Wars", "WWTWO", "II World War", "W.W. II", "World War Ⅱ", "WW-2", "2w2", "IIWW", "W.W.II", "World War II/Infobox", "Segunda Guerra Mundial", "WW 2", "WW@", "Word war II", "Guerre mondiale II", "World War II/Edited Text", "world war ii infobox", "world war 1939 1945", "second world war history and events", "countries in second world war", "origins and commencement of world war ii", "ww", "w w 2", "w w ii", "world war ii edited text"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "World War II", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:58:13.718751Z"}
{"question_id": "tqa_rc_validation_166", "question": "South Pacific was set during which war?", "ground_truth": ["WWII", "The Second world war", "WorldWar2", "WW2", "Second World war", "War World Two", "World War II", "Second Great War", "The 2nd World War", "WW-II", "2nd world war", "World War two", "The second great war", "World war 2", "The Origins and Commencement of World War II", "World War ll", "WW II", "World-War II", "W.W.2", "WarII", "War World II", "War World 2", "World War II countries and Leaders", "Countries in the Second World War", "Second World War: The History and the Events", "Ww2'", "Nazi occupation", "World War, 1939-1945", "Second World Wars", "WWTWO", "II World War", "W.W. II", "World War Ⅱ", "WW-2", "2w2", "IIWW", "W.W.II", "World War II/Infobox", "Segunda Guerra Mundial", "WW 2", "WW@", "Word war II", "Guerre mondiale II", "World War II/Edited Text", "world war ii infobox", "world war 1939 1945", "second world war history and events", "countries in second world war", "origins and commencement of world war ii", "ww", "w w 2", "w w ii", "world war ii edited text"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "World War II", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:58:14.181155Z"}
{"question_id": "tqa_rc_validation_166", "question": "South Pacific was set during which war?", "ground_truth": ["WWII", "The Second world war", "WorldWar2", "WW2", "Second World war", "War World Two", "World War II", "Second Great War", "The 2nd World War", "WW-II", "2nd world war", "World War two", "The second great war", "World war 2", "The Origins and Commencement of World War II", "World War ll", "WW II", "World-War II", "W.W.2", "WarII", "War World II", "War World 2", "World War II countries and Leaders", "Countries in the Second World War", "Second World War: The History and the Events", "Ww2'", "Nazi occupation", "World War, 1939-1945", "Second World Wars", "WWTWO", "II World War", "W.W. II", "World War Ⅱ", "WW-2", "2w2", "IIWW", "W.W.II", "World War II/Infobox", "Segunda Guerra Mundial", "WW 2", "WW@", "Word war II", "Guerre mondiale II", "World War II/Edited Text", "world war ii infobox", "world war 1939 1945", "second world war history and events", "countries in second world war", "origins and commencement of world war ii", "ww", "w w 2", "w w ii", "world war ii edited text"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "World War II", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:58:15.327596Z"}
{"question_id": "tqa_rc_validation_166", "question": "South Pacific was set during which war?", "ground_truth": ["WWII", "The Second world war", "WorldWar2", "WW2", "Second World war", "War World Two", "World War II", "Second Great War", "The 2nd World War", "WW-II", "2nd world war", "World War two", "The second great war", "World war 2", "The Origins and Commencement of World War II", "World War ll", "WW II", "World-War II", "W.W.2", "WarII", "War World II", "War World 2", "World War II countries and Leaders", "Countries in the Second World War", "Second World War: The History and the Events", "Ww2'", "Nazi occupation", "World War, 1939-1945", "Second World Wars", "WWTWO", "II World War", "W.W. II", "World War Ⅱ", "WW-2", "2w2", "IIWW", "W.W.II", "World War II/Infobox", "Segunda Guerra Mundial", "WW 2", "WW@", "Word war II", "Guerre mondiale II", "World War II/Edited Text", "world war ii infobox", "world war 1939 1945", "second world war history and events", "countries in second world war", "origins and commencement of world war ii", "ww", "w w 2", "w w ii", "world war ii edited text"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "World War II", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:58:16.160770Z"}
{"question_id": "tqa_rc_validation_167", "question": "What percentage of the earth's surface is covered by Europe?", "ground_truth": ["8%", "eight  %", "8 %", "8", "eight"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "About 2%", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["About 2%", "About 2%", "About 2%", "About 2%", "About 2%", "About 2%", "About 2%", "About 2%", "About 2%", "About 2%"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:58:38.407293Z"}
{"question_id": "tqa_rc_validation_167", "question": "What percentage of the earth's surface is covered by Europe?", "ground_truth": ["8%", "eight  %", "8 %", "8", "eight"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "2%", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["2%", "2%", "2%", "2%", "2%", "2%", "2%", "2%", "2%", "2%"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:59:05.836646Z"}
{"question_id": "tqa_rc_validation_167", "question": "What percentage of the earth's surface is covered by Europe?", "ground_truth": ["8%", "eight  %", "8 %", "8", "eight"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "7%", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["6", "7%", "7%", "7%", "6", "7%", "7%", "7%", "7%", "6"], "equivalence_results": ["different", "same", "same", "same", "different", "same", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:59:17.133296Z"}
{"question_id": "tqa_rc_validation_167", "question": "What percentage of the earth's surface is covered by Europe?", "ground_truth": ["8%", "eight  %", "8 %", "8", "eight"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "9", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["9", "9", "9", "9", "9", "9", "9", "9", "9", "9"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T03:59:39.194720Z"}
{"question_id": "tqa_rc_validation_167", "question": "What percentage of the earth's surface is covered by Europe?", "ground_truth": ["8%", "eight  %", "8 %", "8", "eight"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "7%", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Approximately 6", "7", "8%", "7%", "7%", "5", "About 6", "7", "7%", "About 6"], "equivalence_results": ["unclear", "same", "different", "same", "same", "different", "different", "same", "same", "different"], "equivalence_stats": {"num_same": 5, "num_different": 4, "num_unclear": 1, "total": 10}, "equivalence_ratio": 0.5555555555555556, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T03:59:55.732167Z"}
{"question_id": "tqa_rc_validation_168", "question": "Which European town gave its name to a Treaty which symbolizes closer economic links between European countries?", "ground_truth": ["Maastricht", "Maastricht, the Netherlands", "Maasthrict", "Mestreech", "Mastericht", "Maestricht", "Maastrict", "Maastricht, Netherlands", "Vrijthof", "UN/LOCODE:NLMST", "Limmel", "maastricht netherlands", "un locode nlmst"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Maastricht", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:59:56.507947Z"}
{"question_id": "tqa_rc_validation_168", "question": "Which European town gave its name to a Treaty which symbolizes closer economic links between European countries?", "ground_truth": ["Maastricht", "Maastricht, the Netherlands", "Maasthrict", "Mestreech", "Mastericht", "Maestricht", "Maastrict", "Maastricht, Netherlands", "Vrijthof", "UN/LOCODE:NLMST", "Limmel", "maastricht netherlands", "un locode nlmst"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Maastricht", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:59:58.125982Z"}
{"question_id": "tqa_rc_validation_168", "question": "Which European town gave its name to a Treaty which symbolizes closer economic links between European countries?", "ground_truth": ["Maastricht", "Maastricht, the Netherlands", "Maasthrict", "Mestreech", "Mastericht", "Maestricht", "Maastrict", "Maastricht, Netherlands", "Vrijthof", "UN/LOCODE:NLMST", "Limmel", "maastricht netherlands", "un locode nlmst"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Maastricht", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:59:58.696197Z"}
{"question_id": "tqa_rc_validation_168", "question": "Which European town gave its name to a Treaty which symbolizes closer economic links between European countries?", "ground_truth": ["Maastricht", "Maastricht, the Netherlands", "Maasthrict", "Mestreech", "Mastericht", "Maestricht", "Maastrict", "Maastricht, Netherlands", "Vrijthof", "UN/LOCODE:NLMST", "Limmel", "maastricht netherlands", "un locode nlmst"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Maastricht", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T03:59:59.827827Z"}
{"question_id": "tqa_rc_validation_168", "question": "Which European town gave its name to a Treaty which symbolizes closer economic links between European countries?", "ground_truth": ["Maastricht", "Maastricht, the Netherlands", "Maasthrict", "Mestreech", "Mastericht", "Maestricht", "Maastrict", "Maastricht, Netherlands", "Vrijthof", "UN/LOCODE:NLMST", "Limmel", "maastricht netherlands", "un locode nlmst"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Maastricht", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:00:00.697817Z"}
{"question_id": "tqa_rc_validation_169", "question": "Which home of champagne in France was also where the German High Command surrendered in WWII?", "ground_truth": ["Reims", "Reims, France", "Saint Remi Basilica", "Rheims", "Rheims, France", "Durocortorum", "Saint-Remi Cathedral", "rheims france", "reims france", "saint remi cathedral"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Reims", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:00:01.523690Z"}
{"question_id": "tqa_rc_validation_169", "question": "Which home of champagne in France was also where the German High Command surrendered in WWII?", "ground_truth": ["Reims", "Reims, France", "Saint Remi Basilica", "Rheims", "Rheims, France", "Durocortorum", "Saint-Remi Cathedral", "rheims france", "reims france", "saint remi cathedral"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Reims", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:00:03.091324Z"}
{"question_id": "tqa_rc_validation_169", "question": "Which home of champagne in France was also where the German High Command surrendered in WWII?", "ground_truth": ["Reims", "Reims, France", "Saint Remi Basilica", "Rheims", "Rheims, France", "Durocortorum", "Saint-Remi Cathedral", "rheims france", "reims france", "saint remi cathedral"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Reims", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:00:03.395797Z"}
{"question_id": "tqa_rc_validation_169", "question": "Which home of champagne in France was also where the German High Command surrendered in WWII?", "ground_truth": ["Reims", "Reims, France", "Saint Remi Basilica", "Rheims", "Rheims, France", "Durocortorum", "Saint-Remi Cathedral", "rheims france", "reims france", "saint remi cathedral"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Reims", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:00:04.527872Z"}
{"question_id": "tqa_rc_validation_169", "question": "Which home of champagne in France was also where the German High Command surrendered in WWII?", "ground_truth": ["Reims", "Reims, France", "Saint Remi Basilica", "Rheims", "Rheims, France", "Durocortorum", "Saint-Remi Cathedral", "rheims france", "reims france", "saint remi cathedral"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "the Hotel Drouot, however, that is not correct either", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Hall of Mirrors at the Palace of Versailles", "The Ritz Hotel in Paris was not the answer however a similar answer to this was that the Ritz in Paris is not the answer the answer to this is actually the Hotel Châtelaine in Paris was not it", "The Hall of Mirrors in the Palace of Versailles", "The Château de Rethondes", "The Supreme Headquarters Allied Expeditionary Force (SHAEF) in Versailles, near Paris, and more specifically, the SHAEF headquarters was located in the Château de Rastignac, which is in the countryside near Vichy", "The home of champagne in France where the German High Command surrendered in WWII is Reims", "The Supreme Headquarters Allied Expeditionary Force (SHAEF) was located at the U", "Fermont or Rethondes are often mentioned in this context but most notably  The place often mentioned is  FERDINAND CASTELNau's  FERMONT CHÂTEAU, and also the  COMPIÈ", "The Kremlin in Compiègne", "The Hall of Mirrors in the Palace of Versailles"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:00:24.918712Z"}
{"question_id": "tqa_rc_validation_170", "question": "Which was the first European city this century to open an underground railway system?", "ground_truth": ["Paris", "Paříž", "FRPAR", "Name of paris and its inhabitants", "Paname", "Paris France", "Ville Lumière", "Leucetia", "Rue de Ménilmontant", "Paris agglomeration", "France Paris", "Sports in Paris", "Departement de Paris", "Paris, Ile-De-France", "Rue de Menilmontant", "UN/LOCODE:FRPAR", "Paříži", "Ville Lumiere", "Paris, France", "Paris, Île-de-France", "Paris, Île-de-France, France", "Parijs", "Parisien", "Cuisine of Paris", "Suburbs of Paris", "Sport in Paris", "The weather in Paris", "Parisian (person)", "Parizi", "París", "Paree", "Paris, Europe", "Paris, Banks of the Seine", "Paris (etymology)", "Paris (France)", "The City of Love (city)", "Département de Paris", "paris europe", "paris etymology", "city of love city", "paris île de france", "paris ile de france", "parisian person", "paris banks of seine", "weather in paris", "paris île de france france", "un locode frpar"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Budapest", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:00:42.130926Z"}
{"question_id": "tqa_rc_validation_170", "question": "Which was the first European city this century to open an underground railway system?", "ground_truth": ["Paris", "Paříž", "FRPAR", "Name of paris and its inhabitants", "Paname", "Paris France", "Ville Lumière", "Leucetia", "Rue de Ménilmontant", "Paris agglomeration", "France Paris", "Sports in Paris", "Departement de Paris", "Paris, Ile-De-France", "Rue de Menilmontant", "UN/LOCODE:FRPAR", "Paříži", "Ville Lumiere", "Paris, France", "Paris, Île-de-France", "Paris, Île-de-France, France", "Parijs", "Parisien", "Cuisine of Paris", "Suburbs of Paris", "Sport in Paris", "The weather in Paris", "Parisian (person)", "Parizi", "París", "Paree", "Paris, Europe", "Paris, Banks of the Seine", "Paris (etymology)", "Paris (France)", "The City of Love (city)", "Département de Paris", "paris europe", "paris etymology", "city of love city", "paris île de france", "paris ile de france", "parisian person", "paris banks of seine", "weather in paris", "paris île de france france", "un locode frpar"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Budapest", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:01:05.328456Z"}
{"question_id": "tqa_rc_validation_170", "question": "Which was the first European city this century to open an underground railway system?", "ground_truth": ["Paris", "Paříž", "FRPAR", "Name of paris and its inhabitants", "Paname", "Paris France", "Ville Lumière", "Leucetia", "Rue de Ménilmontant", "Paris agglomeration", "France Paris", "Sports in Paris", "Departement de Paris", "Paris, Ile-De-France", "Rue de Menilmontant", "UN/LOCODE:FRPAR", "Paříži", "Ville Lumiere", "Paris, France", "Paris, Île-de-France", "Paris, Île-de-France, France", "Parijs", "Parisien", "Cuisine of Paris", "Suburbs of Paris", "Sport in Paris", "The weather in Paris", "Parisian (person)", "Parizi", "París", "Paree", "Paris, Europe", "Paris, Banks of the Seine", "Paris (etymology)", "Paris (France)", "The City of Love (city)", "Département de Paris", "paris europe", "paris etymology", "city of love city", "paris île de france", "paris ile de france", "parisian person", "paris banks of seine", "weather in paris", "paris île de france france", "un locode frpar"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "London", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["London", "London", "London", "London", "London", "London", "London", "London", "London", "London"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:01:17.001561Z"}
{"question_id": "tqa_rc_validation_170", "question": "Which was the first European city this century to open an underground railway system?", "ground_truth": ["Paris", "Paříž", "FRPAR", "Name of paris and its inhabitants", "Paname", "Paris France", "Ville Lumière", "Leucetia", "Rue de Ménilmontant", "Paris agglomeration", "France Paris", "Sports in Paris", "Departement de Paris", "Paris, Ile-De-France", "Rue de Menilmontant", "UN/LOCODE:FRPAR", "Paříži", "Ville Lumiere", "Paris, France", "Paris, Île-de-France", "Paris, Île-de-France, France", "Parijs", "Parisien", "Cuisine of Paris", "Suburbs of Paris", "Sport in Paris", "The weather in Paris", "Parisian (person)", "Parizi", "París", "Paree", "Paris, Europe", "Paris, Banks of the Seine", "Paris (etymology)", "Paris (France)", "The City of Love (city)", "Département de Paris", "paris europe", "paris etymology", "city of love city", "paris île de france", "paris ile de france", "parisian person", "paris banks of seine", "weather in paris", "paris île de france france", "un locode frpar"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Budapest", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest", "Budapest"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:01:38.120301Z"}
{"question_id": "tqa_rc_validation_170", "question": "Which was the first European city this century to open an underground railway system?", "ground_truth": ["Paris", "Paříž", "FRPAR", "Name of paris and its inhabitants", "Paname", "Paris France", "Ville Lumière", "Leucetia", "Rue de Ménilmontant", "Paris agglomeration", "France Paris", "Sports in Paris", "Departement de Paris", "Paris, Ile-De-France", "Rue de Menilmontant", "UN/LOCODE:FRPAR", "Paříži", "Ville Lumiere", "Paris, France", "Paris, Île-de-France", "Paris, Île-de-France, France", "Parijs", "Parisien", "Cuisine of Paris", "Suburbs of Paris", "Sport in Paris", "The weather in Paris", "Parisian (person)", "Parizi", "París", "Paree", "Paris, Europe", "Paris, Banks of the Seine", "Paris (etymology)", "Paris (France)", "The City of Love (city)", "Département de Paris", "paris europe", "paris etymology", "city of love city", "paris île de france", "paris ile de france", "parisian person", "paris banks of seine", "weather in paris", "paris île de france france", "un locode frpar"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "I'm not aware of any information about the first European city to open an underground railway system this century", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["I'm not sure what you're referring to as \"this century", "I'm not aware of any information about the first European city to open an underground railway system this century", "I don't have the specific information to answer this question", "Birmingham", "Thessaloniki, Greece (not a European city per se, but on the European side of the continent), and the first European city to open one in this century was Bucharest, Romania", "I'm not aware of any information about the first European city to open an underground railway system this century", "Nottingham", "Bucharest, Romania in 1999", "I'm sorry but I do not have information on the first European city to open an underground railway system this century", "Paris"], "equivalence_results": ["different", "same", "same", "different", "different", "same", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:01:55.987184Z"}
{"question_id": "tqa_rc_validation_171", "question": "Who first drew Mickey Mouse when ?Disney first supplied the voice?", "ground_truth": ["Ub Iwerks", "Iwerks, Ub", "Ub Iwerks Studio", "Celebrity Productions", "Ubbe Ert Iwwerks", "iwerks ub"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Ub Iwerks, in 1928", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:01:57.022303Z"}
{"question_id": "tqa_rc_validation_171", "question": "Who first drew Mickey Mouse when ?Disney first supplied the voice?", "ground_truth": ["Ub Iwerks", "Iwerks, Ub", "Ub Iwerks Studio", "Celebrity Productions", "Ubbe Ert Iwwerks", "iwerks ub"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Ub Iwerks", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:01:59.149205Z"}
{"question_id": "tqa_rc_validation_171", "question": "Who first drew Mickey Mouse when ?Disney first supplied the voice?", "ground_truth": ["Ub Iwerks", "Iwerks, Ub", "Ub Iwerks Studio", "Celebrity Productions", "Ubbe Ert Iwwerks", "iwerks ub"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Walt Disney drew Mickey Mouse and also first supplied the voice", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Walt Disney drew Mickey Mouse and also first supplied the voice", "Walt Disney drew Mickey Mouse and also initially provided the voice", "Walt Disney drew Mickey Mouse and also first supplied the voice", "Walt Disney drew Mickey Mouse and also first supplied the voice", "Walt Disney drew Mickey Mouse and also first supplied the voice", "Walt Disney drew Mickey Mouse and also first supplied the voice in 1928 for the cartoon short \"Steamboat Willie\"", "Walt Disney first supplied the voice, Ub Iwerks drew the character", "Walt Disney drew Mickey Mouse and also initially provided the voice", "Walt Disney drew Mickey Mouse and also first supplied the voice", "Walt Disney first supplied the voice and Ub Iwerks drew Mickey Mouse"], "equivalence_results": ["same", "same", "same", "same", "same", "different", "different", "same", "same", "different"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:02:10.037014Z"}
{"question_id": "tqa_rc_validation_171", "question": "Who first drew Mickey Mouse when ?Disney first supplied the voice?", "ground_truth": ["Ub Iwerks", "Iwerks, Ub", "Ub Iwerks Studio", "Celebrity Productions", "Ubbe Ert Iwwerks", "iwerks ub"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Walt Disney", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Walt Disney", "Walt Disney", "Walt Disney", "Walt Disney", "Walt Disney", "Walt Disney", "Walt Disney", "Walt Disney", "Walt Disney", "Walt Disney"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:02:32.033535Z"}
{"question_id": "tqa_rc_validation_171", "question": "Who first drew Mickey Mouse when ?Disney first supplied the voice?", "ground_truth": ["Ub Iwerks", "Iwerks, Ub", "Ub Iwerks Studio", "Celebrity Productions", "Ubbe Ert Iwwerks", "iwerks ub"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Ub Iwerks first drew Mickey Mouse in 1928", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["I couldn't find any information regarding the person who first drew Mickey Mouse when Disney first supplied the voice", "Walt Disney first drew Mickey Mouse in 1928", "There is not enough information provided", "I couldn't find any information that matches your question", "Walt Disney first drew Mickey Mouse in 1928", "There is no information on who first drew Mickey Mouse while Disney first supplied the voice", "Ferdinand Horvath", "Walt Disney first drew Mickey Mouse in 1928", "Walt Disney first drew Mickey Mouse in 1928", "Ub Iwerks first drew Mickey Mouse in 1928"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "same"], "equivalence_stats": {"num_same": 1, "num_different": 9, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.1, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:02:54.083172Z"}
{"question_id": "tqa_rc_validation_172", "question": "Which actress wrote the novel The Last of the Really Great Whangdoodles?", "ground_truth": ["Julie Andrews", "Julia Elizabeth Wells", "Julie Elizabeth Andrews, DBE", "Julie Andrews Edwards", "Julie Wells", "Julie Elizabeth Wells", "Julie Elizabeth Andrews", "Dame Julie Andrews", "Julie Elizabeth Andrews DBE"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Julie Andrews", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:02:54.930751Z"}
{"question_id": "tqa_rc_validation_172", "question": "Which actress wrote the novel The Last of the Really Great Whangdoodles?", "ground_truth": ["Julie Andrews", "Julia Elizabeth Wells", "Julie Elizabeth Andrews, DBE", "Julie Andrews Edwards", "Julie Wells", "Julie Elizabeth Wells", "Julie Elizabeth Andrews", "Dame Julie Andrews", "Julie Elizabeth Andrews DBE"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Julie Andrews", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:02:55.910409Z"}
{"question_id": "tqa_rc_validation_172", "question": "Which actress wrote the novel The Last of the Really Great Whangdoodles?", "ground_truth": ["Julie Andrews", "Julia Elizabeth Wells", "Julie Elizabeth Andrews, DBE", "Julie Andrews Edwards", "Julie Wells", "Julie Elizabeth Wells", "Julie Elizabeth Andrews", "Dame Julie Andrews", "Julie Elizabeth Andrews DBE"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Julie Andrews", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:02:56.270236Z"}
{"question_id": "tqa_rc_validation_172", "question": "Which actress wrote the novel The Last of the Really Great Whangdoodles?", "ground_truth": ["Julie Andrews", "Julia Elizabeth Wells", "Julie Elizabeth Andrews, DBE", "Julie Andrews Edwards", "Julie Wells", "Julie Elizabeth Wells", "Julie Elizabeth Andrews", "Dame Julie Andrews", "Julie Elizabeth Andrews DBE"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Julie Andrews", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:02:57.647271Z"}
{"question_id": "tqa_rc_validation_172", "question": "Which actress wrote the novel The Last of the Really Great Whangdoodles?", "ground_truth": ["Julie Andrews", "Julia Elizabeth Wells", "Julie Elizabeth Andrews, DBE", "Julie Andrews Edwards", "Julie Wells", "Julie Elizabeth Wells", "Julie Elizabeth Andrews", "Dame Julie Andrews", "Julie Elizabeth Andrews DBE"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Julie Andrews", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:02:58.390187Z"}
{"question_id": "tqa_rc_validation_173", "question": "Who was the star of the film based on the record Harper Valley PTA by Jeannie C Riley?", "ground_truth": ["Barbara Eden", "Barbara Morehead", "Barbara Jean Morehead"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Barbara Eden", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:02:59.275300Z"}
{"question_id": "tqa_rc_validation_173", "question": "Who was the star of the film based on the record Harper Valley PTA by Jeannie C Riley?", "ground_truth": ["Barbara Eden", "Barbara Morehead", "Barbara Jean Morehead"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Barbara Eden", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:03:00.129805Z"}
{"question_id": "tqa_rc_validation_173", "question": "Who was the star of the film based on the record Harper Valley PTA by Jeannie C Riley?", "ground_truth": ["Barbara Eden", "Barbara Morehead", "Barbara Jean Morehead"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Barbara Eden", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:03:00.371710Z"}
{"question_id": "tqa_rc_validation_173", "question": "Who was the star of the film based on the record Harper Valley PTA by Jeannie C Riley?", "ground_truth": ["Barbara Eden", "Barbara Morehead", "Barbara Jean Morehead"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Barbara Eden", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:03:01.526090Z"}
{"question_id": "tqa_rc_validation_173", "question": "Who was the star of the film based on the record Harper Valley PTA by Jeannie C Riley?", "ground_truth": ["Barbara Eden", "Barbara Morehead", "Barbara Jean Morehead"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Shirley Jones", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Sharon Gless", "Shelley Winters", "Shirley Jones", "Grease's Olivia Newton-John starred in the film 'Grease 2' and also the film 'Xanadu', however the actual film you are referring to is the film 'Harper Valley PTA: The Movie', and the star", "Shirley Jones was not in the film, however;  the film was actually called Harper Valley PTA (TV movie 1978) and starred Barbara Eden", "Shirley Jones starred in the film 'Harper Valley PTA'", "Shelley Duvall starred in the 1978 film 'Harper Valley PTA'", "Shirley Jones starred in the film \"The Harper Valley PTA\" based on the song", "Shirley Jones starred in the 1978 film 'Harper Valley PTA'", "Shirley Jones"], "equivalence_results": ["different", "different", "same", "unclear", "different", "same", "different", "same", "same", "same"], "equivalence_stats": {"num_same": 5, "num_different": 4, "num_unclear": 1, "total": 10}, "equivalence_ratio": 0.5555555555555556, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:03:27.377431Z"}
{"question_id": "tqa_rc_validation_174", "question": "What color golf balls are used on the golf course in Antarctica?", "ground_truth": ["Orange", "Orange (album)", "Orangeishness", "Orange (film)", "Orangishness", "Orangeishly", "Orangishly", "Oranfe", "Orange (disambiguation)", "orange disambiguation", "orange album", "orange film"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Orange", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:03:28.238860Z"}
{"question_id": "tqa_rc_validation_174", "question": "What color golf balls are used on the golf course in Antarctica?", "ground_truth": ["Orange", "Orange (album)", "Orangeishness", "Orange (film)", "Orangishness", "Orangeishly", "Orangishly", "Oranfe", "Orange (disambiguation)", "orange disambiguation", "orange album", "orange film"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Orange", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:03:29.993251Z"}
{"question_id": "tqa_rc_validation_174", "question": "What color golf balls are used on the golf course in Antarctica?", "ground_truth": ["Orange", "Orange (album)", "Orangeishness", "Orange (film)", "Orangishness", "Orangeishly", "Orangishly", "Oranfe", "Orange (disambiguation)", "orange disambiguation", "orange album", "orange film"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Yellow", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Red or brightly colored to be visible against the snowy background", "Yellow", "Yellow or brightly colored balls, typically yellow", "Yellow or orange, but typically yellow, to increase visibility in the snowy conditions", "Yellow or brightly colored balls, typically yellow", "Yellow", "Red or brightly colored", "Yellow", "Red or bright colors", "Yellow"], "equivalence_results": ["different", "same", "same", "different", "same", "same", "different", "same", "different", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:03:41.448080Z"}
{"question_id": "tqa_rc_validation_174", "question": "What color golf balls are used on the golf course in Antarctica?", "ground_truth": ["Orange", "Orange (album)", "Orangeishness", "Orange (film)", "Orangishness", "Orangeishly", "Orangishly", "Oranfe", "Orange (disambiguation)", "orange disambiguation", "orange album", "orange film"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Orange", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:03:42.668012Z"}
{"question_id": "tqa_rc_validation_174", "question": "What color golf balls are used on the golf course in Antarctica?", "ground_truth": ["Orange", "Orange (album)", "Orangeishness", "Orange (film)", "Orangishness", "Orangeishly", "Orangishly", "Oranfe", "Orange (disambiguation)", "orange disambiguation", "orange album", "orange film"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "There is no official information on the color of golf balls used on golf courses in Antarctica, as there are no permanent golf courses in Antarctica", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["There is no official information on the specific color of golf balls used on golf courses in Antarctica", "There is no definitive answer as information on the color of golf balls used in Antarctica is not widely documented", "There is no specific information about the color of golf balls used on the golf course in Antarctica", "There is no official golf course in Antarctica", "They are yellow", "There are no official golf courses in Antarctica, so there is no specified color of golf balls used there", "There is no official golf course in Antarctica", "There is no official golf course in Antarctica, so no specific color golf balls are used there", "There is no official information available on the color of golf balls used in Antarctica", "There are no golf courses in Antarctica"], "equivalence_results": ["different", "different", "different", "same", "different", "same", "same", "same", "different", "different"], "equivalence_stats": {"num_same": 4, "num_different": 6, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.4, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:04:00.436768Z"}
{"question_id": "tqa_rc_validation_175", "question": "Throughout the 80s and 90s Phil Collins recorded on which record label?", "ground_truth": ["Atlantic", "Sea of Atlas", "The Pond", "Ethiopic Ocean", "Across the pond", "North Atlantic", "The Atlantic Ocean", "North Atlantic ocean", "Northern Atlantic", "Altantic Ocean", "Atlantis Thalassa", "Atlantic basic", "Atlantic basin", "Atlantic Oceans", "Occidental Ocean", "Ethiopian Ocean", "North Atlantic fisheries", "North-East Atlantic", "Atlantic ocean", "Atlantic (ocean)", "Antlantic Ocean", "South Atlantic Ocean", "Oceanvs Occidentalis", "Central Atlantic", "South Atlantic", "East Atlantic", "Atlantic coast", "north east atlantic", "across pond", "pond"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Atlantic Records", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:01.187952Z"}
{"question_id": "tqa_rc_validation_175", "question": "Throughout the 80s and 90s Phil Collins recorded on which record label?", "ground_truth": ["Atlantic", "Sea of Atlas", "The Pond", "Ethiopic Ocean", "Across the pond", "North Atlantic", "The Atlantic Ocean", "North Atlantic ocean", "Northern Atlantic", "Altantic Ocean", "Atlantis Thalassa", "Atlantic basic", "Atlantic basin", "Atlantic Oceans", "Occidental Ocean", "Ethiopian Ocean", "North Atlantic fisheries", "North-East Atlantic", "Atlantic ocean", "Atlantic (ocean)", "Antlantic Ocean", "South Atlantic Ocean", "Oceanvs Occidentalis", "Central Atlantic", "South Atlantic", "East Atlantic", "Atlantic coast", "north east atlantic", "across pond", "pond"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Atlantic Records", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:02.611461Z"}
{"question_id": "tqa_rc_validation_175", "question": "Throughout the 80s and 90s Phil Collins recorded on which record label?", "ground_truth": ["Atlantic", "Sea of Atlas", "The Pond", "Ethiopic Ocean", "Across the pond", "North Atlantic", "The Atlantic Ocean", "North Atlantic ocean", "Northern Atlantic", "Altantic Ocean", "Atlantis Thalassa", "Atlantic basic", "Atlantic basin", "Atlantic Oceans", "Occidental Ocean", "Ethiopian Ocean", "North Atlantic fisheries", "North-East Atlantic", "Atlantic ocean", "Atlantic (ocean)", "Antlantic Ocean", "South Atlantic Ocean", "Oceanvs Occidentalis", "Central Atlantic", "South Atlantic", "East Atlantic", "Atlantic coast", "north east atlantic", "across pond", "pond"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Atlantic Records in the US and Virgin Records in the UK, but more specifically for his solo work, he was signed to Virgin Records in the UK and Atlantic Records in the US, however his solo work was released on Virgin in the UK and Atlantic in", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Atlantic Records in the US and Virgin Records in the UK and Europe, but his main label was Virgin Records in the UK and Atlantic Records for the US, however his worldwide label was Virgin (outside the US) and Atlantic (in the US), though", "Virgin Records", "Atlantic Records in the US and Virgin Records in the UK", "Atlantic Records in the US and Virgin Records in the UK, but his main label was Virgin Records", "Atlantic Records in the US and Virgin Records in the UK and other parts of Europe, but more specifically for his solo work, he was signed to Virgin Records (in the UK) and Atlantic Records (in the US), however his most commonly associated label", "Atlantic Records in the US and Virgin Records in the UK, but primarily with Atlantic in the US and Virgin in some other countries, however mainly with Virgin Records outside of the US", "Atlantic Records in the US and Virgin Records in the UK and Europe, but his main label was Virgin Records in the UK and Atlantic Records for the US", "Virgin Records", "Virgin Records", "Atlantic Records in the US and Virgin Records in the UK (for his solo work), while still being a part of Genesis which was signed to Atlantic Records in the US and Charisma/Virgin in the UK"], "equivalence_results": ["same", "different", "same", "same", "same", "same", "same", "different", "different", "same"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:04:15.023559Z"}
{"question_id": "tqa_rc_validation_175", "question": "Throughout the 80s and 90s Phil Collins recorded on which record label?", "ground_truth": ["Atlantic", "Sea of Atlas", "The Pond", "Ethiopic Ocean", "Across the pond", "North Atlantic", "The Atlantic Ocean", "North Atlantic ocean", "Northern Atlantic", "Altantic Ocean", "Atlantis Thalassa", "Atlantic basic", "Atlantic basin", "Atlantic Oceans", "Occidental Ocean", "Ethiopian Ocean", "North Atlantic fisheries", "North-East Atlantic", "Atlantic ocean", "Atlantic (ocean)", "Antlantic Ocean", "South Atlantic Ocean", "Oceanvs Occidentalis", "Central Atlantic", "South Atlantic", "East Atlantic", "Atlantic coast", "north east atlantic", "across pond", "pond"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Atlantic Records", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:16.282413Z"}
{"question_id": "tqa_rc_validation_175", "question": "Throughout the 80s and 90s Phil Collins recorded on which record label?", "ground_truth": ["Atlantic", "Sea of Atlas", "The Pond", "Ethiopic Ocean", "Across the pond", "North Atlantic", "The Atlantic Ocean", "North Atlantic ocean", "Northern Atlantic", "Altantic Ocean", "Atlantis Thalassa", "Atlantic basic", "Atlantic basin", "Atlantic Oceans", "Occidental Ocean", "Ethiopian Ocean", "North Atlantic fisheries", "North-East Atlantic", "Atlantic ocean", "Atlantic (ocean)", "Antlantic Ocean", "South Atlantic Ocean", "Oceanvs Occidentalis", "Central Atlantic", "South Atlantic", "East Atlantic", "Atlantic coast", "north east atlantic", "across pond", "pond"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Atlantic Records and then Virgin Records, but most notably Atlantic Records and then Virgin Records for the US and Atlantic Records for the UK", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Virgin Records and Atlantic Records, and then later Columbia Records and also Arista Records", "Virgin Records, then Atlantic Records, and later Weberman's Atlantic Records successor Arista Records'  and then finally Atlantic and then Virgin", "Virgin Records and Atlantic Records (then a subsidiary of Warner Music Group)", "Virgin Records and Atlantic Records", "Atlantic Records, but also Virgin Records and also Columbia Records but mainly Atlantic and also Virgin and mainly also Atlantic and Virgin's former owner Charisma Records  also Atlantic but  mainly Atlantic and also Virgin", "Virgin Records and Atlantic Records", "Virgin Records and Atlantic Records", "Atlantic Records, however it is more commonly known that Phil Collins recorded on Atlantic's subsidiary label, Atlantic's sister label as well as Virgin Records and also Atlantic Records's subsidiary label Atlantic's sister label's subsidiary label Atlantic subsidiary label's subsidiary label Atlantic's", "Atlantic Records and then Virgin Records", "Virgin Records and Atlantic Records"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "different", "different", "different", "different"], "equivalence_stats": {"num_same": 0, "num_different": 10, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:04:34.908083Z"}
{"question_id": "tqa_rc_validation_176", "question": "On which label did Chuck Berry record in the 1950s and 1960s?", "ground_truth": ["Chess", "Chess match", "Šachmatai", "Sjakk", "Ajedrez", "Ahedres", "Ficheall", "Rank and file (chess)", "Chess Revers", "Xadrez", "Chess publications", "Satranç", "Western chess", "Šachy", "Шахи", "Chess game", "European chess", "Chess psychology", "Ŝako", "ਸ਼ਤਰੰਜ", "Chess games", "शतरंज", "Play chess", "Skaak", "Orthochess", "Chesss", "Game of chess", "Šach", "Echedoù", "Échecs", "שחמט", "Chesse", "Scacci", "Шахмат", "Escacs", "Cög", "Şah", "Cờ vua", "International Chess", "Chess board game", "Шахматы", "Skak", "شطرنج", "Шатар", "Chess career", "Σκάκι", "Šahs", "Cheess", "Chess srategy and tactics", "Chess (game)", "Skák", "rank and file chess"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Chess Records", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:35.675883Z"}
{"question_id": "tqa_rc_validation_176", "question": "On which label did Chuck Berry record in the 1950s and 1960s?", "ground_truth": ["Chess", "Chess match", "Šachmatai", "Sjakk", "Ajedrez", "Ahedres", "Ficheall", "Rank and file (chess)", "Chess Revers", "Xadrez", "Chess publications", "Satranç", "Western chess", "Šachy", "Шахи", "Chess game", "European chess", "Chess psychology", "Ŝako", "ਸ਼ਤਰੰਜ", "Chess games", "शतरंज", "Play chess", "Skaak", "Orthochess", "Chesss", "Game of chess", "Šach", "Echedoù", "Échecs", "שחמט", "Chesse", "Scacci", "Шахмат", "Escacs", "Cög", "Şah", "Cờ vua", "International Chess", "Chess board game", "Шахматы", "Skak", "شطرنج", "Шатар", "Chess career", "Σκάκι", "Šahs", "Cheess", "Chess srategy and tactics", "Chess (game)", "Skák", "rank and file chess"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Chess", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:36.517759Z"}
{"question_id": "tqa_rc_validation_176", "question": "On which label did Chuck Berry record in the 1950s and 1960s?", "ground_truth": ["Chess", "Chess match", "Šachmatai", "Sjakk", "Ajedrez", "Ahedres", "Ficheall", "Rank and file (chess)", "Chess Revers", "Xadrez", "Chess publications", "Satranç", "Western chess", "Šachy", "Шахи", "Chess game", "European chess", "Chess psychology", "Ŝako", "ਸ਼ਤਰੰਜ", "Chess games", "शतरंज", "Play chess", "Skaak", "Orthochess", "Chesss", "Game of chess", "Šach", "Echedoù", "Échecs", "שחמט", "Chesse", "Scacci", "Шахмат", "Escacs", "Cög", "Şah", "Cờ vua", "International Chess", "Chess board game", "Шахматы", "Skak", "شطرنج", "Шатар", "Chess career", "Σκάκι", "Šahs", "Cheess", "Chess srategy and tactics", "Chess (game)", "Skák", "rank and file chess"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Chess Records", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:36.801664Z"}
{"question_id": "tqa_rc_validation_176", "question": "On which label did Chuck Berry record in the 1950s and 1960s?", "ground_truth": ["Chess", "Chess match", "Šachmatai", "Sjakk", "Ajedrez", "Ahedres", "Ficheall", "Rank and file (chess)", "Chess Revers", "Xadrez", "Chess publications", "Satranç", "Western chess", "Šachy", "Шахи", "Chess game", "European chess", "Chess psychology", "Ŝako", "ਸ਼ਤਰੰਜ", "Chess games", "शतरंज", "Play chess", "Skaak", "Orthochess", "Chesss", "Game of chess", "Šach", "Echedoù", "Échecs", "שחמט", "Chesse", "Scacci", "Шахмат", "Escacs", "Cög", "Şah", "Cờ vua", "International Chess", "Chess board game", "Шахматы", "Skak", "شطرنج", "Шатар", "Chess career", "Σκάκι", "Šahs", "Cheess", "Chess srategy and tactics", "Chess (game)", "Skák", "rank and file chess"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Chess Records", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:37.951135Z"}
{"question_id": "tqa_rc_validation_176", "question": "On which label did Chuck Berry record in the 1950s and 1960s?", "ground_truth": ["Chess", "Chess match", "Šachmatai", "Sjakk", "Ajedrez", "Ahedres", "Ficheall", "Rank and file (chess)", "Chess Revers", "Xadrez", "Chess publications", "Satranç", "Western chess", "Šachy", "Шахи", "Chess game", "European chess", "Chess psychology", "Ŝako", "ਸ਼ਤਰੰਜ", "Chess games", "शतरंज", "Play chess", "Skaak", "Orthochess", "Chesss", "Game of chess", "Šach", "Echedoù", "Échecs", "שחמט", "Chesse", "Scacci", "Шахмат", "Escacs", "Cög", "Şah", "Cờ vua", "International Chess", "Chess board game", "Шахматы", "Skak", "شطرنج", "Шатар", "Chess career", "Σκάκι", "Šahs", "Cheess", "Chess srategy and tactics", "Chess (game)", "Skák", "rank and file chess"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Chess Records", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:38.895143Z"}
{"question_id": "tqa_rc_validation_177", "question": "What was the name of Michael Jackson's second wife?", "ground_truth": ["Debbie Rowe", "Deborah Jeanne Rowe", "Deborah Rowe Jackson", "Debbie Jackson", "Deborah Rowe"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Debbie Rowe", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:39.708380Z"}
{"question_id": "tqa_rc_validation_177", "question": "What was the name of Michael Jackson's second wife?", "ground_truth": ["Debbie Rowe", "Deborah Jeanne Rowe", "Deborah Rowe Jackson", "Debbie Jackson", "Deborah Rowe"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Debbie Rowe", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:41.564704Z"}
{"question_id": "tqa_rc_validation_177", "question": "What was the name of Michael Jackson's second wife?", "ground_truth": ["Debbie Rowe", "Deborah Jeanne Rowe", "Deborah Rowe Jackson", "Debbie Jackson", "Deborah Rowe"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Debbie Rowe", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:41.724322Z"}
{"question_id": "tqa_rc_validation_177", "question": "What was the name of Michael Jackson's second wife?", "ground_truth": ["Debbie Rowe", "Deborah Jeanne Rowe", "Deborah Rowe Jackson", "Debbie Jackson", "Deborah Rowe"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Debbie Rowe", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:04:42.854183Z"}
{"question_id": "tqa_rc_validation_177", "question": "What was the name of Michael Jackson's second wife?", "ground_truth": ["Debbie Rowe", "Deborah Jeanne Rowe", "Deborah Rowe Jackson", "Debbie Jackson", "Deborah Rowe"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Lisa Marie Presley", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Lisa Marie Presley", "Lisa Marie Presley", "Lisa Marie Presley", "Lisa Marie Presley", "Lisa Marie Presley", "Lisa Marie Presley", "Lisa Marie Presley", "Lisa Marie Presley then Deborah Rowe", "Lisa Marie Presley", "Debbie Rowe"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "different", "same", "different"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:05:00.080382Z"}
{"question_id": "tqa_rc_validation_178", "question": "Which US city was named after a British Prime Minister?", "ground_truth": ["Pittsburgh", "Smoky City", "Pittsburgh (Pa.)", "Pittsburgh, Pennsylvania.", "Frick International Studies Academy Middle School", "Pitsburgh", "The Burgh", "Pittsbrugh", "Pittsburgh, Pa", "Pittsburgh, USA", "Glenwood, Pennsylvania", "Pittsburgh (PA)", "The Pittsburgh Style of Literature", "Pittsburgh, Pennsylvania, U.S.", "Pittsburgh, United States of America", "Pittsburgh Pennsyvania", "UN/LOCODE:USPIT", "Da burgh", "Pittsburgh (pgh)", "Climate of Pittsburgh, Pennsylvania", "City of Bridges", "Pittsburgh Frick 6–8 Middle School", "St. Justin's High School", "East End (Pittsburgh)", "Pittsburgh, Pennsylvania, USA", "Pittsburgh, Allegheny County, Pennsylvania", "The City of Bridges", "Pittsburgh, Pennsylvania, US", "Fort du Quesne", "Pittsburgh Frick 6-8 Middle School", "City of Pittsburgh", "The Steel City", "Pittsburgh, PA.", "Pittsburgh Style", "Education in pittsburgh", "Pittsburg, PA", "Pittsburgh, Pennsylvania, U.S.A.", "Pittsburg, Pennsylvania", "Pittsburgh, Pennsylvania", "steel city", "climate of pittsburgh pennsylvania", "un locode uspit", "pittsburgh pennsylvania usa", "pittsburgh pennsylvania u s", "st justin s high school", "pittsburgh pa", "glenwood pennsylvania", "pittsburgh style of literature", "east end pittsburgh", "pittsburgh pennsylvania us", "pittsburgh usa", "pittsburg pennsylvania", "pittsburgh frick 6 8 middle school", "pittsburgh pennsylvania", "pittsburgh united states of america", "pittsburg pa", "burgh", "pittsburgh allegheny county pennsylvania", "pittsburgh pgh"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Pittsburgh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:00.862815Z"}
{"question_id": "tqa_rc_validation_178", "question": "Which US city was named after a British Prime Minister?", "ground_truth": ["Pittsburgh", "Smoky City", "Pittsburgh (Pa.)", "Pittsburgh, Pennsylvania.", "Frick International Studies Academy Middle School", "Pitsburgh", "The Burgh", "Pittsbrugh", "Pittsburgh, Pa", "Pittsburgh, USA", "Glenwood, Pennsylvania", "Pittsburgh (PA)", "The Pittsburgh Style of Literature", "Pittsburgh, Pennsylvania, U.S.", "Pittsburgh, United States of America", "Pittsburgh Pennsyvania", "UN/LOCODE:USPIT", "Da burgh", "Pittsburgh (pgh)", "Climate of Pittsburgh, Pennsylvania", "City of Bridges", "Pittsburgh Frick 6–8 Middle School", "St. Justin's High School", "East End (Pittsburgh)", "Pittsburgh, Pennsylvania, USA", "Pittsburgh, Allegheny County, Pennsylvania", "The City of Bridges", "Pittsburgh, Pennsylvania, US", "Fort du Quesne", "Pittsburgh Frick 6-8 Middle School", "City of Pittsburgh", "The Steel City", "Pittsburgh, PA.", "Pittsburgh Style", "Education in pittsburgh", "Pittsburg, PA", "Pittsburgh, Pennsylvania, U.S.A.", "Pittsburg, Pennsylvania", "Pittsburgh, Pennsylvania", "steel city", "climate of pittsburgh pennsylvania", "un locode uspit", "pittsburgh pennsylvania usa", "pittsburgh pennsylvania u s", "st justin s high school", "pittsburgh pa", "glenwood pennsylvania", "pittsburgh style of literature", "east end pittsburgh", "pittsburgh pennsylvania us", "pittsburgh usa", "pittsburg pennsylvania", "pittsburgh frick 6 8 middle school", "pittsburgh pennsylvania", "pittsburgh united states of america", "pittsburg pa", "burgh", "pittsburgh allegheny county pennsylvania", "pittsburgh pgh"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Pittsburgh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:02.709278Z"}
{"question_id": "tqa_rc_validation_178", "question": "Which US city was named after a British Prime Minister?", "ground_truth": ["Pittsburgh", "Smoky City", "Pittsburgh (Pa.)", "Pittsburgh, Pennsylvania.", "Frick International Studies Academy Middle School", "Pitsburgh", "The Burgh", "Pittsbrugh", "Pittsburgh, Pa", "Pittsburgh, USA", "Glenwood, Pennsylvania", "Pittsburgh (PA)", "The Pittsburgh Style of Literature", "Pittsburgh, Pennsylvania, U.S.", "Pittsburgh, United States of America", "Pittsburgh Pennsyvania", "UN/LOCODE:USPIT", "Da burgh", "Pittsburgh (pgh)", "Climate of Pittsburgh, Pennsylvania", "City of Bridges", "Pittsburgh Frick 6–8 Middle School", "St. Justin's High School", "East End (Pittsburgh)", "Pittsburgh, Pennsylvania, USA", "Pittsburgh, Allegheny County, Pennsylvania", "The City of Bridges", "Pittsburgh, Pennsylvania, US", "Fort du Quesne", "Pittsburgh Frick 6-8 Middle School", "City of Pittsburgh", "The Steel City", "Pittsburgh, PA.", "Pittsburgh Style", "Education in pittsburgh", "Pittsburg, PA", "Pittsburgh, Pennsylvania, U.S.A.", "Pittsburg, Pennsylvania", "Pittsburgh, Pennsylvania", "steel city", "climate of pittsburgh pennsylvania", "un locode uspit", "pittsburgh pennsylvania usa", "pittsburgh pennsylvania u s", "st justin s high school", "pittsburgh pa", "glenwood pennsylvania", "pittsburgh style of literature", "east end pittsburgh", "pittsburgh pennsylvania us", "pittsburgh usa", "pittsburg pennsylvania", "pittsburgh frick 6 8 middle school", "pittsburgh pennsylvania", "pittsburgh united states of america", "pittsburg pa", "burgh", "pittsburgh allegheny county pennsylvania", "pittsburgh pgh"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Pittsburgh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:02.937253Z"}
{"question_id": "tqa_rc_validation_178", "question": "Which US city was named after a British Prime Minister?", "ground_truth": ["Pittsburgh", "Smoky City", "Pittsburgh (Pa.)", "Pittsburgh, Pennsylvania.", "Frick International Studies Academy Middle School", "Pitsburgh", "The Burgh", "Pittsbrugh", "Pittsburgh, Pa", "Pittsburgh, USA", "Glenwood, Pennsylvania", "Pittsburgh (PA)", "The Pittsburgh Style of Literature", "Pittsburgh, Pennsylvania, U.S.", "Pittsburgh, United States of America", "Pittsburgh Pennsyvania", "UN/LOCODE:USPIT", "Da burgh", "Pittsburgh (pgh)", "Climate of Pittsburgh, Pennsylvania", "City of Bridges", "Pittsburgh Frick 6–8 Middle School", "St. Justin's High School", "East End (Pittsburgh)", "Pittsburgh, Pennsylvania, USA", "Pittsburgh, Allegheny County, Pennsylvania", "The City of Bridges", "Pittsburgh, Pennsylvania, US", "Fort du Quesne", "Pittsburgh Frick 6-8 Middle School", "City of Pittsburgh", "The Steel City", "Pittsburgh, PA.", "Pittsburgh Style", "Education in pittsburgh", "Pittsburg, PA", "Pittsburgh, Pennsylvania, U.S.A.", "Pittsburg, Pennsylvania", "Pittsburgh, Pennsylvania", "steel city", "climate of pittsburgh pennsylvania", "un locode uspit", "pittsburgh pennsylvania usa", "pittsburgh pennsylvania u s", "st justin s high school", "pittsburgh pa", "glenwood pennsylvania", "pittsburgh style of literature", "east end pittsburgh", "pittsburgh pennsylvania us", "pittsburgh usa", "pittsburg pennsylvania", "pittsburgh frick 6 8 middle school", "pittsburgh pennsylvania", "pittsburgh united states of america", "pittsburg pa", "burgh", "pittsburgh allegheny county pennsylvania", "pittsburgh pgh"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Pittsburgh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:04.265886Z"}
{"question_id": "tqa_rc_validation_178", "question": "Which US city was named after a British Prime Minister?", "ground_truth": ["Pittsburgh", "Smoky City", "Pittsburgh (Pa.)", "Pittsburgh, Pennsylvania.", "Frick International Studies Academy Middle School", "Pitsburgh", "The Burgh", "Pittsbrugh", "Pittsburgh, Pa", "Pittsburgh, USA", "Glenwood, Pennsylvania", "Pittsburgh (PA)", "The Pittsburgh Style of Literature", "Pittsburgh, Pennsylvania, U.S.", "Pittsburgh, United States of America", "Pittsburgh Pennsyvania", "UN/LOCODE:USPIT", "Da burgh", "Pittsburgh (pgh)", "Climate of Pittsburgh, Pennsylvania", "City of Bridges", "Pittsburgh Frick 6–8 Middle School", "St. Justin's High School", "East End (Pittsburgh)", "Pittsburgh, Pennsylvania, USA", "Pittsburgh, Allegheny County, Pennsylvania", "The City of Bridges", "Pittsburgh, Pennsylvania, US", "Fort du Quesne", "Pittsburgh Frick 6-8 Middle School", "City of Pittsburgh", "The Steel City", "Pittsburgh, PA.", "Pittsburgh Style", "Education in pittsburgh", "Pittsburg, PA", "Pittsburgh, Pennsylvania, U.S.A.", "Pittsburg, Pennsylvania", "Pittsburgh, Pennsylvania", "steel city", "climate of pittsburgh pennsylvania", "un locode uspit", "pittsburgh pennsylvania usa", "pittsburgh pennsylvania u s", "st justin s high school", "pittsburgh pa", "glenwood pennsylvania", "pittsburgh style of literature", "east end pittsburgh", "pittsburgh pennsylvania us", "pittsburgh usa", "pittsburg pennsylvania", "pittsburgh frick 6 8 middle school", "pittsburgh pennsylvania", "pittsburgh united states of america", "pittsburg pa", "burgh", "pittsburgh allegheny county pennsylvania", "pittsburgh pgh"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Pittsburgh", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:05.021285Z"}
{"question_id": "tqa_rc_validation_179", "question": "\"Who said, To err is human but it feels divine?\"\"\"", "ground_truth": ["Mae West", "Is that a gun in your pocket, or are you just happy to see me%3F", "When I'm Bad, I'm Better", "Jane Mast", "When I'm good, I'm very good...", "Mae West filmography", "is that gun in your pocket or are you just happy to see me 3f", "when i m bad i m better", "when i m good i m very good"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Mae West", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:05.744993Z"}
{"question_id": "tqa_rc_validation_179", "question": "\"Who said, To err is human but it feels divine?\"\"\"", "ground_truth": ["Mae West", "Is that a gun in your pocket, or are you just happy to see me%3F", "When I'm Bad, I'm Better", "Jane Mast", "When I'm good, I'm very good...", "Mae West filmography", "is that gun in your pocket or are you just happy to see me 3f", "when i m bad i m better", "when i m good i m very good"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Mae West", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:07.343748Z"}
{"question_id": "tqa_rc_validation_179", "question": "\"Who said, To err is human but it feels divine?\"\"\"", "ground_truth": ["Mae West", "Is that a gun in your pocket, or are you just happy to see me%3F", "When I'm Bad, I'm Better", "Jane Mast", "When I'm good, I'm very good...", "Mae West filmography", "is that gun in your pocket or are you just happy to see me 3f", "when i m bad i m better", "when i m good i m very good"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Mae West", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:07.761677Z"}
{"question_id": "tqa_rc_validation_179", "question": "\"Who said, To err is human but it feels divine?\"\"\"", "ground_truth": ["Mae West", "Is that a gun in your pocket, or are you just happy to see me%3F", "When I'm Bad, I'm Better", "Jane Mast", "When I'm good, I'm very good...", "Mae West filmography", "is that gun in your pocket or are you just happy to see me 3f", "when i m bad i m better", "when i m good i m very good"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Mae West", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:08.919245Z"}
{"question_id": "tqa_rc_validation_179", "question": "\"Who said, To err is human but it feels divine?\"\"\"", "ground_truth": ["Mae West", "Is that a gun in your pocket, or are you just happy to see me%3F", "When I'm Bad, I'm Better", "Jane Mast", "When I'm good, I'm very good...", "Mae West filmography", "is that gun in your pocket or are you just happy to see me 3f", "when i m bad i m better", "when i m good i m very good"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Mae West", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:09.740743Z"}
{"question_id": "tqa_rc_validation_180", "question": "Which singer had a big 60s No 1 with Roses Are Red?", "ground_truth": ["Bobby Vinton"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Bobby Vinton", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:10.723799Z"}
{"question_id": "tqa_rc_validation_180", "question": "Which singer had a big 60s No 1 with Roses Are Red?", "ground_truth": ["Bobby Vinton"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Bobby Vinton", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:11.715128Z"}
{"question_id": "tqa_rc_validation_180", "question": "Which singer had a big 60s No 1 with Roses Are Red?", "ground_truth": ["Bobby Vinton"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Bobby Vinton", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:11.869650Z"}
{"question_id": "tqa_rc_validation_180", "question": "Which singer had a big 60s No 1 with Roses Are Red?", "ground_truth": ["Bobby Vinton"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Bobby Vinton", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:13.088127Z"}
{"question_id": "tqa_rc_validation_180", "question": "Which singer had a big 60s No 1 with Roses Are Red?", "ground_truth": ["Bobby Vinton"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Bobby Vinton", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:13.887006Z"}
{"question_id": "tqa_rc_validation_181", "question": "What are the international registration letters of a vehicle from Iceland?", "ground_truth": ["IS", "I S", "I.s.", "Is.", "IS (disambiguation)", "is disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "IS", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:14.564750Z"}
{"question_id": "tqa_rc_validation_181", "question": "What are the international registration letters of a vehicle from Iceland?", "ground_truth": ["IS", "I S", "I.s.", "Is.", "IS (disambiguation)", "is disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "IS", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:16.078459Z"}
{"question_id": "tqa_rc_validation_181", "question": "What are the international registration letters of a vehicle from Iceland?", "ground_truth": ["IS", "I S", "I.s.", "Is.", "IS (disambiguation)", "is disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "IS", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:16.235292Z"}
{"question_id": "tqa_rc_validation_181", "question": "What are the international registration letters of a vehicle from Iceland?", "ground_truth": ["IS", "I S", "I.s.", "Is.", "IS (disambiguation)", "is disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "IS", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:05:17.383089Z"}
{"question_id": "tqa_rc_validation_181", "question": "What are the international registration letters of a vehicle from Iceland?", "ground_truth": ["IS", "I S", "I.s.", "Is.", "IS (disambiguation)", "is disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "ÍS", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["ÍS", "IS", "ICE", "ÍS", "IC", "ISL", "IC", "IS", "ÍS", "FR"], "equivalence_results": ["same", "different", "different", "same", "different", "different", "different", "different", "same", "different"], "equivalence_stats": {"num_same": 3, "num_different": 7, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.3, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:05:36.109503Z"}
{"question_id": "tqa_rc_validation_182", "question": "Where was the American venue of the Live Aid concert?", "ground_truth": ["Philadelphia", "Philedelphia", "City of brotherly love", "The Quaker City", "Philadelphia, Pennsylvania", "Philadelphia, Pennsylvania, U.S.A.", "Philadelphia, Pa.", "List of nicknames for Philadelphia", "Philidalphia", "Philadelphia, United States", "Philadelphia, Pennsylvania, U.S.", "Philadelphia PA", "Philadelphia Suburban Rail", "Philadelphi", "Philadelphia, U.S.", "Philadelphia Regional Rail", "The City of Brotherly Love", "City of Philadelphia", "Philadelphia (Pennsylvania)", "Wiccacoa", "Philadelpia, Pennsylvania", "Philadelphia, USA", "Philadelphia, Philadelphia County, Pennsylvania", "Government of Philadelphia", "Philadelphia (PA)", "Philadelphia, Pennsylvania, USA", "Philadelphia (City)", "UN/LOCODE:USPHL", "The City That Loves You Back", "Philadelphia (Pa.)", "Phila.", "The Cradle of Liberty", "Philadelphia (city, Pennsylvania)", "Philidelphia", "Philadelphia, Pennsylvania, US", "Philadelphia Commuter Rail", "The City and County of Philadelphia, Pennsylvania", "Philadephia, Pennsylvania", "Philadelphia City", "Philadelphia Pennsylvania", "Philadelphia City Controller", "Philladelphia", "Political families of Philadelphia", "Philadelphia, Pa", "The Birthplace of America", "Philadelpia, PA", "birthplace of america", "philadelpia pa", "philadelphia pennsylvania u s", "un locode usphl", "philadephia pennsylvania", "city and county of philadelphia pennsylvania", "philadelpia pennsylvania", "philadelphia pennsylvania us", "phila", "philadelphia u s", "cradle of liberty", "philadelphia usa", "city that loves you back", "philadelphia city pennsylvania", "philadelphia united states", "philadelphia philadelphia county pennsylvania", "quaker city", "philadelphia pennsylvania usa"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "John F", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["John F", "John F", "John F", "John F", "John F", "John F", "John F", "John F", "John F", "John F"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:05:55.535966Z"}
{"question_id": "tqa_rc_validation_182", "question": "Where was the American venue of the Live Aid concert?", "ground_truth": ["Philadelphia", "Philedelphia", "City of brotherly love", "The Quaker City", "Philadelphia, Pennsylvania", "Philadelphia, Pennsylvania, U.S.A.", "Philadelphia, Pa.", "List of nicknames for Philadelphia", "Philidalphia", "Philadelphia, United States", "Philadelphia, Pennsylvania, U.S.", "Philadelphia PA", "Philadelphia Suburban Rail", "Philadelphi", "Philadelphia, U.S.", "Philadelphia Regional Rail", "The City of Brotherly Love", "City of Philadelphia", "Philadelphia (Pennsylvania)", "Wiccacoa", "Philadelpia, Pennsylvania", "Philadelphia, USA", "Philadelphia, Philadelphia County, Pennsylvania", "Government of Philadelphia", "Philadelphia (PA)", "Philadelphia, Pennsylvania, USA", "Philadelphia (City)", "UN/LOCODE:USPHL", "The City That Loves You Back", "Philadelphia (Pa.)", "Phila.", "The Cradle of Liberty", "Philadelphia (city, Pennsylvania)", "Philidelphia", "Philadelphia, Pennsylvania, US", "Philadelphia Commuter Rail", "The City and County of Philadelphia, Pennsylvania", "Philadephia, Pennsylvania", "Philadelphia City", "Philadelphia Pennsylvania", "Philadelphia City Controller", "Philladelphia", "Political families of Philadelphia", "Philadelphia, Pa", "The Birthplace of America", "Philadelpia, PA", "birthplace of america", "philadelpia pa", "philadelphia pennsylvania u s", "un locode usphl", "philadephia pennsylvania", "city and county of philadelphia pennsylvania", "philadelpia pennsylvania", "philadelphia pennsylvania us", "phila", "philadelphia u s", "cradle of liberty", "philadelphia usa", "city that loves you back", "philadelphia city pennsylvania", "philadelphia united states", "philadelphia philadelphia county pennsylvania", "quaker city", "philadelphia pennsylvania usa"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "John F", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["John F", "John F", "John F", "John F", "John F", "John F", "John F", "John F", "John F", "John F"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:06:24.477938Z"}
{"question_id": "tqa_rc_validation_182", "question": "Where was the American venue of the Live Aid concert?", "ground_truth": ["Philadelphia", "Philedelphia", "City of brotherly love", "The Quaker City", "Philadelphia, Pennsylvania", "Philadelphia, Pennsylvania, U.S.A.", "Philadelphia, Pa.", "List of nicknames for Philadelphia", "Philidalphia", "Philadelphia, United States", "Philadelphia, Pennsylvania, U.S.", "Philadelphia PA", "Philadelphia Suburban Rail", "Philadelphi", "Philadelphia, U.S.", "Philadelphia Regional Rail", "The City of Brotherly Love", "City of Philadelphia", "Philadelphia (Pennsylvania)", "Wiccacoa", "Philadelpia, Pennsylvania", "Philadelphia, USA", "Philadelphia, Philadelphia County, Pennsylvania", "Government of Philadelphia", "Philadelphia (PA)", "Philadelphia, Pennsylvania, USA", "Philadelphia (City)", "UN/LOCODE:USPHL", "The City That Loves You Back", "Philadelphia (Pa.)", "Phila.", "The Cradle of Liberty", "Philadelphia (city, Pennsylvania)", "Philidelphia", "Philadelphia, Pennsylvania, US", "Philadelphia Commuter Rail", "The City and County of Philadelphia, Pennsylvania", "Philadephia, Pennsylvania", "Philadelphia City", "Philadelphia Pennsylvania", "Philadelphia City Controller", "Philladelphia", "Political families of Philadelphia", "Philadelphia, Pa", "The Birthplace of America", "Philadelpia, PA", "birthplace of america", "philadelpia pa", "philadelphia pennsylvania u s", "un locode usphl", "philadephia pennsylvania", "city and county of philadelphia pennsylvania", "philadelpia pennsylvania", "philadelphia pennsylvania us", "phila", "philadelphia u s", "cradle of liberty", "philadelphia usa", "city that loves you back", "philadelphia city pennsylvania", "philadelphia united states", "philadelphia philadelphia county pennsylvania", "quaker city", "philadelphia pennsylvania usa"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Philadelphia, at John F", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:06:24.716129Z"}
{"question_id": "tqa_rc_validation_182", "question": "Where was the American venue of the Live Aid concert?", "ground_truth": ["Philadelphia", "Philedelphia", "City of brotherly love", "The Quaker City", "Philadelphia, Pennsylvania", "Philadelphia, Pennsylvania, U.S.A.", "Philadelphia, Pa.", "List of nicknames for Philadelphia", "Philidalphia", "Philadelphia, United States", "Philadelphia, Pennsylvania, U.S.", "Philadelphia PA", "Philadelphia Suburban Rail", "Philadelphi", "Philadelphia, U.S.", "Philadelphia Regional Rail", "The City of Brotherly Love", "City of Philadelphia", "Philadelphia (Pennsylvania)", "Wiccacoa", "Philadelpia, Pennsylvania", "Philadelphia, USA", "Philadelphia, Philadelphia County, Pennsylvania", "Government of Philadelphia", "Philadelphia (PA)", "Philadelphia, Pennsylvania, USA", "Philadelphia (City)", "UN/LOCODE:USPHL", "The City That Loves You Back", "Philadelphia (Pa.)", "Phila.", "The Cradle of Liberty", "Philadelphia (city, Pennsylvania)", "Philidelphia", "Philadelphia, Pennsylvania, US", "Philadelphia Commuter Rail", "The City and County of Philadelphia, Pennsylvania", "Philadephia, Pennsylvania", "Philadelphia City", "Philadelphia Pennsylvania", "Philadelphia City Controller", "Philladelphia", "Political families of Philadelphia", "Philadelphia, Pa", "The Birthplace of America", "Philadelpia, PA", "birthplace of america", "philadelpia pa", "philadelphia pennsylvania u s", "un locode usphl", "philadephia pennsylvania", "city and county of philadelphia pennsylvania", "philadelpia pennsylvania", "philadelphia pennsylvania us", "phila", "philadelphia u s", "cradle of liberty", "philadelphia usa", "city that loves you back", "philadelphia city pennsylvania", "philadelphia united states", "philadelphia philadelphia county pennsylvania", "quaker city", "philadelphia pennsylvania usa"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Philadelphia", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:06:26.221260Z"}
{"question_id": "tqa_rc_validation_182", "question": "Where was the American venue of the Live Aid concert?", "ground_truth": ["Philadelphia", "Philedelphia", "City of brotherly love", "The Quaker City", "Philadelphia, Pennsylvania", "Philadelphia, Pennsylvania, U.S.A.", "Philadelphia, Pa.", "List of nicknames for Philadelphia", "Philidalphia", "Philadelphia, United States", "Philadelphia, Pennsylvania, U.S.", "Philadelphia PA", "Philadelphia Suburban Rail", "Philadelphi", "Philadelphia, U.S.", "Philadelphia Regional Rail", "The City of Brotherly Love", "City of Philadelphia", "Philadelphia (Pennsylvania)", "Wiccacoa", "Philadelpia, Pennsylvania", "Philadelphia, USA", "Philadelphia, Philadelphia County, Pennsylvania", "Government of Philadelphia", "Philadelphia (PA)", "Philadelphia, Pennsylvania, USA", "Philadelphia (City)", "UN/LOCODE:USPHL", "The City That Loves You Back", "Philadelphia (Pa.)", "Phila.", "The Cradle of Liberty", "Philadelphia (city, Pennsylvania)", "Philidelphia", "Philadelphia, Pennsylvania, US", "Philadelphia Commuter Rail", "The City and County of Philadelphia, Pennsylvania", "Philadephia, Pennsylvania", "Philadelphia City", "Philadelphia Pennsylvania", "Philadelphia City Controller", "Philladelphia", "Political families of Philadelphia", "Philadelphia, Pa", "The Birthplace of America", "Philadelpia, PA", "birthplace of america", "philadelpia pa", "philadelphia pennsylvania u s", "un locode usphl", "philadephia pennsylvania", "city and county of philadelphia pennsylvania", "philadelpia pennsylvania", "philadelphia pennsylvania us", "phila", "philadelphia u s", "cradle of liberty", "philadelphia usa", "city that loves you back", "philadelphia city pennsylvania", "philadelphia united states", "philadelphia philadelphia county pennsylvania", "quaker city", "philadelphia pennsylvania usa"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "John F", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["John F", "John F", "John F", "John F", "John F", "John F", "John F", "John F", "John F", "John F"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:06:42.524526Z"}
{"question_id": "tqa_rc_validation_183", "question": "Which was the longest moon landing?", "ground_truth": ["Apollo 17", "Apollo XVII", "Apollo17"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Apollo 17 (about 75 hours on the lunar surface)", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:06:43.616336Z"}
{"question_id": "tqa_rc_validation_183", "question": "Which was the longest moon landing?", "ground_truth": ["Apollo 17", "Apollo XVII", "Apollo17"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Apollo 17", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:06:46.677865Z"}
{"question_id": "tqa_rc_validation_183", "question": "Which was the longest moon landing?", "ground_truth": ["Apollo 17", "Apollo XVII", "Apollo17"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Apollo 17", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:06:46.918015Z"}
{"question_id": "tqa_rc_validation_183", "question": "Which was the longest moon landing?", "ground_truth": ["Apollo 17", "Apollo XVII", "Apollo17"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Apollo 17", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:06:48.199806Z"}
{"question_id": "tqa_rc_validation_183", "question": "Which was the longest moon landing?", "ground_truth": ["Apollo 17", "Apollo XVII", "Apollo17"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Apollo 17", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:06:49.100026Z"}
{"question_id": "tqa_rc_validation_184", "question": "Who had the most expensive presidential inauguration ceremony of the 20th century?", "ground_truth": ["George W. Bush", "George Walker Bush", "Dubya", "Bush, George W.", "Bush Jr.", "George W. Bush (painter)", "W Bush", "Bushian", "Gorge w bush", "Bush the younger", "George w", "Bush 43", "Bush II", "George the Younger", "George W. Bussh", "George W. Bush Street", "George Bush (43rd U.S. President)", "G W Bush", "Dubyuh", "George Bush jr.", "G.W. Bush", "W. bush", "Dubya Bush", "G. W. Bush", "George W Bush", "US President George W. Bush", "G.w.bush", "Bush Junior", "George W. Bush, 43rd President of the United States", "George Bush (2000)", "George w.", "Gorge W. Bush", "G. Walker Bush", "George Dubya Bush", "Geroge W Bush", "2004 Republican Presidential Nominee", "George Bush II", "Baby Bush", "2000 Republican Presidential Nominee", "Junior Bush", "President Bush (2000)", "Goerge W. Bush", "George Bush Jr", "George W. Budh", "43rd President of the United States", "George W. Buah", "G Dub", "George W Bush Jr", "43rd Pesident of the United States", "Jorge W. Bush", "International perception of george W. Bush", "GeorgeWBush", "George bush 43", "Bush (43)", "George Bush 2", "George Bush (43)", "Bush-43", "George Bush Junior", "George Wаlker Bush", "Gw bush", "G. W. B.", "Bushists", "Religious faith of George W. Bush", "President Bush (43)", "George W.Bush", "George Bush, Jr.", "G. Dub", "President George W Bush", "Former President George W. Bush", "President George Walker Bush", "george w budh", "g walker bush", "jorge w bush", "us president george w bush", "george w bush street", "goerge w bush", "43rd pesident of united states", "george w bush 43rd president of united states", "george w buah", "george bush 2000", "international perception of george w bush", "george w bush painter", "bush george w", "president bush 2000", "religious faith of george w bush", "president bush 43", "former president george w bush", "43rd president of united states", "g w b", "george w bussh", "bush jr", "bush younger", "george bush 43rd u s president", "george younger"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Bill Clinton", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Bill Clinton", "Bill Clinton", "Bill Clinton", "Bill Clinton", "Bill Clinton", "Bill Clinton", "Bill Clinton", "Bill Clinton", "Bill Clinton (1997)", "Bill Clinton"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:07:07.047703Z"}
{"question_id": "tqa_rc_validation_184", "question": "Who had the most expensive presidential inauguration ceremony of the 20th century?", "ground_truth": ["George W. Bush", "George Walker Bush", "Dubya", "Bush, George W.", "Bush Jr.", "George W. Bush (painter)", "W Bush", "Bushian", "Gorge w bush", "Bush the younger", "George w", "Bush 43", "Bush II", "George the Younger", "George W. Bussh", "George W. Bush Street", "George Bush (43rd U.S. President)", "G W Bush", "Dubyuh", "George Bush jr.", "G.W. Bush", "W. bush", "Dubya Bush", "G. W. Bush", "George W Bush", "US President George W. Bush", "G.w.bush", "Bush Junior", "George W. Bush, 43rd President of the United States", "George Bush (2000)", "George w.", "Gorge W. Bush", "G. Walker Bush", "George Dubya Bush", "Geroge W Bush", "2004 Republican Presidential Nominee", "George Bush II", "Baby Bush", "2000 Republican Presidential Nominee", "Junior Bush", "President Bush (2000)", "Goerge W. Bush", "George Bush Jr", "George W. Budh", "43rd President of the United States", "George W. Buah", "G Dub", "George W Bush Jr", "43rd Pesident of the United States", "Jorge W. Bush", "International perception of george W. Bush", "GeorgeWBush", "George bush 43", "Bush (43)", "George Bush 2", "George Bush (43)", "Bush-43", "George Bush Junior", "George Wаlker Bush", "Gw bush", "G. W. B.", "Bushists", "Religious faith of George W. Bush", "President Bush (43)", "George W.Bush", "George Bush, Jr.", "G. Dub", "President George W Bush", "Former President George W. Bush", "President George Walker Bush", "george w budh", "g walker bush", "jorge w bush", "us president george w bush", "george w bush street", "goerge w bush", "43rd pesident of united states", "george w bush 43rd president of united states", "george w buah", "george bush 2000", "international perception of george w bush", "george w bush painter", "bush george w", "president bush 2000", "religious faith of george w bush", "president bush 43", "former president george w bush", "43rd president of united states", "g w b", "george w bussh", "bush jr", "bush younger", "george bush 43rd u s president", "george younger"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Bill Clinton (1993 inauguration)", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Bill Clinton (1993 inauguration)", "Bill Clinton (1993 inauguration)", "Bill Clinton (1993 inauguration)", "Bill Clinton (1993 inauguration)", "Bill Clinton (1993 inauguration)", "Bill Clinton (1993 inauguration)", "Bill Clinton (1993 inauguration)", "Bill Clinton (1993 inauguration)", "Bill Clinton (1993 inauguration)", "Bill Clinton (1993 inauguration)"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:07:32.120288Z"}
{"question_id": "tqa_rc_validation_184", "question": "Who had the most expensive presidential inauguration ceremony of the 20th century?", "ground_truth": ["George W. Bush", "George Walker Bush", "Dubya", "Bush, George W.", "Bush Jr.", "George W. Bush (painter)", "W Bush", "Bushian", "Gorge w bush", "Bush the younger", "George w", "Bush 43", "Bush II", "George the Younger", "George W. Bussh", "George W. Bush Street", "George Bush (43rd U.S. President)", "G W Bush", "Dubyuh", "George Bush jr.", "G.W. Bush", "W. bush", "Dubya Bush", "G. W. Bush", "George W Bush", "US President George W. Bush", "G.w.bush", "Bush Junior", "George W. Bush, 43rd President of the United States", "George Bush (2000)", "George w.", "Gorge W. Bush", "G. Walker Bush", "George Dubya Bush", "Geroge W Bush", "2004 Republican Presidential Nominee", "George Bush II", "Baby Bush", "2000 Republican Presidential Nominee", "Junior Bush", "President Bush (2000)", "Goerge W. Bush", "George Bush Jr", "George W. Budh", "43rd President of the United States", "George W. Buah", "G Dub", "George W Bush Jr", "43rd Pesident of the United States", "Jorge W. Bush", "International perception of george W. Bush", "GeorgeWBush", "George bush 43", "Bush (43)", "George Bush 2", "George Bush (43)", "Bush-43", "George Bush Junior", "George Wаlker Bush", "Gw bush", "G. W. B.", "Bushists", "Religious faith of George W. Bush", "President Bush (43)", "George W.Bush", "George Bush, Jr.", "G. Dub", "President George W Bush", "Former President George W. Bush", "President George Walker Bush", "george w budh", "g walker bush", "jorge w bush", "us president george w bush", "george w bush street", "goerge w bush", "43rd pesident of united states", "george w bush 43rd president of united states", "george w buah", "george bush 2000", "international perception of george w bush", "george w bush painter", "bush george w", "president bush 2000", "religious faith of george w bush", "president bush 43", "former president george w bush", "43rd president of united states", "g w b", "george w bussh", "bush jr", "bush younger", "george bush 43rd u s president", "george younger"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Ronald Reagan", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ronald Reagan", "Ronald Reagan", "Ronald Reagan in 1981, with a cost of about $16 million", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan in 1981, with a cost of around $16 million", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan in 1981, with a cost of around $40 million"], "equivalence_results": ["same", "same", "unclear", "same", "same", "different", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 7, "num_different": 2, "num_unclear": 1, "total": 10}, "equivalence_ratio": 0.7777777777777778, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:07:43.101335Z"}
{"question_id": "tqa_rc_validation_184", "question": "Who had the most expensive presidential inauguration ceremony of the 20th century?", "ground_truth": ["George W. Bush", "George Walker Bush", "Dubya", "Bush, George W.", "Bush Jr.", "George W. Bush (painter)", "W Bush", "Bushian", "Gorge w bush", "Bush the younger", "George w", "Bush 43", "Bush II", "George the Younger", "George W. Bussh", "George W. Bush Street", "George Bush (43rd U.S. President)", "G W Bush", "Dubyuh", "George Bush jr.", "G.W. Bush", "W. bush", "Dubya Bush", "G. W. Bush", "George W Bush", "US President George W. Bush", "G.w.bush", "Bush Junior", "George W. Bush, 43rd President of the United States", "George Bush (2000)", "George w.", "Gorge W. Bush", "G. Walker Bush", "George Dubya Bush", "Geroge W Bush", "2004 Republican Presidential Nominee", "George Bush II", "Baby Bush", "2000 Republican Presidential Nominee", "Junior Bush", "President Bush (2000)", "Goerge W. Bush", "George Bush Jr", "George W. Budh", "43rd President of the United States", "George W. Buah", "G Dub", "George W Bush Jr", "43rd Pesident of the United States", "Jorge W. Bush", "International perception of george W. Bush", "GeorgeWBush", "George bush 43", "Bush (43)", "George Bush 2", "George Bush (43)", "Bush-43", "George Bush Junior", "George Wаlker Bush", "Gw bush", "G. W. B.", "Bushists", "Religious faith of George W. Bush", "President Bush (43)", "George W.Bush", "George Bush, Jr.", "G. Dub", "President George W Bush", "Former President George W. Bush", "President George Walker Bush", "george w budh", "g walker bush", "jorge w bush", "us president george w bush", "george w bush street", "goerge w bush", "43rd pesident of united states", "george w bush 43rd president of united states", "george w buah", "george bush 2000", "international perception of george w bush", "george w bush painter", "bush george w", "president bush 2000", "religious faith of george w bush", "president bush 43", "former president george w bush", "43rd president of united states", "g w b", "george w bussh", "bush jr", "bush younger", "george bush 43rd u s president", "george younger"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Ronald Reagan", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Bill Clinton", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan", "Ronald Reagan"], "equivalence_results": ["different", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:08:05.063536Z"}
{"question_id": "tqa_rc_validation_184", "question": "Who had the most expensive presidential inauguration ceremony of the 20th century?", "ground_truth": ["George W. Bush", "George Walker Bush", "Dubya", "Bush, George W.", "Bush Jr.", "George W. Bush (painter)", "W Bush", "Bushian", "Gorge w bush", "Bush the younger", "George w", "Bush 43", "Bush II", "George the Younger", "George W. Bussh", "George W. Bush Street", "George Bush (43rd U.S. President)", "G W Bush", "Dubyuh", "George Bush jr.", "G.W. Bush", "W. bush", "Dubya Bush", "G. W. Bush", "George W Bush", "US President George W. Bush", "G.w.bush", "Bush Junior", "George W. Bush, 43rd President of the United States", "George Bush (2000)", "George w.", "Gorge W. Bush", "G. Walker Bush", "George Dubya Bush", "Geroge W Bush", "2004 Republican Presidential Nominee", "George Bush II", "Baby Bush", "2000 Republican Presidential Nominee", "Junior Bush", "President Bush (2000)", "Goerge W. Bush", "George Bush Jr", "George W. Budh", "43rd President of the United States", "George W. Buah", "G Dub", "George W Bush Jr", "43rd Pesident of the United States", "Jorge W. Bush", "International perception of george W. Bush", "GeorgeWBush", "George bush 43", "Bush (43)", "George Bush 2", "George Bush (43)", "Bush-43", "George Bush Junior", "George Wаlker Bush", "Gw bush", "G. W. B.", "Bushists", "Religious faith of George W. Bush", "President Bush (43)", "George W.Bush", "George Bush, Jr.", "G. Dub", "President George W Bush", "Former President George W. Bush", "President George Walker Bush", "george w budh", "g walker bush", "jorge w bush", "us president george w bush", "george w bush street", "goerge w bush", "43rd pesident of united states", "george w bush 43rd president of united states", "george w buah", "george bush 2000", "international perception of george w bush", "george w bush painter", "bush george w", "president bush 2000", "religious faith of george w bush", "president bush 43", "former president george w bush", "43rd president of united states", "g w b", "george w bussh", "bush jr", "bush younger", "george bush 43rd u s president", "george younger"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "John F", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Dwight D", "Calvin Coolidge's inauguration in 1925", "Lyndon B", "John F", "John F", "Ronald Reagan in 1985", "Dwight D", "Dwight D", "Dwight D", "John F"], "equivalence_results": ["unclear", "different", "different", "same", "same", "different", "different", "different", "different", "same"], "equivalence_stats": {"num_same": 3, "num_different": 6, "num_unclear": 1, "total": 10}, "equivalence_ratio": 0.3333333333333333, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:08:23.721208Z"}
{"question_id": "tqa_rc_validation_185", "question": "Who became Israel's head of state in 1993?", "ground_truth": ["Ezer Weizman", "עזר ויצמן", "Ezer Weizmann"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Ezer Weizman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:08:25.132529Z"}
{"question_id": "tqa_rc_validation_185", "question": "Who became Israel's head of state in 1993?", "ground_truth": ["Ezer Weizman", "עזר ויצמן", "Ezer Weizmann"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Ezer Weizman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:08:27.032198Z"}
{"question_id": "tqa_rc_validation_185", "question": "Who became Israel's head of state in 1993?", "ground_truth": ["Ezer Weizman", "עזר ויצמן", "Ezer Weizmann"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Ezer Weizman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:08:27.251621Z"}
{"question_id": "tqa_rc_validation_185", "question": "Who became Israel's head of state in 1993?", "ground_truth": ["Ezer Weizman", "עזר ויצמן", "Ezer Weizmann"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Ezer Weizman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:08:28.914818Z"}
{"question_id": "tqa_rc_validation_185", "question": "Who became Israel's head of state in 1993?", "ground_truth": ["Ezer Weizman", "עזר ויצמן", "Ezer Weizmann"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Ezer Weizman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:08:29.691440Z"}
{"question_id": "tqa_rc_validation_186", "question": "In WWII, who was the head of the Nazi party's security service?", "ground_truth": ["Reinhard Heidrich", "Rinehardt Heydrich", "Himmler's Evil Genius", "ReinhardHeydrich", "Heidrich, Rinehardt", "Reinhard Hydrich", "Reinhard Hydrick", "The Young Evil God of Death", "Rinehardt Heidrich", "Heydrich", "Heydrich Reinhard", "Reinhard Hidrich", "Reinhard Hidrick", "Rhinehardt Heidrich", "Reinhard Heydrick", "The Butcher of Prague", "Heidrich, Reinhardt", "Heidrich, Rhinehardt", "Reinhardt Heydrich", "Rhinehardt Heydrich", "Reinhard Heydrich", "Rhinehart Heidrich", "Reihnard Heidrich", "Rhinehard Heydrich", "Heydrich Reinhart", "Rheinhard Heydrich", "Heydrich, Reinhard", "Rinehard Heidrich", "Butcher of Prague", "HeydrichReinhardt", "Rhinehart Heydrich", "Heidrich, Rhinehart", "Reinhart heidrich", "ReinhardtHeydrich", "Heydrich, Reinhart", "Heydrich, Reinhardt", "Heydrich,Reinhardt", "Rinehard Heydrich", "Heydrich Reinhardt", "Reinhart Heydrich", "Heidrich, Rinehart", "Young Evil God of Death", "Heidrich, Reinhart", "Rinehart Heydrich", "HeydrichReinhard", "Heydrich,Reinhard", "Reinhard Tristan Eugen Heydrich", "Rhinehard Heidrich", "Heidrich, Rhinehard", "Heidrich, Rinehard", "Heydrich,Reinhart", "Heidrich, Reinhard", "Rinehart Heidrich", "Himler's Evil Genius", "himler s evil genius", "heidrich reinhart", "heidrich rhinehard", "himmler s evil genius", "heidrich rinehart", "heidrich reinhard", "heidrich rhinehart", "heidrich rinehardt", "heidrich rinehard", "heidrich reinhardt", "heidrich rhinehardt"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Reinhard Heydrich", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:08:30.612444Z"}
{"question_id": "tqa_rc_validation_186", "question": "In WWII, who was the head of the Nazi party's security service?", "ground_truth": ["Reinhard Heidrich", "Rinehardt Heydrich", "Himmler's Evil Genius", "ReinhardHeydrich", "Heidrich, Rinehardt", "Reinhard Hydrich", "Reinhard Hydrick", "The Young Evil God of Death", "Rinehardt Heidrich", "Heydrich", "Heydrich Reinhard", "Reinhard Hidrich", "Reinhard Hidrick", "Rhinehardt Heidrich", "Reinhard Heydrick", "The Butcher of Prague", "Heidrich, Reinhardt", "Heidrich, Rhinehardt", "Reinhardt Heydrich", "Rhinehardt Heydrich", "Reinhard Heydrich", "Rhinehart Heidrich", "Reihnard Heidrich", "Rhinehard Heydrich", "Heydrich Reinhart", "Rheinhard Heydrich", "Heydrich, Reinhard", "Rinehard Heidrich", "Butcher of Prague", "HeydrichReinhardt", "Rhinehart Heydrich", "Heidrich, Rhinehart", "Reinhart heidrich", "ReinhardtHeydrich", "Heydrich, Reinhart", "Heydrich, Reinhardt", "Heydrich,Reinhardt", "Rinehard Heydrich", "Heydrich Reinhardt", "Reinhart Heydrich", "Heidrich, Rinehart", "Young Evil God of Death", "Heidrich, Reinhart", "Rinehart Heydrich", "HeydrichReinhard", "Heydrich,Reinhard", "Reinhard Tristan Eugen Heydrich", "Rhinehard Heidrich", "Heidrich, Rhinehard", "Heidrich, Rinehard", "Heydrich,Reinhart", "Heidrich, Reinhard", "Rinehart Heidrich", "Himler's Evil Genius", "himler s evil genius", "heidrich reinhart", "heidrich rhinehard", "himmler s evil genius", "heidrich rinehart", "heidrich reinhard", "heidrich rhinehart", "heidrich rinehardt", "heidrich rinehard", "heidrich reinhardt", "heidrich rhinehardt"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Reinhard Heydrich", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:08:32.398646Z"}
{"question_id": "tqa_rc_validation_6", "question": "What was the last US state to reintroduce alcohol after prohibition?", "ground_truth": ["Utah", "Utah (State)", "Forty-Fifth State", "Sports in Utah", "Climate of Utah", "Education in Utah", "UT (state)", "Utahn", "Yutas", "Geography of Utah", "Utah, United States", "Utah state nickname", "History of mining in Utah", "State of Utah", "Religion in Utah", "Utah (U.S. state)", "Transportation in Utah", "Beehive State", "US-UT", "Utahan", "Politics of Utah", "Salt Lake Seagulls", "45th State", "History of Utah (to 1847)", "The Beehive State", "Youtah", "Transport in Utah", "utah united states", "us ut", "utah state", "forty fifth state", "ut state", "history of utah to 1847", "utah u s state"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Mississippi", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Mississippi", "Mississippi", "Mississippi", "Mississippi", "Kansas", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:08:36.343075Z"}
{"question_id": "tqa_rc_validation_186", "question": "In WWII, who was the head of the Nazi party's security service?", "ground_truth": ["Reinhard Heidrich", "Rinehardt Heydrich", "Himmler's Evil Genius", "ReinhardHeydrich", "Heidrich, Rinehardt", "Reinhard Hydrich", "Reinhard Hydrick", "The Young Evil God of Death", "Rinehardt Heidrich", "Heydrich", "Heydrich Reinhard", "Reinhard Hidrich", "Reinhard Hidrick", "Rhinehardt Heidrich", "Reinhard Heydrick", "The Butcher of Prague", "Heidrich, Reinhardt", "Heidrich, Rhinehardt", "Reinhardt Heydrich", "Rhinehardt Heydrich", "Reinhard Heydrich", "Rhinehart Heidrich", "Reihnard Heidrich", "Rhinehard Heydrich", "Heydrich Reinhart", "Rheinhard Heydrich", "Heydrich, Reinhard", "Rinehard Heidrich", "Butcher of Prague", "HeydrichReinhardt", "Rhinehart Heydrich", "Heidrich, Rhinehart", "Reinhart heidrich", "ReinhardtHeydrich", "Heydrich, Reinhart", "Heydrich, Reinhardt", "Heydrich,Reinhardt", "Rinehard Heydrich", "Heydrich Reinhardt", "Reinhart Heydrich", "Heidrich, Rinehart", "Young Evil God of Death", "Heidrich, Reinhart", "Rinehart Heydrich", "HeydrichReinhard", "Heydrich,Reinhard", "Reinhard Tristan Eugen Heydrich", "Rhinehard Heidrich", "Heidrich, Rhinehard", "Heidrich, Rinehard", "Heydrich,Reinhart", "Heidrich, Reinhard", "Rinehart Heidrich", "Himler's Evil Genius", "himler s evil genius", "heidrich reinhart", "heidrich rhinehard", "himmler s evil genius", "heidrich rinehart", "heidrich reinhard", "heidrich rhinehart", "heidrich rinehardt", "heidrich rinehard", "heidrich reinhardt", "heidrich rhinehardt"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Ernst Kaltenbrunner, however the actual head was Reinhard Heydrich until his death in 1942, after which Heinrich Himmler took over and appointed Kaltenbrunner as his deputy and later chief", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Ernst Kaltenbrunner was not the head for the entire war, the head of the Nazi party's security service was Reinhard Heydrich until his death in 1942, after which Heinrich Himmler took over some of his responsibilities,", "Ernst Kaltenbrunner, however the actual head was Reinhard Heydrich until his death in 1942, after which Heinrich Himmler took over, and then Ernst Kaltenbrunner became the head in 1943", "Ernst Kaltenbrunner, however the actual head was Reinhard Heydrich until his death in 1942, after which Heinrich Himmler took over, and Ernst Kaltenbrunner became the head in 1943", "Ernst Kaltenbrunner, however the actual head was Reinhard Heydrich until his death in 1942, after which Heinrich Himmler oversaw it before Kaltenbrunner took over", "Reinhard Heydrich", "Ernst Kaltenbrunner, however the actual head was Reinhard Heydrich until his death in 1942, after which Heinrich Himmler took over, and then Kaltenbrunner became the head in 1943", "Ernst Kaltenbrunner, however the actual head was Reinhard Heydrich until his death in 1942, after which Heinrich Himmler took over and appointed Kaltenbrunner as his deputy and later chief", "Ernst Kaltenbrunner, however the actual head was Reinhard Heydrich until his death in 1942, after which Heinrich Himmler took over, and then Ernst Kaltenbrunner became the head in 1943", "Ernst Kaltenbrunner, however the actual head was Reinhard Heydrich until his death in 1942, after which Heinrich Himmler took over and then appointed Kaltenbrunner as his deputy and later chief", "Reinhard Heydrich"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "same", "different", "same", "different"], "equivalence_stats": {"num_same": 2, "num_different": 8, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.2, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:08:44.701197Z"}
{"question_id": "tqa_rc_validation_186", "question": "In WWII, who was the head of the Nazi party's security service?", "ground_truth": ["Reinhard Heidrich", "Rinehardt Heydrich", "Himmler's Evil Genius", "ReinhardHeydrich", "Heidrich, Rinehardt", "Reinhard Hydrich", "Reinhard Hydrick", "The Young Evil God of Death", "Rinehardt Heidrich", "Heydrich", "Heydrich Reinhard", "Reinhard Hidrich", "Reinhard Hidrick", "Rhinehardt Heidrich", "Reinhard Heydrick", "The Butcher of Prague", "Heidrich, Reinhardt", "Heidrich, Rhinehardt", "Reinhardt Heydrich", "Rhinehardt Heydrich", "Reinhard Heydrich", "Rhinehart Heidrich", "Reihnard Heidrich", "Rhinehard Heydrich", "Heydrich Reinhart", "Rheinhard Heydrich", "Heydrich, Reinhard", "Rinehard Heidrich", "Butcher of Prague", "HeydrichReinhardt", "Rhinehart Heydrich", "Heidrich, Rhinehart", "Reinhart heidrich", "ReinhardtHeydrich", "Heydrich, Reinhart", "Heydrich, Reinhardt", "Heydrich,Reinhardt", "Rinehard Heydrich", "Heydrich Reinhardt", "Reinhart Heydrich", "Heidrich, Rinehart", "Young Evil God of Death", "Heidrich, Reinhart", "Rinehart Heydrich", "HeydrichReinhard", "Heydrich,Reinhard", "Reinhard Tristan Eugen Heydrich", "Rhinehard Heidrich", "Heidrich, Rhinehard", "Heidrich, Rinehard", "Heydrich,Reinhart", "Heidrich, Reinhard", "Rinehart Heidrich", "Himler's Evil Genius", "himler s evil genius", "heidrich reinhart", "heidrich rhinehard", "himmler s evil genius", "heidrich rinehart", "heidrich reinhard", "heidrich rhinehart", "heidrich rinehardt", "heidrich rinehard", "heidrich reinhardt", "heidrich rhinehardt"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Reinhard Heydrich", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:08:46.106348Z"}
{"question_id": "tqa_rc_validation_186", "question": "In WWII, who was the head of the Nazi party's security service?", "ground_truth": ["Reinhard Heidrich", "Rinehardt Heydrich", "Himmler's Evil Genius", "ReinhardHeydrich", "Heidrich, Rinehardt", "Reinhard Hydrich", "Reinhard Hydrick", "The Young Evil God of Death", "Rinehardt Heidrich", "Heydrich", "Heydrich Reinhard", "Reinhard Hidrich", "Reinhard Hidrick", "Rhinehardt Heidrich", "Reinhard Heydrick", "The Butcher of Prague", "Heidrich, Reinhardt", "Heidrich, Rhinehardt", "Reinhardt Heydrich", "Rhinehardt Heydrich", "Reinhard Heydrich", "Rhinehart Heidrich", "Reihnard Heidrich", "Rhinehard Heydrich", "Heydrich Reinhart", "Rheinhard Heydrich", "Heydrich, Reinhard", "Rinehard Heidrich", "Butcher of Prague", "HeydrichReinhardt", "Rhinehart Heydrich", "Heidrich, Rhinehart", "Reinhart heidrich", "ReinhardtHeydrich", "Heydrich, Reinhart", "Heydrich, Reinhardt", "Heydrich,Reinhardt", "Rinehard Heydrich", "Heydrich Reinhardt", "Reinhart Heydrich", "Heidrich, Rinehart", "Young Evil God of Death", "Heidrich, Reinhart", "Rinehart Heydrich", "HeydrichReinhard", "Heydrich,Reinhard", "Reinhard Tristan Eugen Heydrich", "Rhinehard Heidrich", "Heidrich, Rhinehard", "Heidrich, Rinehard", "Heydrich,Reinhart", "Heidrich, Reinhard", "Rinehart Heidrich", "Himler's Evil Genius", "himler s evil genius", "heidrich reinhart", "heidrich rhinehard", "himmler s evil genius", "heidrich rinehart", "heidrich reinhard", "heidrich rhinehart", "heidrich rinehardt", "heidrich rinehard", "heidrich reinhardt", "heidrich rhinehardt"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Heinrich Himmler", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Heinrich Himmler", "Heinrich Himmler", "Heinrich Himmler", "Heinrich Himmler", "Heinrich Himmler", "Heinrich Himmler", "Heinrich Himmler", "Heinrich Himmler", "Heinrich Himmler", "Heinrich Himmler"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:09:03.774119Z"}
{"question_id": "tqa_rc_validation_187", "question": "Which President of the Philippines was deposed in 1986?", "ground_truth": ["Marcos", "Marcos (disambiguation)", "Markos", "marcos disambiguation"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Ferdinand Marcos", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:04.565187Z"}
{"question_id": "tqa_rc_validation_187", "question": "Which President of the Philippines was deposed in 1986?", "ground_truth": ["Marcos", "Marcos (disambiguation)", "Markos", "marcos disambiguation"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Ferdinand Marcos", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:06.158864Z"}
{"question_id": "tqa_rc_validation_187", "question": "Which President of the Philippines was deposed in 1986?", "ground_truth": ["Marcos", "Marcos (disambiguation)", "Markos", "marcos disambiguation"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Ferdinand Marcos", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:06.626828Z"}
{"question_id": "tqa_rc_validation_187", "question": "Which President of the Philippines was deposed in 1986?", "ground_truth": ["Marcos", "Marcos (disambiguation)", "Markos", "marcos disambiguation"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Ferdinand Marcos", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:07.954966Z"}
{"question_id": "tqa_rc_validation_187", "question": "Which President of the Philippines was deposed in 1986?", "ground_truth": ["Marcos", "Marcos (disambiguation)", "Markos", "marcos disambiguation"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Ferdinand Marcos", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:08.681690Z"}
{"question_id": "tqa_rc_validation_188", "question": "What kind of disaster claimed some 100,000 lives in Armenia in 1988?", "ground_truth": ["Earthquake", "Seism", "Seismic event", "The kinds of earthquakes", "Seismically active", "Low-magnitude earthquake", "Earth tremor", "Causes of earthquakes", "Seismic movement", "Earth quakes", "Earthshake", "Seismic activity", "Quake weapons", "Seismicity", "地震", "Earth quake", "Main shock", "Site effects (earthquake)", "Earthquakes", "Speedjump", "Tectonic earthquake", "kinds of earthquakes", "site effects earthquake", "low magnitude earthquake"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "An earthquake", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:09.531595Z"}
{"question_id": "tqa_rc_validation_188", "question": "What kind of disaster claimed some 100,000 lives in Armenia in 1988?", "ground_truth": ["Earthquake", "Seism", "Seismic event", "The kinds of earthquakes", "Seismically active", "Low-magnitude earthquake", "Earth tremor", "Causes of earthquakes", "Seismic movement", "Earth quakes", "Earthshake", "Seismic activity", "Quake weapons", "Seismicity", "地震", "Earth quake", "Main shock", "Site effects (earthquake)", "Earthquakes", "Speedjump", "Tectonic earthquake", "kinds of earthquakes", "site effects earthquake", "low magnitude earthquake"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Earthquake", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:11.118940Z"}
{"question_id": "tqa_rc_validation_188", "question": "What kind of disaster claimed some 100,000 lives in Armenia in 1988?", "ground_truth": ["Earthquake", "Seism", "Seismic event", "The kinds of earthquakes", "Seismically active", "Low-magnitude earthquake", "Earth tremor", "Causes of earthquakes", "Seismic movement", "Earth quakes", "Earthshake", "Seismic activity", "Quake weapons", "Seismicity", "地震", "Earth quake", "Main shock", "Site effects (earthquake)", "Earthquakes", "Speedjump", "Tectonic earthquake", "kinds of earthquakes", "site effects earthquake", "low magnitude earthquake"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Earthquake", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:11.268576Z"}
{"question_id": "tqa_rc_validation_188", "question": "What kind of disaster claimed some 100,000 lives in Armenia in 1988?", "ground_truth": ["Earthquake", "Seism", "Seismic event", "The kinds of earthquakes", "Seismically active", "Low-magnitude earthquake", "Earth tremor", "Causes of earthquakes", "Seismic movement", "Earth quakes", "Earthshake", "Seismic activity", "Quake weapons", "Seismicity", "地震", "Earth quake", "Main shock", "Site effects (earthquake)", "Earthquakes", "Speedjump", "Tectonic earthquake", "kinds of earthquakes", "site effects earthquake", "low magnitude earthquake"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Earthquake", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:12.747874Z"}
{"question_id": "tqa_rc_validation_188", "question": "What kind of disaster claimed some 100,000 lives in Armenia in 1988?", "ground_truth": ["Earthquake", "Seism", "Seismic event", "The kinds of earthquakes", "Seismically active", "Low-magnitude earthquake", "Earth tremor", "Causes of earthquakes", "Seismic movement", "Earth quakes", "Earthshake", "Seismic activity", "Quake weapons", "Seismicity", "地震", "Earth quake", "Main shock", "Site effects (earthquake)", "Earthquakes", "Speedjump", "Tectonic earthquake", "kinds of earthquakes", "site effects earthquake", "low magnitude earthquake"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Earthquake", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:13.607174Z"}
{"question_id": "tqa_rc_validation_189", "question": "Which state on the Gulf of Mexico is nearest the end of the alphabet?", "ground_truth": ["Texas", "Texas (U.S. State)", "US-TX", "Texos", "Lone Star State", "Texas, USA", "Religion in Texas", "Texas (state)", "Lake Ozark, Texas", "Christianity in Texas", "The State of Texas", "Twenty-eighth State", "Texas-sized", "28th State", "The Lone Star State", "Texas, United States", "Texass", "State of Texas", "Everything is bigger in Texas", "texas u s state", "us tx", "lake ozark texas", "twenty eighth state", "texas state", "texas sized", "texas usa", "texas united states"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Texas", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:14.488719Z"}
{"question_id": "tqa_rc_validation_189", "question": "Which state on the Gulf of Mexico is nearest the end of the alphabet?", "ground_truth": ["Texas", "Texas (U.S. State)", "US-TX", "Texos", "Lone Star State", "Texas, USA", "Religion in Texas", "Texas (state)", "Lake Ozark, Texas", "Christianity in Texas", "The State of Texas", "Twenty-eighth State", "Texas-sized", "28th State", "The Lone Star State", "Texas, United States", "Texass", "State of Texas", "Everything is bigger in Texas", "texas u s state", "us tx", "lake ozark texas", "twenty eighth state", "texas state", "texas sized", "texas usa", "texas united states"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Texas", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:15.929251Z"}
{"question_id": "tqa_rc_validation_189", "question": "Which state on the Gulf of Mexico is nearest the end of the alphabet?", "ground_truth": ["Texas", "Texas (U.S. State)", "US-TX", "Texos", "Lone Star State", "Texas, USA", "Religion in Texas", "Texas (state)", "Lake Ozark, Texas", "Christianity in Texas", "The State of Texas", "Twenty-eighth State", "Texas-sized", "28th State", "The Lone Star State", "Texas, United States", "Texass", "State of Texas", "Everything is bigger in Texas", "texas u s state", "us tx", "lake ozark texas", "twenty eighth state", "texas state", "texas sized", "texas usa", "texas united states"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Texas", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:16.070043Z"}
{"question_id": "tqa_rc_validation_189", "question": "Which state on the Gulf of Mexico is nearest the end of the alphabet?", "ground_truth": ["Texas", "Texas (U.S. State)", "US-TX", "Texos", "Lone Star State", "Texas, USA", "Religion in Texas", "Texas (state)", "Lake Ozark, Texas", "Christianity in Texas", "The State of Texas", "Twenty-eighth State", "Texas-sized", "28th State", "The Lone Star State", "Texas, United States", "Texass", "State of Texas", "Everything is bigger in Texas", "texas u s state", "us tx", "lake ozark texas", "twenty eighth state", "texas state", "texas sized", "texas usa", "texas united states"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Texas", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:17.308988Z"}
{"question_id": "tqa_rc_validation_189", "question": "Which state on the Gulf of Mexico is nearest the end of the alphabet?", "ground_truth": ["Texas", "Texas (U.S. State)", "US-TX", "Texos", "Lone Star State", "Texas, USA", "Religion in Texas", "Texas (state)", "Lake Ozark, Texas", "Christianity in Texas", "The State of Texas", "Twenty-eighth State", "Texas-sized", "28th State", "The Lone Star State", "Texas, United States", "Texass", "State of Texas", "Everything is bigger in Texas", "texas u s state", "us tx", "lake ozark texas", "twenty eighth state", "texas state", "texas sized", "texas usa", "texas united states"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Texas", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:17.966448Z"}
{"question_id": "tqa_rc_validation_190", "question": "Truax Field international airport is in which US state?", "ground_truth": ["Wisconsin", "Badger State", "State of Wisconsin", "Wis.", "Transportation in Wisconsin", "Government of Wisconsin", "Climate of Wisconsin", "Wisconsin, USA", "Wiscosin, USA", "30th State", "Wisconson", "Politics of Wisconsin", "Demographics of Wisconsin", "America's Dairyland", "Winconsin", "Religion in Wisconsin", "Transport in Wisconsin", "US-WI", "Wisconsin state", "Economy of Wisconsin", "The Badger State", "Wisconsin (state)", "Education in Wisconsin", "Geography of Wisconsin", "Wiskonsin", "Wisconsin (U.S. state)", "Thirtieth State", "Film industry in Wisconsin", "Wisc.", "Wisconsin, United States", "wisc", "wis", "wisconsin united states", "wisconsin u s state", "wisconsin usa", "wiscosin usa", "america s dairyland", "us wi"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Wisconsin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:18.717682Z"}
{"question_id": "tqa_rc_validation_190", "question": "Truax Field international airport is in which US state?", "ground_truth": ["Wisconsin", "Badger State", "State of Wisconsin", "Wis.", "Transportation in Wisconsin", "Government of Wisconsin", "Climate of Wisconsin", "Wisconsin, USA", "Wiscosin, USA", "30th State", "Wisconson", "Politics of Wisconsin", "Demographics of Wisconsin", "America's Dairyland", "Winconsin", "Religion in Wisconsin", "Transport in Wisconsin", "US-WI", "Wisconsin state", "Economy of Wisconsin", "The Badger State", "Wisconsin (state)", "Education in Wisconsin", "Geography of Wisconsin", "Wiskonsin", "Wisconsin (U.S. state)", "Thirtieth State", "Film industry in Wisconsin", "Wisc.", "Wisconsin, United States", "wisc", "wis", "wisconsin united states", "wisconsin u s state", "wisconsin usa", "wiscosin usa", "america s dairyland", "us wi"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Wisconsin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:19.628233Z"}
{"question_id": "tqa_rc_validation_190", "question": "Truax Field international airport is in which US state?", "ground_truth": ["Wisconsin", "Badger State", "State of Wisconsin", "Wis.", "Transportation in Wisconsin", "Government of Wisconsin", "Climate of Wisconsin", "Wisconsin, USA", "Wiscosin, USA", "30th State", "Wisconson", "Politics of Wisconsin", "Demographics of Wisconsin", "America's Dairyland", "Winconsin", "Religion in Wisconsin", "Transport in Wisconsin", "US-WI", "Wisconsin state", "Economy of Wisconsin", "The Badger State", "Wisconsin (state)", "Education in Wisconsin", "Geography of Wisconsin", "Wiskonsin", "Wisconsin (U.S. state)", "Thirtieth State", "Film industry in Wisconsin", "Wisc.", "Wisconsin, United States", "wisc", "wis", "wisconsin united states", "wisconsin u s state", "wisconsin usa", "wiscosin usa", "america s dairyland", "us wi"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Wisconsin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:20.064889Z"}
{"question_id": "tqa_rc_validation_190", "question": "Truax Field international airport is in which US state?", "ground_truth": ["Wisconsin", "Badger State", "State of Wisconsin", "Wis.", "Transportation in Wisconsin", "Government of Wisconsin", "Climate of Wisconsin", "Wisconsin, USA", "Wiscosin, USA", "30th State", "Wisconson", "Politics of Wisconsin", "Demographics of Wisconsin", "America's Dairyland", "Winconsin", "Religion in Wisconsin", "Transport in Wisconsin", "US-WI", "Wisconsin state", "Economy of Wisconsin", "The Badger State", "Wisconsin (state)", "Education in Wisconsin", "Geography of Wisconsin", "Wiskonsin", "Wisconsin (U.S. state)", "Thirtieth State", "Film industry in Wisconsin", "Wisc.", "Wisconsin, United States", "wisc", "wis", "wisconsin united states", "wisconsin u s state", "wisconsin usa", "wiscosin usa", "america s dairyland", "us wi"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Wisconsin", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:21.614101Z"}
{"question_id": "tqa_rc_validation_190", "question": "Truax Field international airport is in which US state?", "ground_truth": ["Wisconsin", "Badger State", "State of Wisconsin", "Wis.", "Transportation in Wisconsin", "Government of Wisconsin", "Climate of Wisconsin", "Wisconsin, USA", "Wiscosin, USA", "30th State", "Wisconson", "Politics of Wisconsin", "Demographics of Wisconsin", "America's Dairyland", "Winconsin", "Religion in Wisconsin", "Transport in Wisconsin", "US-WI", "Wisconsin state", "Economy of Wisconsin", "The Badger State", "Wisconsin (state)", "Education in Wisconsin", "Geography of Wisconsin", "Wiskonsin", "Wisconsin (U.S. state)", "Thirtieth State", "Film industry in Wisconsin", "Wisc.", "Wisconsin, United States", "wisc", "wis", "wisconsin united states", "wisconsin u s state", "wisconsin usa", "wiscosin usa", "america s dairyland", "us wi"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Iowa", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Nebraska", "Iowa", "Nebraska", "Iowa", "Iowa", "Truax Field is in the US state of Wisconsin", "Iowa", "Iowa", "Nevada", "Iowa"], "equivalence_results": ["different", "same", "different", "same", "same", "different", "same", "same", "different", "same"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:09:37.532677Z"}
{"question_id": "tqa_rc_validation_191", "question": "In what month was the attack on Pearl Harbor?", "ground_truth": ["December", "㋋", "Xber", "Dec.", "Decembre", "dec"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "December", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:38.447341Z"}
{"question_id": "tqa_rc_validation_191", "question": "In what month was the attack on Pearl Harbor?", "ground_truth": ["December", "㋋", "Xber", "Dec.", "Decembre", "dec"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "December", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:39.950020Z"}
{"question_id": "tqa_rc_validation_191", "question": "In what month was the attack on Pearl Harbor?", "ground_truth": ["December", "㋋", "Xber", "Dec.", "Decembre", "dec"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "December", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:40.150149Z"}
{"question_id": "tqa_rc_validation_191", "question": "In what month was the attack on Pearl Harbor?", "ground_truth": ["December", "㋋", "Xber", "Dec.", "Decembre", "dec"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "December", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:41.258883Z"}
{"question_id": "tqa_rc_validation_191", "question": "In what month was the attack on Pearl Harbor?", "ground_truth": ["December", "㋋", "Xber", "Dec.", "Decembre", "dec"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "December", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:09:42.154655Z"}
{"question_id": "tqa_rc_validation_192", "question": "Who did Dr. Crippen murder?", "ground_truth": ["His wife"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Cora Henrietta Crippen (Belle Elmore)", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Cora Henrietta Crippen (his wife)", "Cora Henrietta Crippen (his wife, known as Belle Elmore)", "Cora Henrietta Crippen (his wife)", "Cora Henrietta Crippen (his wife)", "Cora Henrietta “Belle” Crippen (his wife)", "Cora Henrietta Crippen (Belle Elmore)", "Cora Henrietta Crippen (Belle Elmore)", "Cora Crippen (his wife, Belle Elmore)", "Cora Henrietta Crippen (Belle Elmore)", "Cora Henrietta Crippen (his wife, known as Belle Elmore)"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:10:02.967539Z"}
{"question_id": "tqa_rc_validation_192", "question": "Who did Dr. Crippen murder?", "ground_truth": ["His wife"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "His wife, Cora Crippen (also known as Belle Elmore)", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:10:05.093535Z"}
{"question_id": "tqa_rc_validation_192", "question": "Who did Dr. Crippen murder?", "ground_truth": ["His wife"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "His wife, Cora Henrietta Crippen", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:10:17.309903Z"}
{"question_id": "tqa_rc_validation_192", "question": "Who did Dr. Crippen murder?", "ground_truth": ["His wife"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "His wife, Cora Crippen", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:10:18.698505Z"}
{"question_id": "tqa_rc_validation_192", "question": "Who did Dr. Crippen murder?", "ground_truth": ["His wife"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "His wife, Cora Henrietta Crippen", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["His wife, Cora Henrietta Crippen", "His wife Cora Crippen", "His wife, Cora Henrietta Crippen", "Helen Crippen (née Barlow), his wife", "His wife, Cora Henrietta Crippen", "His wife Cora Crippen", "His wife Cora Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Henrietta Crippen", "His wife, Cora Crippen"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:10:35.934288Z"}
{"question_id": "tqa_rc_validation_193", "question": "In the 1904 Olympics, how many of the 23 track and field titles were won by Americans?", "ground_truth": ["21", "twenty-one", "twenty one"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "22", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["22", "22", "21", "22", "22", "22", "22", "22", "22", "21"], "equivalence_results": ["same", "same", "different", "same", "same", "same", "same", "same", "same", "different"], "equivalence_stats": {"num_same": 8, "num_different": 2, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.8, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:10:53.521998Z"}
{"question_id": "tqa_rc_validation_193", "question": "In the 1904 Olympics, how many of the 23 track and field titles were won by Americans?", "ground_truth": ["21", "twenty-one", "twenty one"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "23", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["23", "23", "23", "23", "23", "23", "23", "23", "23", "23"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:11:17.818075Z"}
{"question_id": "tqa_rc_validation_193", "question": "In the 1904 Olympics, how many of the 23 track and field titles were won by Americans?", "ground_truth": ["21", "twenty-one", "twenty one"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "21", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:11:18.087026Z"}
{"question_id": "tqa_rc_validation_193", "question": "In the 1904 Olympics, how many of the 23 track and field titles were won by Americans?", "ground_truth": ["21", "twenty-one", "twenty one"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "21", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:11:19.283384Z"}
{"question_id": "tqa_rc_validation_193", "question": "In the 1904 Olympics, how many of the 23 track and field titles were won by Americans?", "ground_truth": ["21", "twenty-one", "twenty one"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "12", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["16", "23", "13", "15", "8", "20", "12", "15", "20", "13"], "equivalence_results": ["different", "different", "different", "different", "different", "different", "same", "different", "different", "different"], "equivalence_stats": {"num_same": 1, "num_different": 9, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.1, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:11:35.567929Z"}
{"question_id": "tqa_rc_validation_194", "question": "The Black Hills lie between which two rivers?", "ground_truth": ["Belle Fourche and Cheyenne"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "The Cheyenne River and the Belle Fourche River", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:11:55.427305Z"}
{"question_id": "tqa_rc_validation_194", "question": "The Black Hills lie between which two rivers?", "ground_truth": ["Belle Fourche and Cheyenne"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "The Cheyenne River and the Belle Fourche River", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:12:23.401342Z"}
{"question_id": "tqa_rc_validation_194", "question": "The Black Hills lie between which two rivers?", "ground_truth": ["Belle Fourche and Cheyenne"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "The Cheyenne River and the Belle Fourche River", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:12:33.092700Z"}
{"question_id": "tqa_rc_validation_194", "question": "The Black Hills lie between which two rivers?", "ground_truth": ["Belle Fourche and Cheyenne"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Cheyenne River and Belle Fourche River", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Cheyenne River and Belle Fourche River", "Cheyenne River and Belle Fourche River", "Cheyenne River and Belle Fourche River", "Cheyenne River and Belle Fourche River", "Cheyenne River and Belle Fourche River", "Cheyenne River and Belle Fourche River", "Cheyenne River and Belle Fourche River", "Cheyenne River and Belle Fourche River", "Cheyenne River and Belle Fourche River", "Cheyenne River and Belle Fourche River"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:12:55.818875Z"}
{"question_id": "tqa_rc_validation_194", "question": "The Black Hills lie between which two rivers?", "ground_truth": ["Belle Fourche and Cheyenne"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "The Cheyenne and the Belle Fourche rivers", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["The Cheyenne and the Belle Fourche rivers", "The Black Hills lie between the Cheyenne River and the Belle Fourche River", "The Cheyenne and the Belle Fourche rivers", "The Black Hills lie between the Cheyenne River and the Belle Fourche River", "The Cheyenne River and the Belle Fourche River", "The Black Hills lie between the Cheyenne River and the Belle Fourche River", "The Cheyenne and Belle Fourche rivers", "The Cheyenne River and the Belle Fourche River", "The Cheyenne and Belle Fourche rivers", "The Cheyenne and the Belle Fourche rivers"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:13:12.621903Z"}
{"question_id": "tqa_rc_validation_195", "question": "In what year was the first in-flight movie shown on an internal flight in the USA.", "ground_truth": ["1929", "one thousand, nine hundred and twenty-nine", "one thousand nine hundred and twenty nine"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "1921", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1925", "1921", "1925", "1921", "1921", "1921", "1925", "1921", "1921", "1921"], "equivalence_results": ["different", "same", "different", "same", "same", "same", "different", "same", "same", "same"], "equivalence_stats": {"num_same": 7, "num_different": 3, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.7, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:13:30.439398Z"}
{"question_id": "tqa_rc_validation_195", "question": "In what year was the first in-flight movie shown on an internal flight in the USA.", "ground_truth": ["1929", "one thousand, nine hundred and twenty-nine", "one thousand nine hundred and twenty nine"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "1925", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1925", "1925", "1925", "1925", "1925", "1925", "1925", "1925", "1925", "1925"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:13:57.022474Z"}
{"question_id": "tqa_rc_validation_195", "question": "In what year was the first in-flight movie shown on an internal flight in the USA.", "ground_truth": ["1929", "one thousand, nine hundred and twenty-nine", "one thousand nine hundred and twenty nine"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "1961", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1961", "1961", "1961", "1961", "1961", "1961", "1961", "1961", "1961", "1961"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:14:06.698038Z"}
{"question_id": "tqa_rc_validation_195", "question": "In what year was the first in-flight movie shown on an internal flight in the USA.", "ground_truth": ["1929", "one thousand, nine hundred and twenty-nine", "one thousand nine hundred and twenty nine"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "1921", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1921", "1921", "1921", "1921", "1921", "1921", "1921", "1921", "1921", "1921"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:14:28.370353Z"}
{"question_id": "tqa_rc_validation_195", "question": "In what year was the first in-flight movie shown on an internal flight in the USA.", "ground_truth": ["1929", "one thousand, nine hundred and twenty-nine", "one thousand nine hundred and twenty nine"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "1933", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["1942", "1933", "1933", "1933", "1952", "1933", "1933", "1933", "1942", "1942"], "equivalence_results": ["different", "same", "same", "same", "different", "same", "same", "same", "different", "different"], "equivalence_stats": {"num_same": 6, "num_different": 4, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.6, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:14:45.180799Z"}
{"question_id": "tqa_rc_validation_196", "question": "In which city was John Lennon murdered?", "ground_truth": ["New York", "New Yourk State", "State of N.Y.", "US-NY", "N Y", "The state of NY", "NewYork", "NYS", "Neo York", "NY state", "Nova York", "State of new york", "Ny", "Nueva York (estado)", "N Y state", "New York (state)", "U.S. state of New York", "New York state", "New York, U.S.", "State New York", "Nýja-Jórvík", "State of N. Y.", "N. Y. state", "The state of N.Y.", "NY (state)", "New York's", "N.Y. (U.S. state)", "State of new yourk", "New York (U.S. state)", "New Yrok", "11th State", "New York (USA State)", "State of N Y", "New-York", "The State of New York", "US state of New York", "N Y (U.S. state)", "N.Y. state", "N.Y.", "The state of N. Y.", "N. Y. (state)", "The state of N Y", "New York, US", "N.Y. (state)", "Nyja-Jorvik", "Religion in New York", "New Yourk", "N. Y.", "New York State's", "Estado Nueva York", "New york population", "New York, U.S.A", "NY (U.S. state)", "Estado de Nueva York", "N. Y. (U.S. state)", "Eleventh State", "N Y (state)", "State of NY", "New York (U.S. state", "us ny", "new york state s", "nýja jórvík", "new york us", "u s state of new york", "new york u s", "new york s", "n y u s state", "new york usa state", "nyja jorvik", "nueva york estado", "new york u s state", "ny u s state"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "New York City", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:14:45.976090Z"}
{"question_id": "tqa_rc_validation_196", "question": "In which city was John Lennon murdered?", "ground_truth": ["New York", "New Yourk State", "State of N.Y.", "US-NY", "N Y", "The state of NY", "NewYork", "NYS", "Neo York", "NY state", "Nova York", "State of new york", "Ny", "Nueva York (estado)", "N Y state", "New York (state)", "U.S. state of New York", "New York state", "New York, U.S.", "State New York", "Nýja-Jórvík", "State of N. Y.", "N. Y. state", "The state of N.Y.", "NY (state)", "New York's", "N.Y. (U.S. state)", "State of new yourk", "New York (U.S. state)", "New Yrok", "11th State", "New York (USA State)", "State of N Y", "New-York", "The State of New York", "US state of New York", "N Y (U.S. state)", "N.Y. state", "N.Y.", "The state of N. Y.", "N. Y. (state)", "The state of N Y", "New York, US", "N.Y. (state)", "Nyja-Jorvik", "Religion in New York", "New Yourk", "N. Y.", "New York State's", "Estado Nueva York", "New york population", "New York, U.S.A", "NY (U.S. state)", "Estado de Nueva York", "N. Y. (U.S. state)", "Eleventh State", "N Y (state)", "State of NY", "New York (U.S. state", "us ny", "new york state s", "nýja jórvík", "new york us", "u s state of new york", "new york u s", "new york s", "n y u s state", "new york usa state", "nyja jorvik", "nueva york estado", "new york u s state", "ny u s state"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "New York City", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:14:47.465475Z"}
{"question_id": "tqa_rc_validation_196", "question": "In which city was John Lennon murdered?", "ground_truth": ["New York", "New Yourk State", "State of N.Y.", "US-NY", "N Y", "The state of NY", "NewYork", "NYS", "Neo York", "NY state", "Nova York", "State of new york", "Ny", "Nueva York (estado)", "N Y state", "New York (state)", "U.S. state of New York", "New York state", "New York, U.S.", "State New York", "Nýja-Jórvík", "State of N. Y.", "N. Y. state", "The state of N.Y.", "NY (state)", "New York's", "N.Y. (U.S. state)", "State of new yourk", "New York (U.S. state)", "New Yrok", "11th State", "New York (USA State)", "State of N Y", "New-York", "The State of New York", "US state of New York", "N Y (U.S. state)", "N.Y. state", "N.Y.", "The state of N. Y.", "N. Y. (state)", "The state of N Y", "New York, US", "N.Y. (state)", "Nyja-Jorvik", "Religion in New York", "New Yourk", "N. Y.", "New York State's", "Estado Nueva York", "New york population", "New York, U.S.A", "NY (U.S. state)", "Estado de Nueva York", "N. Y. (U.S. state)", "Eleventh State", "N Y (state)", "State of NY", "New York (U.S. state", "us ny", "new york state s", "nýja jórvík", "new york us", "u s state of new york", "new york u s", "new york s", "n y u s state", "new york usa state", "nyja jorvik", "nueva york estado", "new york u s state", "ny u s state"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "New York City", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:14:47.915290Z"}
{"question_id": "tqa_rc_validation_196", "question": "In which city was John Lennon murdered?", "ground_truth": ["New York", "New Yourk State", "State of N.Y.", "US-NY", "N Y", "The state of NY", "NewYork", "NYS", "Neo York", "NY state", "Nova York", "State of new york", "Ny", "Nueva York (estado)", "N Y state", "New York (state)", "U.S. state of New York", "New York state", "New York, U.S.", "State New York", "Nýja-Jórvík", "State of N. Y.", "N. Y. state", "The state of N.Y.", "NY (state)", "New York's", "N.Y. (U.S. state)", "State of new yourk", "New York (U.S. state)", "New Yrok", "11th State", "New York (USA State)", "State of N Y", "New-York", "The State of New York", "US state of New York", "N Y (U.S. state)", "N.Y. state", "N.Y.", "The state of N. Y.", "N. Y. (state)", "The state of N Y", "New York, US", "N.Y. (state)", "Nyja-Jorvik", "Religion in New York", "New Yourk", "N. Y.", "New York State's", "Estado Nueva York", "New york population", "New York, U.S.A", "NY (U.S. state)", "Estado de Nueva York", "N. Y. (U.S. state)", "Eleventh State", "N Y (state)", "State of NY", "New York (U.S. state", "us ny", "new york state s", "nýja jórvík", "new york us", "u s state of new york", "new york u s", "new york s", "n y u s state", "new york usa state", "nyja jorvik", "nueva york estado", "new york u s state", "ny u s state"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "New York City", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:14:49.011476Z"}
{"question_id": "tqa_rc_validation_196", "question": "In which city was John Lennon murdered?", "ground_truth": ["New York", "New Yourk State", "State of N.Y.", "US-NY", "N Y", "The state of NY", "NewYork", "NYS", "Neo York", "NY state", "Nova York", "State of new york", "Ny", "Nueva York (estado)", "N Y state", "New York (state)", "U.S. state of New York", "New York state", "New York, U.S.", "State New York", "Nýja-Jórvík", "State of N. Y.", "N. Y. state", "The state of N.Y.", "NY (state)", "New York's", "N.Y. (U.S. state)", "State of new yourk", "New York (U.S. state)", "New Yrok", "11th State", "New York (USA State)", "State of N Y", "New-York", "The State of New York", "US state of New York", "N Y (U.S. state)", "N.Y. state", "N.Y.", "The state of N. Y.", "N. Y. (state)", "The state of N Y", "New York, US", "N.Y. (state)", "Nyja-Jorvik", "Religion in New York", "New Yourk", "N. Y.", "New York State's", "Estado Nueva York", "New york population", "New York, U.S.A", "NY (U.S. state)", "Estado de Nueva York", "N. Y. (U.S. state)", "Eleventh State", "N Y (state)", "State of NY", "New York (U.S. state", "us ny", "new york state s", "nýja jórvík", "new york us", "u s state of new york", "new york u s", "new york s", "n y u s state", "new york usa state", "nyja jorvik", "nueva york estado", "new york u s state", "ny u s state"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "New York City", "greedy_correct": true, "correctness_match_type": "prediction_contains_gold", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:14:49.877040Z"}
{"question_id": "tqa_rc_validation_197", "question": "How was President Kennedy assassinated?", "ground_truth": ["Shot", "Shot (unit)", "Shot (drink)", "Shot (beverage)", "Shot (disambiguation)", "Shot (alcohol)", "shot unit", "shot disambiguation", "shot drink", "shot alcohol", "shot beverage"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "President John F", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["He was shot while riding in a motorcade in Dallas, Texas, on November 22, 1963", "President Kennedy was assassinated by being shot while riding in a motorcade in Dallas, Texas, on November 22, 1963", "President Kennedy was assassinated by being shot while riding in a motorcade in Dallas, Texas, on November 22, 1963", "President Kennedy was assassinated by being shot while riding in a motorcade in Dallas, Texas, on November 22, 1963", "President Kennedy was assassinated by being shot while riding in a motorcade in Dallas, Texas, on November 22, 1963", "He was shot while riding in a motorcade in Dallas, Texas, on November 22, 1963", "He was shot while riding in a motorcade in Dallas, Texas, on November 22, 1963", "He was shot by Lee Harvey Oswald while riding in a motorcade in Dallas, Texas", "He was shot by Lee Harvey Oswald while riding in a motorcade in Dallas, Texas", "He was shot by Lee Harvey Oswald while riding in a motorcade in Dallas, Texas"], "equivalence_results": ["different", "different", "different", "different", "different", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 5, "num_unclear": 5, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:15:11.082327Z"}
{"question_id": "tqa_rc_validation_197", "question": "How was President Kennedy assassinated?", "ground_truth": ["Shot", "Shot (unit)", "Shot (drink)", "Shot (beverage)", "Shot (disambiguation)", "Shot (alcohol)", "shot unit", "shot disambiguation", "shot drink", "shot alcohol", "shot beverage"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "He was shot in Dallas, Texas, on November 22, 1963", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["He was shot in Dallas, Texas, on November 22, 1963", "He was shot in Dallas, Texas, on November 22, 1963", "He was shot in Dallas, Texas, on November 22, 1963", "He was shot in Dallas, Texas, on November 22, 1963", "He was shot in Dallas, Texas, on November 22, 1963", "He was shot in Dallas, Texas, on November 22, 1963", "He was shot in Dallas, Texas, on November 22, 1963", "He was shot while riding in a presidential motorcade in Dallas, Texas, on November 22, 1963", "He was shot in Dallas, Texas, on November 22, 1963", "He was shot in Dallas, Texas, on November 22, 1963"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:15:39.853754Z"}
{"question_id": "tqa_rc_validation_197", "question": "How was President Kennedy assassinated?", "ground_truth": ["Shot", "Shot (unit)", "Shot (drink)", "Shot (beverage)", "Shot (disambiguation)", "Shot (alcohol)", "shot unit", "shot disambiguation", "shot drink", "shot alcohol", "shot beverage"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "He was shot while riding in an open-top car in a motorcade in Dallas, Texas", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["He was shot while riding in an open-top car in a motorcade in Dallas, Texas", "He was shot while riding in an open-top car in a motorcade in Dallas, Texas", "He was shot while riding in an open-top car in a motorcade in Dallas, Texas", "He was shot while riding in an open-top car in a motorcade in Dallas, Texas", "He was shot while riding in an open-top car in a motorcade in Dallas, Texas", "He was shot while riding in an open-top car in a motorcade in Dallas, Texas", "He was shot while riding in an open-top car in a motorcade in Dallas, Texas", "By being shot", "He was shot while riding in an open-top car in a motorcade in Dallas, Texas", "He was shot while riding in an open-top car in a motorcade in Dallas, Texas"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "different", "same", "same"], "equivalence_stats": {"num_same": 9, "num_different": 1, "num_unclear": 0, "total": 10}, "equivalence_ratio": 0.9, "error_label_1.0": "inconsistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:15:50.445832Z"}
{"question_id": "tqa_rc_validation_197", "question": "How was President Kennedy assassinated?", "ground_truth": ["Shot", "Shot (unit)", "Shot (drink)", "Shot (beverage)", "Shot (disambiguation)", "Shot (alcohol)", "shot unit", "shot disambiguation", "shot drink", "shot alcohol", "shot beverage"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "He was shot by a sniper while riding in a motorcade in Dallas, Texas", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["He was shot by a sniper while riding in a motorcade in Dallas, Texas", "He was shot by a sniper while riding in a motorcade in Dallas, Texas", "He was shot by a sniper while riding in a motorcade in Dallas, Texas", "He was shot by a sniper while riding in a motorcade in Dallas, Texas", "He was shot by a sniper while riding in a motorcade in Dallas, Texas", "He was shot by a sniper while riding in a motorcade in Dallas, Texas", "He was shot by a sniper while riding in a motorcade in Dallas, Texas", "He was shot by a sniper while riding in a motorcade in Dallas, Texas", "He was shot by a sniper while riding in a motorcade in Dallas, Texas", "He was shot by a sniper while riding in a motorcade in Dallas, Texas"], "equivalence_results": ["same", "same", "same", "same", "same", "same", "same", "same", "same", "same"], "equivalence_stats": {"num_same": 10, "num_different": 0, "num_unclear": 0, "total": 10}, "equivalence_ratio": 1.0, "error_label_1.0": "self_consistent_error", "error_label_0.9": "self_consistent_error", "error_label_0.8": "self_consistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:16:17.424547Z"}
{"question_id": "tqa_rc_validation_197", "question": "How was President Kennedy assassinated?", "ground_truth": ["Shot", "Shot (unit)", "Shot (drink)", "Shot (beverage)", "Shot (disambiguation)", "Shot (alcohol)", "shot unit", "shot disambiguation", "shot drink", "shot alcohol", "shot beverage"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "President Kennedy was assassinated by a gunshot wound inflicted by Lee Harvey Oswald while riding in an open-top car in a motorcade through Dealey Plaza in Dallas, Texas, on November 22, 1963", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["President Kennedy was assassinated by a gunshot wound inflicted by Lee Harvey Oswald while riding in an open-top car in a motorcade through Dealey Plaza in Dallas, Texas, on November 22, 1963", "President Kennedy was shot with multiple gunshots by Lee Harvey Oswald from the sixth floor of the Texas School Book Depository building in Dallas, Texas, on November 22, 1963", "President John F", "President Kennedy was shot by Lee Harvey Oswald using a rifle from the sixth floor of the Texas School Book Depository building in Dallas, Texas, on November 22, 1963", "President Kennedy was assassinated by a gunshot wound inflicted by Lee Harvey Oswald using a Mannlicher-Carcano rifle from the sixth floor of the Texas School Book Depository building in Dallas, Texas, on November 22, 1963", "President Kennedy was assassinated by Lee Harvey Oswald with a shot from a rifle, fired from the sixth floor of the Texas School Book Depository building in Dallas, Texas, on November 22, 1963", "President Kennedy was assassinated by a gunshot wound inflicted by Lee Harvey Oswald using a rifle from the sixth floor of the Texas School Book Depository building in Dallas, Texas, on November 22, 1963", "President Kennedy was assassinated by a gunshot wound caused by a rifle shot from the sixth floor of the Texas School Book Depository building, fired by Lee Harvey Oswald", "He was shot by Lee Harvey Oswald with a rifle from the sixth floor of the Texas School Book Depository building in Dallas, Texas, on November 22, 1963", "President Kennedy was assassinated by shots fired from the sixth floor of the Texas School Book Depository building in Dallas, Texas, by Lee Harvey Oswald on November 22, 1963"], "equivalence_results": ["same", "same", "unclear", "same", "different", "same", "different", "same", "same", "same"], "equivalence_stats": {"num_same": 7, "num_different": 2, "num_unclear": 1, "total": 10}, "equivalence_ratio": 0.7777777777777778, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "self_consistent_error", "timestamp": "2026-02-07T04:16:37.958636Z"}
{"question_id": "tqa_rc_validation_198", "question": "Which caped crusader operated in Gotham City?", "ground_truth": ["Batman", "Batman: War on Crime", "Bat-man", "The Bat-Man", "Fictional history of Batman", "Bruce Wayne / Batman", "Bat-Embargo", "Batmarine", "History of Batman", "Brucewayne", "The Caped Crusader", "Batman/Bruce Wayne", "Batsy", "Bruce Wayne (Batman)", "Bat man", "Skills and abilities of Batman", "New Look Batman", "Batman (Bruce Wayne)", "Matches Malone", "Silver Age Batman", "Batman (DC Comics)", "Bruno Diaz", "Batman (comics)", "Bruce Wayne", "Golden Age Batman", "Batdude", "Na na na na na na na na", "Batman Emblem", "Skills, abilities, resources and equipment of Batman", "THE BATMAN", "Caped Crusader", "Batman / Bruce Wayne", "The Batman Handbook: The Ultimate Training Manual", "batman handbook ultimate training manual", "batman bruce wayne", "bat embargo", "skills abilities resources and equipment of batman", "batman war on crime", "bruce wayne batman", "batman comics", "batman dc comics"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Batman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:38.743660Z"}
{"question_id": "tqa_rc_validation_198", "question": "Which caped crusader operated in Gotham City?", "ground_truth": ["Batman", "Batman: War on Crime", "Bat-man", "The Bat-Man", "Fictional history of Batman", "Bruce Wayne / Batman", "Bat-Embargo", "Batmarine", "History of Batman", "Brucewayne", "The Caped Crusader", "Batman/Bruce Wayne", "Batsy", "Bruce Wayne (Batman)", "Bat man", "Skills and abilities of Batman", "New Look Batman", "Batman (Bruce Wayne)", "Matches Malone", "Silver Age Batman", "Batman (DC Comics)", "Bruno Diaz", "Batman (comics)", "Bruce Wayne", "Golden Age Batman", "Batdude", "Na na na na na na na na", "Batman Emblem", "Skills, abilities, resources and equipment of Batman", "THE BATMAN", "Caped Crusader", "Batman / Bruce Wayne", "The Batman Handbook: The Ultimate Training Manual", "batman handbook ultimate training manual", "batman bruce wayne", "bat embargo", "skills abilities resources and equipment of batman", "batman war on crime", "bruce wayne batman", "batman comics", "batman dc comics"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Batman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:40.335698Z"}
{"question_id": "tqa_rc_validation_198", "question": "Which caped crusader operated in Gotham City?", "ground_truth": ["Batman", "Batman: War on Crime", "Bat-man", "The Bat-Man", "Fictional history of Batman", "Bruce Wayne / Batman", "Bat-Embargo", "Batmarine", "History of Batman", "Brucewayne", "The Caped Crusader", "Batman/Bruce Wayne", "Batsy", "Bruce Wayne (Batman)", "Bat man", "Skills and abilities of Batman", "New Look Batman", "Batman (Bruce Wayne)", "Matches Malone", "Silver Age Batman", "Batman (DC Comics)", "Bruno Diaz", "Batman (comics)", "Bruce Wayne", "Golden Age Batman", "Batdude", "Na na na na na na na na", "Batman Emblem", "Skills, abilities, resources and equipment of Batman", "THE BATMAN", "Caped Crusader", "Batman / Bruce Wayne", "The Batman Handbook: The Ultimate Training Manual", "batman handbook ultimate training manual", "batman bruce wayne", "bat embargo", "skills abilities resources and equipment of batman", "batman war on crime", "bruce wayne batman", "batman comics", "batman dc comics"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Batman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:40.560084Z"}
{"question_id": "tqa_rc_validation_198", "question": "Which caped crusader operated in Gotham City?", "ground_truth": ["Batman", "Batman: War on Crime", "Bat-man", "The Bat-Man", "Fictional history of Batman", "Bruce Wayne / Batman", "Bat-Embargo", "Batmarine", "History of Batman", "Brucewayne", "The Caped Crusader", "Batman/Bruce Wayne", "Batsy", "Bruce Wayne (Batman)", "Bat man", "Skills and abilities of Batman", "New Look Batman", "Batman (Bruce Wayne)", "Matches Malone", "Silver Age Batman", "Batman (DC Comics)", "Bruno Diaz", "Batman (comics)", "Bruce Wayne", "Golden Age Batman", "Batdude", "Na na na na na na na na", "Batman Emblem", "Skills, abilities, resources and equipment of Batman", "THE BATMAN", "Caped Crusader", "Batman / Bruce Wayne", "The Batman Handbook: The Ultimate Training Manual", "batman handbook ultimate training manual", "batman bruce wayne", "bat embargo", "skills abilities resources and equipment of batman", "batman war on crime", "bruce wayne batman", "batman comics", "batman dc comics"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Batman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:41.835977Z"}
{"question_id": "tqa_rc_validation_198", "question": "Which caped crusader operated in Gotham City?", "ground_truth": ["Batman", "Batman: War on Crime", "Bat-man", "The Bat-Man", "Fictional history of Batman", "Bruce Wayne / Batman", "Bat-Embargo", "Batmarine", "History of Batman", "Brucewayne", "The Caped Crusader", "Batman/Bruce Wayne", "Batsy", "Bruce Wayne (Batman)", "Bat man", "Skills and abilities of Batman", "New Look Batman", "Batman (Bruce Wayne)", "Matches Malone", "Silver Age Batman", "Batman (DC Comics)", "Bruno Diaz", "Batman (comics)", "Bruce Wayne", "Golden Age Batman", "Batdude", "Na na na na na na na na", "Batman Emblem", "Skills, abilities, resources and equipment of Batman", "THE BATMAN", "Caped Crusader", "Batman / Bruce Wayne", "The Batman Handbook: The Ultimate Training Manual", "batman handbook ultimate training manual", "batman bruce wayne", "bat embargo", "skills abilities resources and equipment of batman", "batman war on crime", "bruce wayne batman", "batman comics", "batman dc comics"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Batman", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:42.568237Z"}
{"question_id": "tqa_rc_validation_199", "question": "Who did Jack Ruby shoot in November 1963?", "ground_truth": ["Lee Harvey Oswald", "Oswald the Lone Assassin", "Lone Nut Theory", "Lone gunman", "Lee Oswald", "Lee H. Oswald", "A.J. Hidell", "L.H.O.", "L. H. Oswald", "L.H.O", "Alek J. Hidell", "Maria Oswald Porter", "Lee Harvey Oswald (photo)", "Lee Harvey Oswald's", "Lee harvy oswald", "Lone gunman theory", "Alek James Hidell", "Lee Harvey Ostwald", "oswald lone assassin", "l h oswald", "lee h oswald", "j hidell", "lee harvey oswald photo", "l h o", "lee harvey oswald s", "alek j hidell"], "model": "GPT-5.2 (OpenAI)", "greedy_answer": "Lee Harvey Oswald", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:43.455141Z"}
{"question_id": "tqa_rc_validation_199", "question": "Who did Jack Ruby shoot in November 1963?", "ground_truth": ["Lee Harvey Oswald", "Oswald the Lone Assassin", "Lone Nut Theory", "Lone gunman", "Lee Oswald", "Lee H. Oswald", "A.J. Hidell", "L.H.O.", "L. H. Oswald", "L.H.O", "Alek J. Hidell", "Maria Oswald Porter", "Lee Harvey Oswald (photo)", "Lee Harvey Oswald's", "Lee harvy oswald", "Lone gunman theory", "Alek James Hidell", "Lee Harvey Ostwald", "oswald lone assassin", "l h oswald", "lee h oswald", "j hidell", "lee harvey oswald photo", "l h o", "lee harvey oswald s", "alek j hidell"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Lee Harvey Oswald", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:45.064878Z"}
{"question_id": "tqa_rc_validation_199", "question": "Who did Jack Ruby shoot in November 1963?", "ground_truth": ["Lee Harvey Oswald", "Oswald the Lone Assassin", "Lone Nut Theory", "Lone gunman", "Lee Oswald", "Lee H. Oswald", "A.J. Hidell", "L.H.O.", "L. H. Oswald", "L.H.O", "Alek J. Hidell", "Maria Oswald Porter", "Lee Harvey Oswald (photo)", "Lee Harvey Oswald's", "Lee harvy oswald", "Lone gunman theory", "Alek James Hidell", "Lee Harvey Ostwald", "oswald lone assassin", "l h oswald", "lee h oswald", "j hidell", "lee harvey oswald photo", "l h o", "lee harvey oswald s", "alek j hidell"], "model": "Llama 4 Maverick (Groq)", "greedy_answer": "Lee Harvey Oswald", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:45.298144Z"}
{"question_id": "tqa_rc_validation_199", "question": "Who did Jack Ruby shoot in November 1963?", "ground_truth": ["Lee Harvey Oswald", "Oswald the Lone Assassin", "Lone Nut Theory", "Lone gunman", "Lee Oswald", "Lee H. Oswald", "A.J. Hidell", "L.H.O.", "L. H. Oswald", "L.H.O", "Alek J. Hidell", "Maria Oswald Porter", "Lee Harvey Oswald (photo)", "Lee Harvey Oswald's", "Lee harvy oswald", "Lone gunman theory", "Alek James Hidell", "Lee Harvey Ostwald", "oswald lone assassin", "l h oswald", "lee h oswald", "j hidell", "lee harvey oswald photo", "l h o", "lee harvey oswald s", "alek j hidell"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Lee Harvey Oswald", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:46.381778Z"}
{"question_id": "tqa_rc_validation_199", "question": "Who did Jack Ruby shoot in November 1963?", "ground_truth": ["Lee Harvey Oswald", "Oswald the Lone Assassin", "Lone Nut Theory", "Lone gunman", "Lee Oswald", "Lee H. Oswald", "A.J. Hidell", "L.H.O.", "L. H. Oswald", "L.H.O", "Alek J. Hidell", "Maria Oswald Porter", "Lee Harvey Oswald (photo)", "Lee Harvey Oswald's", "Lee harvy oswald", "Lone gunman theory", "Alek James Hidell", "Lee Harvey Ostwald", "oswald lone assassin", "l h oswald", "lee h oswald", "j hidell", "lee harvey oswald photo", "l h o", "lee harvey oswald s", "alek j hidell"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Lee Harvey Oswald", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:16:47.029301Z"}
{"question_id": "tqa_rc_validation_6", "question": "What was the last US state to reintroduce alcohol after prohibition?", "ground_truth": ["Utah", "Utah (State)", "Forty-Fifth State", "Sports in Utah", "Climate of Utah", "Education in Utah", "UT (state)", "Utahn", "Yutas", "Geography of Utah", "Utah, United States", "Utah state nickname", "History of mining in Utah", "State of Utah", "Religion in Utah", "Utah (U.S. state)", "Transportation in Utah", "Beehive State", "US-UT", "Utahan", "Politics of Utah", "Salt Lake Seagulls", "45th State", "History of Utah (to 1847)", "The Beehive State", "Youtah", "Transport in Utah", "utah united states", "us ut", "utah state", "forty fifth state", "ut state", "history of utah to 1847", "utah u s state"], "model": "DeepSeek V3.2 (DeepSeek)", "greedy_answer": "Mississippi", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi", "Mississippi"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:19:19.136608Z"}
{"question_id": "tqa_rc_validation_6", "question": "What was the last US state to reintroduce alcohol after prohibition?", "ground_truth": ["Utah", "Utah (State)", "Forty-Fifth State", "Sports in Utah", "Climate of Utah", "Education in Utah", "UT (state)", "Utahn", "Yutas", "Geography of Utah", "Utah, United States", "Utah state nickname", "History of mining in Utah", "State of Utah", "Religion in Utah", "Utah (U.S. state)", "Transportation in Utah", "Beehive State", "US-UT", "Utahan", "Politics of Utah", "Salt Lake Seagulls", "45th State", "History of Utah (to 1847)", "The Beehive State", "Youtah", "Transport in Utah", "utah united states", "us ut", "utah state", "forty fifth state", "ut state", "history of utah to 1847", "utah u s state"], "model": "Llama 3.1 8B (HuggingFace)", "greedy_answer": "Mississippi", "greedy_correct": false, "correctness_match_type": null, "stochastic_answers": ["Massachusetts", "Mississippi", "Mississippi, on November 8, 1966", "Mississippi", "Mississippi", "Mississippi", "Massachusetts", "Massachusetts", "Mississippi", "Mississippi, on November 8, 1966"], "equivalence_results": ["unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear", "unclear"], "equivalence_stats": {"num_same": 0, "num_different": 0, "num_unclear": 10, "total": 10}, "equivalence_ratio": 0.0, "error_label_1.0": "inconsistent_error", "error_label_0.9": "inconsistent_error", "error_label_0.8": "inconsistent_error", "error_label_0.7": "inconsistent_error", "timestamp": "2026-02-07T04:29:57.310954Z"}
{"question_id": "tqa_rc_validation_7", "question": "Which actress was voted Miss Greenwich Village in 1942?", "ground_truth": ["Lauren Bacall", "Bacall", "Lauren Becal", "Lauren Becall", "Betty J. Perske", "Loren Bacall", "Betty Joan Perske", "Betty Perske", "Betty Joan Perski", "betty j perske"], "model": "Claude Opus 4.6 (Anthropic)", "greedy_answer": "Lauren Bacall", "greedy_correct": true, "correctness_match_type": "exact", "stochastic_answers": null, "equivalence_results": null, "equivalence_stats": null, "equivalence_ratio": null, "error_label_1.0": "correct", "error_label_0.9": "correct", "error_label_0.8": "correct", "error_label_0.7": "correct", "timestamp": "2026-02-07T04:31:01.969208Z"}
